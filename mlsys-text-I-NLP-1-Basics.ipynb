{"cells":[{"cell_type":"markdown","metadata":{"id":"gU-Arpc9zElH"},"source":["---\n",">「ある人は十銭をもって一円の十分の一と解釈する。ある人は十銭をもって一銭の十倍と解釈する。同じ言葉が人によって高くも低くもなる。」 \\\n",">（夏目漱石）\n","---"]},{"cell_type":"markdown","metadata":{"id":"bMVPaUY5-hVV"},"source":["# 自然言語処理（Natural Language Processing）\n","\n","プログラミング言語は厳格な文法により「プロセス」を与えることで、その手順通りに処理を行わせることができる\n","\n","一方で、我々が用いる言語は「自然言語」と呼ばれるが、曖昧であり、意味が明確に定義されていない多様な言語である\n","\n","計算機がこのような自然言語を扱うことは従来困難であったが、DNNの発展により扱うことが可能となった"]},{"cell_type":"markdown","metadata":{"id":"JvDBc8NOtmRP"},"source":["## 自然言語処理の応用\n","\n","- 検索エンジン\n","- 機械翻訳\n","  - DeepLなど\n","- 予測変換\n","  - GitHubはMicrosoftが所有しており大量の優良なコードを用いて自動実装や文法だけでなく意味チェックを行うことを目指しているいわれる\n","- スパムフィルタ\n","  - ベイズ網がよく利用されていたがNLP技術の利用が進んでいる\n","- 音声アシスタント\n","  - Alexaなど\n","- 対話システム\n","  - 小説の執筆\n","    - AIノベリスト(https://ai-novel.com/novel.php)\n","  - 一般的な文章処理\n","    - ChatGPT, Gemini, Copilot, Claudeなど\n","  - 画像生成\n","    - Stable Diffusionなど\n","  - 動画生成\n","    - Soraなど\n","  - 楽曲生成\n","    - udioなど\n","\n","### AIノベリストでちょっと遊んでみた\n","「そこには誰もいなかった。しかし、何か咳をする音が聞こえる。」ここまで入力して、以下自動作文させてみた\n","\n","```\n","「誰だ？」と私は叫んだ。\n","咳は止まらない。\n","私は暗闇の中に目を凝らした。\n","そして闇の向こうに人影を確認すると、それが誰なのかが分かった。\n","「父さん」\n","私はそう言って一歩踏み出した。\n","「来るな！」と父は言った。\n","その声には聞き覚えがあった。\n","「父さんだろ？ どうしてこんなところにいるんだよ」\n","返事はなかった。\n","父はただそこに立ち尽くしていた。\n","私の頭の中を様々な疑問や感情が入り乱れた。どうして今になって現れたのか。この部屋には父の思い出...\n","```\n","\n","### ChatGPTで遊んでみた\n","『「そこには誰もいなかった。しかし、何か咳をする音が聞こえる。」この後に続く文章を生成して小説を完成させてください。』とプロンプトで指示して以下自動作文させてみた\n","```\n","そこには誰もいなかった。しかし、何か咳をする音が聞こえる。\n","その音は、一瞬だけだった。けれど確かに、乾いた空気を震わせるような、かすれた喉の奥から漏れるような咳だった。私は足を止め、周囲を見渡した。荒れた床、剥がれかけた壁紙、かつては人が暮らしていた気配だけが残る、忘れられた洋館の一室——\n","再び、咳がした。今度は、より近くから。\n","「……誰か、いるんですか？」\n","私は声をかけた。返事はなかったが、奥の扉がわずかに揺れているのが見えた。風だろうか、それとも——\n","扉を押すと、鈍い音を立てて開いた。薄暗い室内には、ほとんど何もない。だが、窓辺の揺れるカーテンの向こう、微かに何かが動いた。\n","そこには、影があった。\n","人の形をしているが、輪郭が曖昧で、まるで霧の中に立つようにぼやけている。影は、こちらを向いていた。目が合った、と感じた瞬間、私の背筋を冷たいものが駆け上がった。\n","「ここは……もう誰も来ないと思っていた」\n","影が、低く、しかしはっきりと語りかけてきた。\n","「なぜ、あなたはここに来たのですか？」\n","私は答えられなかった。なぜこの館に足を踏み入れたのか、自分でもよく分かっていなかった。ただ引き寄せられるように——この場所に「呼ばれた」ような気がしていたのだ。\n","「あなたは……覚えていないのですね」\n","影が微笑んだ気がした。だがその瞬間、部屋全体が歪むような感覚が走り、私は床に膝をついた。遠くで、再び咳が聞こえた。今度は、自分自身の声のように感じられた。\n","記憶の底から、忘れていた何かが、静かに浮かび上がろうとしていた。\n","```"]},{"cell_type":"markdown","source":["まずは、次のコードをバージョン整合のために実行する"],"metadata":{"id":"OLn3hUlh3fhN"}},{"cell_type":"code","source":["!pip uninstall -y thinc spacy\n","!pip install numpy==1.24.4 scipy==1.14.0 gensim thinc==8.2.1 tsfresh==0.20.0 --upgrade"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ciQzmqhZ3fBx","executionInfo":{"status":"ok","timestamp":1768384701279,"user_tz":-540,"elapsed":20105,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"340bec43-16df-43bf-c310-a0b1045769fa"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: thinc 8.3.10\n","Uninstalling thinc-8.3.10:\n","  Successfully uninstalled thinc-8.3.10\n","Found existing installation: spacy 3.8.11\n","Uninstalling spacy-3.8.11:\n","  Successfully uninstalled spacy-3.8.11\n","Collecting numpy==1.24.4\n","  Downloading numpy-1.24.4.tar.gz (10.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","\n","\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n","\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"]}]},{"cell_type":"markdown","source":["実行したら、**セッションの再起動**を促されるので、**再起動すること**。\n","\n","再起動したら、もう一度最初から実行するよとい。"],"metadata":{"id":"glp-XUej3o5i"}},{"cell_type":"markdown","metadata":{"id":"wimU5555RaL8"},"source":["## 機械可読辞書とコーパス\n","\n","NLPにおいては、大量の「我々が普段扱う言語を電子データ化した情報」が必要となる\n","- NLPに限らずDNNは一般的に教師データとしての大量のデータが必要であるが、特にNLPは量が必要\n","- 従来はこのような情報の入手が困難であった\n","- 現在は、SNSやWebの情報などあらゆる言語情報が電子化されており、これらを用いたデータセットを構築できるようになった\n","\n","この情報セットをコーパス(Corpus)と呼び、言語の使い方を記録・蓄積した文章集合一般のことを指す\n","- 特に計算機が理解できる辞書として利用できる場合、機械可読辞書(Machine-Readable Dictionary)と呼ぶ\n"]},{"cell_type":"markdown","metadata":{"id":"eQmOSAg8Rct8"},"source":["## 形態素解析(Morphological Analysis)\n","\n","コーパスがあっても直接処理するのは困難である\n","- そのままでは単純なデータの羅列にしかならず、無加工で解析するのは困難\n","- そこで、自然言語のテキストデータから、対象言語の文法や単語の品詞等の情報(辞書)に基づいて意味を持つ最小単位語句(形態素:Morpheme)に分割する\n","  - これを「形態素解析」と呼ぶ\n","  - 形態素の品詞等を判別する作業であるが、品詞を問わず分割だけ行うこともしばしば行われ、この分割作業を特に「分かち書き」と呼ぶ\n","\n","例えば、「じょうしがくるまでまつ」を形態素解析するとする\n","\n","もし、単純な辞書(言葉としてあり得る単語群だけで構成されている)場合、次のような分割が想定される(実際にはごく一部でありさらに大量の分類が考えられる)\n","- じょ うし が くる ま でま つ (序 牛が来る 間 デマ 津)\n","- じょ うし が くる まで まつ (序 牛が来るまで待つ)\n","- じょ うし が くるま で まつ (序 牛が車で待つ)\n","- じょ うし が くるま でま つ (序 牛が車デマ津)\n","- じょう し が くる まで まつ (上/穣 死が来るまで待つ)\n","- じょう しが くるま でま つ (上 死が車 デマ 津)\n","- じょうし が くる ま で ま つ (上司が来る間で間 津)\n","- じょうし が くる ま で まつ (上司が来る間で待つ)\n","- じょうし が くる ま でま つ (上司が来る間 デマ 津)\n","- じょうし が くる まで まつ (上司が来るまで待つ)\n","- じょうし が くるま で まつ (上司が車で待つ)\n","\n","出来の悪い日本語変換システムの様であるが、形態素解析の難しさを説明するには十分であろう\n","- 機械学習で自然言語を扱う際、そのために文章を分かち書きすることすら厄介な作業であり、分かち書きのために追加で機械学習が必要というやるせなさ\n","- 英語は分かち書きが文法として含まれており極めて合理的に機械学習させることができる\n","  - 機械学習に向いている言語と向いていない言語がある\n","  - 日本語は向いていない、少なくとも上記の例でも英語ならば、My boss is waiting in the car.などと分かち書きされているので何も混乱なく解析できる\n","\n","日本語の授業で自然言語処理を扱うのは、本当にエグイ\n"]},{"cell_type":"markdown","metadata":{"id":"8I5UptzJBsI3"},"source":["### MeCabを使ってみよう\n","MeCabライブラリを利用して分かち書きしてみよう\n","- MeCabのすごさはすぐにわかるので、まずはインストールして試してみよう"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27612,"status":"ok","timestamp":1768384728894,"user":{"displayName":"西宏章","userId":"00237858890977261979"},"user_tz":-540},"id":"ODvB30dGhXyy","outputId":"4bf8d0a5-2f58-4538-8189-c998487c90c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  libmecab2 mecab-ipadic mecab-utils\n","The following NEW packages will be installed:\n","  libmecab-dev libmecab2 mecab mecab-ipadic mecab-ipadic-utf8 mecab-utils\n","0 upgraded, 6 newly installed, 0 to remove and 1 not upgraded.\n","Need to get 7,367 kB of archives.\n","After this operation, 59.3 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmecab2 amd64 0.996-14build9 [199 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmecab-dev amd64 0.996-14build9 [306 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 mecab-utils amd64 0.996-14build9 [4,850 B]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 mecab-ipadic all 2.7.0-20070801+main-3 [6,718 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 mecab amd64 0.996-14build9 [136 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-3 [4,384 B]\n","Fetched 7,367 kB in 3s (2,869 kB/s)\n","Selecting previously unselected package libmecab2:amd64.\n","(Reading database ... 117528 files and directories currently installed.)\n","Preparing to unpack .../0-libmecab2_0.996-14build9_amd64.deb ...\n","Unpacking libmecab2:amd64 (0.996-14build9) ...\n","Selecting previously unselected package libmecab-dev.\n","Preparing to unpack .../1-libmecab-dev_0.996-14build9_amd64.deb ...\n","Unpacking libmecab-dev (0.996-14build9) ...\n","Selecting previously unselected package mecab-utils.\n","Preparing to unpack .../2-mecab-utils_0.996-14build9_amd64.deb ...\n","Unpacking mecab-utils (0.996-14build9) ...\n","Selecting previously unselected package mecab-ipadic.\n","Preparing to unpack .../3-mecab-ipadic_2.7.0-20070801+main-3_all.deb ...\n","Unpacking mecab-ipadic (2.7.0-20070801+main-3) ...\n","Selecting previously unselected package mecab.\n","Preparing to unpack .../4-mecab_0.996-14build9_amd64.deb ...\n","Unpacking mecab (0.996-14build9) ...\n","Selecting previously unselected package mecab-ipadic-utf8.\n","Preparing to unpack .../5-mecab-ipadic-utf8_2.7.0-20070801+main-3_all.deb ...\n","Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-3) ...\n","Setting up libmecab2:amd64 (0.996-14build9) ...\n","Setting up libmecab-dev (0.996-14build9) ...\n","Setting up mecab-utils (0.996-14build9) ...\n","Setting up mecab-ipadic (2.7.0-20070801+main-3) ...\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27328\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n","Setting up mecab (0.996-14build9) ...\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27328\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-3) ...\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27328\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n","\n","Collecting mecab-python3\n","  Downloading mecab_python3-1.0.12-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.5 kB)\n","Downloading mecab_python3-1.0.12-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (591 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.4/591.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: mecab-python3\n","Successfully installed mecab-python3-1.0.12\n"]}],"source":["!apt install libmecab-dev mecab mecab-ipadic-utf8\n","!pip install mecab-python3"]},{"cell_type":"markdown","metadata":{"id":"GxDMBqSiivy3"},"source":["mecabインストール時に、/usr/local/etc/mecabrcではなく/etc/mecabrcに配置され、 \\\n","\n","error message: [ifs] no such file or directory: /usr/local/etc/mecabrc \\\n","\n","というエラーになるが、これを回避するため、シンボリックリンクを貼る"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":141,"status":"ok","timestamp":1768384729039,"user":{"displayName":"西宏章","userId":"00237858890977261979"},"user_tz":-540},"id":"rV8vd_axit37"},"outputs":[],"source":["!ln -s /etc/mecabrc /usr/local/etc/mecabrc"]},{"cell_type":"markdown","metadata":{"id":"JEsi7WYuDwmD"},"source":["コマンドライン実行可能なのMeCabも入るので実際に試してみよう\n","- 日本語の形態素解析エンジンの中では最もよく使用されている\n","- これがMeCabである、いろいろ試してみるとよい"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":88,"status":"ok","timestamp":1768384729128,"user":{"displayName":"西宏章","userId":"00237858890977261979"},"user_tz":-540},"id":"wviQFEZyDhek","outputId":"401d52b1-ff2f-4577-f1b9-80117ad3a71d"},"outputs":[{"output_type":"stream","name":"stdout","text":["すもも\t名詞,一般,*,*,*,*,すもも,スモモ,スモモ\n","も\t助詞,係助詞,*,*,*,*,も,モ,モ\n","もも\t名詞,一般,*,*,*,*,もも,モモ,モモ\n","も\t助詞,係助詞,*,*,*,*,も,モ,モ\n","もも\t名詞,一般,*,*,*,*,もも,モモ,モモ\n","の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n","うち\t名詞,非自立,副詞可能,*,*,*,うち,ウチ,ウチ\n","EOS\n"]}],"source":["!echo すもももももももものうち | mecab"]},{"cell_type":"markdown","metadata":{"id":"AKeVjC9QRfsj"},"source":["## 構文解析（係り受け解析）\n","\n","形態素解析の結果からわかるように、「これはあり得ない」「この可能性は極めて少ない」という分類がある\n","\n","これらをどのように省くか、その手法をいくつか挙げる\n","\n","まず構文解析\n","- 係り受け解析とも呼ばれる\n","- 形態素解析で得られた単語間の関係性を解析する\n","- 各品詞を辞書から得て、その品詞の並びが自然かどうかを見る\n","\n","「じょ うし が くる ま でま つ (序 牛が来る 間 デマ 津)」は、(人名?)(一般名詞)(助詞)(動詞-連体形)(名詞)(名詞)(名詞)と最後が名詞の連続になり不自然というのがわかる"]},{"cell_type":"markdown","metadata":{"id":"KoRFSNpnwHll"},"source":["## 分散表現\n","単語そのものを数値(ベクトル)として表現する手法で、単に番号を与えるだけでなく、単語間の関連性や類似度をベクトルの中に表現している\n","- 一般に200要素程度のベクトルとして表現される\n","- 具体例としてword2vecなどがある\n","- 後述するが、ベクトルの足し算や引き算などで、関連する単語を導くことができる\n","  - 例: 王 - 男 + 女 = 女王"]},{"cell_type":"markdown","metadata":{"id":"8Ri_E2q4cO1O"},"source":["# word2vec"]},{"cell_type":"markdown","metadata":{"id":"t8G-HllycLGP"},"source":["## word2vecとは？\n","\n","単語のEmbeddingは重要だが、ランダムなIDを与えるのはまずいのではないか？\n","- そのように感じるのはもっともである\n","- では意味が近い言葉に近いIDを与えることなどできるのだろうか？\n","\n","word2vecはそれを可能とする、初歩的な一つの方法である"]},{"cell_type":"markdown","metadata":{"id":"48hupqSqcPtc"},"source":["## どのようなモデルなのか？\n","\n","word2vecはSkip-Gramと呼ばれるNNモデルを利用する\n","- Skip-Gram は２層のニューラルネットワークであり隠れ層は一つのみ\n","- 隣接する層のユニットは全結合している\n","\n","Skip-Gram のアーキテクチャは図に示す通り\n","- ニューラルネットワークはあるタスクで学習させる\n","  - 例えば入力となる言葉に対して近い場所にある言葉を教師データとして与え、相関を学習させる\n","- 実際には学習したタスクに対してニューラルネットワークを使わない\n","- 目的は潜在空間表現を使うことにある\n","  - 潜在空間ベクトルを単語ベクトル(図の$W_{V\\times N}$)と呼び、これを単語のIDとすることを目的とする\n","\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/w2v1.png\" width=400>"]},{"cell_type":"markdown","metadata":{"id":"z9pDSzqqccVi"},"source":["### Skip-Gram が行うタスク\n","\n","Skip-gramでは、ある単語を入力した時、その周辺にどのような単語が現れやすいかを予測するモデルを構築する\n","- 学習は教師あり学習で行い、入力としてある単語を、出力としてその周辺語を与える\n","  - これらの単語は訓練データ内に現れる単語\n","- これらの単語を与え、ネットワークにある単語に対するその周辺語の確率を学習させる\n","\n","例えば、\"I want to eat an apple everyday.\"という文章があった場合、eatに注目した場合の周辺単語は、周辺語として何単語まで考えるのかという指標であるウィンドウサイズ$C$を定めると次の単語が該当する\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/w2v2.png\" width=400>\n","\n","周辺語の数を1つとした時の入出力のイメージは次の通り\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/w2v3.png\" width=400>\n","\n","このネットワークの学習が進めば、近しい場所にあった単語ほど、高い値が出力されるようになるであろう\n","\n"]},{"cell_type":"markdown","metadata":{"id":"toHIXCuHc-Rv"},"source":["### One-hotベクトル表現\n","\n","では、さらに具体的に入力と出力にはどのように単語を与えるべきか？\n","- 単語はもとより可変長\n","- そもそも、単語を数字で表現するために行っているのに、数字にならないとNNに入力することすらできない\n","- その数字(ID)のとり方で学習結果に差が出ては本末転倒\n","\n","まさにその通りで、これを解決するのがOne-hotベクトル表現である\n","- 例えばあるコーパスで単語が3種類あれば、それぞれを(1, 0, 0), (0, 1, 0), (0, 0, 1)と表現する\n","- あるコーパスで単語が10万種類あれば、10万要素あり1つだけ1となるベクトルを全ての単語に充てる\n","  - そんな非現実的なと思うかもしれないが、計算機の性能はこれを可能としてしまったのだから仕方がない\n"]},{"cell_type":"markdown","metadata":{"id":"5PtkrOOJj1R-"},"source":["### word2vecにおけるSkip-Gramの利用\n","\n","10万の単語をOne-hotベクトルで表現し入力としたとき、利用するNNの隠れ層は1つで例えばここに100個の潜在空間ベクトルを与えるとすると、10万の単語を100個の要素(数字)で表現することになる\n","- つまり10万個の要素が100個に縮約されたことになる\n","- 単語そのものを表現させるため、Skip-Gramでは隠れ層に活性化関数を設定せず、隠れ層の出力は単なる入力語の単語ベクトルになる\n","\n","つまり、Skip-Gram では単語の重みベクトル同士の内積を計算していると見なすことができる\n","- この内積値が出力層のユニットに入力される\n","- 出力層ではSoftmaxを用いて正規化する\n","  - 確率として扱えるようにするため\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/w2v7.png\" width=400>\n","\n","word2vecでは、ある単語とその単語に対して実際に現れる周辺語の内積が大きくなるように重みを調整するよう学習させているといえる\n"]},{"cell_type":"markdown","metadata":{"id":"fIXyI0fYtdsB"},"source":["## 実際に扱ってみよう\n","\n","word2vecは膨大なデータが必要となるため、ここでは学習済みモデルを利用する\n","- 一般に精度の良い(実用に耐えうる)word2vecモデルはwikipediaの日本語記事の全情報を学習させている\n","- 医療用語など、限定的な範囲で行う場合は、専門のコーパスを用いて学習させた方が効率も精度もよくなる\n","\n","学習済みモデルのダウンロードを行うが、これだけで相当時間がかかる"]},{"cell_type":"code","source":["!gdown '1-KdCOXj-JPo8GTRDo_Pe4G7bClR4QJ8D'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UwatFLnn6r6F","executionInfo":{"status":"ok","timestamp":1768384737802,"user_tz":-540,"elapsed":8647,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"857b857e-f405-4d68-9d0b-49a4809c9af9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1-KdCOXj-JPo8GTRDo_Pe4G7bClR4QJ8D\n","From (redirected): https://drive.google.com/uc?id=1-KdCOXj-JPo8GTRDo_Pe4G7bClR4QJ8D&confirm=t&uuid=8e20c5e4-54e6-4140-9ecc-a7cd9b2b41de\n","To: /content/wikipedia-jp-model.vec.gz\n","100% 208M/208M [00:03<00:00, 55.3MB/s]\n"]}]},{"cell_type":"code","source":["!pip install gensim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2v2B1xfR8inZ","executionInfo":{"status":"ok","timestamp":1768384777753,"user_tz":-540,"elapsed":6677,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"2c7808b0-1071-4830-c9ab-edf25411e6db"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gensim\n","  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n","Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n","Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: gensim\n","Successfully installed gensim-4.4.0\n"]}]},{"cell_type":"markdown","source":["モデルの読み込みを行うが、この処理に5分程度必要である"],"metadata":{"id":"9fWb20Dc8oDJ"}},{"cell_type":"code","source":["# モデルの読み込み\n","from gensim.models import KeyedVectors\n","\n","# テキスト形式で読み込み\n","model = KeyedVectors.load_word2vec_format(\n","    'wikipedia-jp-model.vec.gz',\n","    binary=False\n",")"],"metadata":{"id":"bjSobcP56yLb","executionInfo":{"status":"ok","timestamp":1768384883487,"user_tz":-540,"elapsed":105327,"user":{"displayName":"西宏章","userId":"00237858890977261979"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["print(\"モデルの読み込み完了！\")\n","print(f\"語彙数: {len(model.key_to_index)}\")\n","\n","# ============================================\n","# 使用例\n","# ============================================\n","\n","print(\"\\n動作確認\")\n","# 例1: 単語の類似単語を検索\n","print(\"【「日本」に似た単語】\")\n","similar_words = model.most_similar('日本', topn=10)\n","for word, score in similar_words:\n","    print(f\"  {word}: {score:.4f}\")\n","\n","# 例2: 単語間の類似度を計算\n","print(\"\\n【単語間の類似度】\")\n","similarity = model.similarity('東京', '大阪')\n","print(f\"  東京 と 大阪: {similarity:.4f}\")\n","\n","# 例3: 有名な単語演算 (王 - 男 + 女 = 女王)\n","print(\"\\n【単語演算: 王 - 男 + 女 = ?】\")\n","result = model.most_similar(positive=['王', '女'], negative=['男'], topn=5)\n","for word, score in result:\n","    print(f\"  {word}: {score:.4f}\")\n","\n","# 例4: 単語のベクトルを取得\n","print(\"\\n【「東京」のベクトル（最初の10次元）】\")\n","vector = model['東京']\n","print(f\"  {vector[:10]}\")\n","print(f\"  ベクトルの次元数: {len(vector)}\")\n","\n","# 例5: 仲間はずれを見つける\n","print(\"\\n【仲間はずれ: 東京, 大阪, 京都, りんご】\")\n","odd_one = model.doesnt_match(['東京', '大阪', '京都', 'りんご'])\n","print(f\"  仲間はずれ: {odd_one}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RlnXrjM-0YsM","executionInfo":{"status":"ok","timestamp":1768384902650,"user_tz":-540,"elapsed":242,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"73c2ed87-8e9b-4f4d-80a8-56775389ce47"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["モデルの読み込み完了！\n","語彙数: 211673\n","\n","動作確認\n","【「日本」に似た単語】\n","  韓国: 0.5399\n","  アメリカ: 0.5136\n","  米国: 0.5083\n","  中国: 0.5070\n","  国内: 0.5043\n","  にっぽん: 0.4940\n","  ほん: 0.4869\n","  日本人: 0.4834\n","  台湾: 0.4810\n","  社団: 0.4653\n","\n","【単語間の類似度】\n","  東京 と 大阪: 0.5910\n","\n","【単語演算: 王 - 男 + 女 = ?】\n","  王妃: 0.6297\n","  妃: 0.5921\n","  王家: 0.5735\n","  国王: 0.5668\n","  后: 0.5621\n","\n","【「東京」のベクトル（最初の10次元）】\n","  [-0.42067   0.081183 -0.15546  -0.24462  -0.29912   0.34963   0.1494\n","  0.208    -0.099115 -0.16831 ]\n","  ベクトルの次元数: 300\n","\n","【仲間はずれ: 東京, 大阪, 京都, りんご】\n","  仲間はずれ: りんご\n"]}]},{"cell_type":"markdown","metadata":{"id":"pO5EqujLaF8f"},"source":["### 類似語句"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1768384902680,"user":{"displayName":"西宏章","userId":"00237858890977261979"},"user_tz":-540},"id":"Nh0z2aipZsQG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ea11aa49-bd42-4195-a919-50122b3028a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('ネコ', 0.6948465704917908),\n"," ('ねこ', 0.6627997159957886),\n"," ('飼い主', 0.6319078803062439),\n"," ('子猫', 0.6110343933105469),\n"," ('飼っ', 0.5984471440315247),\n"," ('ウサギ', 0.5955032110214233),\n"," ('飼い', 0.5943828225135803),\n"," ('犬', 0.5929875373840332),\n"," ('野良猫', 0.5873783826828003),\n"," ('ロシアンブルー', 0.5760769844055176)]\n"]}],"source":["from pprint import pprint\n","pprint(model.most_similar('猫', topn=10))"]},{"cell_type":"markdown","metadata":{"id":"CeIiZmytaElp"},"source":["### 類似度"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1768384902713,"user":{"displayName":"西宏章","userId":"00237858890977261979"},"user_tz":-540},"id":"Ru5gnYXEZwMf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"654a7ac7-a930-40ce-a773-a0c311ca15e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.59298754\n","0.245442\n"]}],"source":["print(model.similarity('猫', '犬'))\n","print(model.similarity('猫', '人'))"]},{"cell_type":"markdown","source":["猫と人の関係より、猫と犬の関係の方がより似ている"],"metadata":{"id":"5bQZFrEi4aWn"}},{"cell_type":"markdown","metadata":{"id":"lgmjqO8SaCVX"},"source":["### 演算"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":59,"status":"ok","timestamp":1768384902759,"user":{"displayName":"西宏章","userId":"00237858890977261979"},"user_tz":-540},"id":"Dw6WWquJZyAa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cd5c19fd-8f11-4921-f9a5-72ea5432de2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('王様', 0.8442699313163757),\n"," ('眠れる', 0.49847689270973206),\n"," ('アンジェリカ', 0.4954322278499603),\n"," ('王女', 0.4931080937385559),\n"," ('女王', 0.4830546975135803),\n"," ('魔法使い', 0.4824971854686737),\n"," ('女', 0.46742168068885803),\n"," ('ラプンツェル', 0.46472883224487305),\n"," ('わがまま', 0.45786088705062866),\n"," ('Princess', 0.4573516249656677)]\n"]}],"source":["# 単語ベクトルの演算\n","new_vec = model['王様'] - model['男'] + model['女']\n","\n","# 計算したベクトルに類似した単語\n","pprint(model.similar_by_vector(new_vec))"]},{"cell_type":"markdown","metadata":{"id":"pRV-JURH6hgW"},"source":["```\n","[('王様', 0.8442699313163757),\n"," ('眠れる', 0.49847689270973206),\n"," ('アンジェリカ', 0.4954322278499603),\n"," ('王女', 0.4931080937385559),\n"," ('女王', 0.4830546975135803),\n"," ('魔法使い', 0.4824971854686737),\n"," ('女', 0.46742168068885803),\n"," ('ラプンツェル', 0.46472883224487305),\n"," ('わがまま', 0.45786088705062866),\n"," ('Princess', 0.4573516249656677)]\n","```\n","女王が入ってきているので、誤ってはいないようである"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1768384902804,"user":{"displayName":"西宏章","userId":"00237858890977261979"},"user_tz":-540},"id":"x4Xpr_pj4i2p","colab":{"base_uri":"https://localhost:8080/"},"outputId":"160c78d4-db8a-47a4-9373-9a735ed4ed18"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('アンジェリカ', 0.49048200249671936),\n"," ('眠れる', 0.4884800910949707),\n"," ('王女', 0.47573140263557434),\n"," ('女王', 0.4754377007484436),\n"," ('魔法使い', 0.46319153904914856),\n"," ('Princess', 0.4499151110649109),\n"," ('アンジェリク', 0.4491198658943176),\n"," ('ラプンツェル', 0.4474671483039856),\n"," ('Princesse', 0.44471073150634766),\n"," ('わがまま', 0.4431554079055786)]"]},"metadata":{},"execution_count":13}],"source":["model.most_similar(positive=['王様', '女'], negative=['男'])"]},{"cell_type":"markdown","metadata":{"id":"6IWbeAS76nrJ"},"source":["```\n","[('アンジェリカ', 0.49048200249671936),\n"," ('眠れる', 0.4884800910949707),\n"," ('王女', 0.47573140263557434),\n"," ('女王', 0.4754377007484436),\n"," ('魔法使い', 0.46319153904914856),\n"," ('Princess', 0.4499151110649109),\n"," ('アンジェリク', 0.4491198658943176),\n"," ('ラプンツェル', 0.4474671483039856),\n"," ('Princesse', 0.44471073150634766),\n"," ('わがまま', 0.4431554079055786)]\n"," ```\n","結果は異なるが、こちらでも同じことができる\n","- こちらが推奨"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":52,"status":"ok","timestamp":1768384902852,"user":{"displayName":"西宏章","userId":"00237858890977261979"},"user_tz":-540},"id":"hjb2w9SiZ4i3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6310c4f7-e2fc-4f09-a604-73056a92549c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('甥', 0.7565309405326843),\n"," ('従兄', 0.722212553024292),\n"," ('従弟', 0.7090374827384949),\n"," ('叔父', 0.7060896754264832),\n"," ('義兄', 0.7008171677589417),\n"," ('叔母', 0.691543698310852),\n"," ('伯父', 0.6811780333518982),\n"," ('従兄弟', 0.679537832736969),\n"," ('妹', 0.6782128810882568),\n"," ('従妹', 0.677395224571228)]"]},"metadata":{},"execution_count":14}],"source":["model.most_similar(positive=['姪', '男性'], negative=['女性'])"]},{"cell_type":"markdown","metadata":{"id":"9Qc5_7Zz6w0l"},"source":["```\n","[('甥', 0.7565309405326843),\n"," ('従兄', 0.722212553024292),\n"," ('従弟', 0.7090374827384949),\n"," ('叔父', 0.7060896754264832),\n"," ('義兄', 0.7008171677589417),\n"," ('叔母', 0.691543698310852),\n"," ('伯父', 0.6811780333518982),\n"," ('従兄弟', 0.679537832736969),\n"," ('妹', 0.6782128810882568),\n"," ('従妹', 0.677395224571228)]\n","```\n","ちょっとおしいが、甥が上位に入っている"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1768384902859,"user":{"displayName":"西宏章","userId":"00237858890977261979"},"user_tz":-540},"id":"cGsSjXkixrTs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bb6b18f0-f38b-4d95-9e96-1548ef16d77b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('経済学部', 0.5606974363327026),\n"," ('明治大学', 0.5386398434638977),\n"," ('中央大学', 0.5302853584289551),\n"," ('一橋大学', 0.5300090909004211),\n"," ('法政大学', 0.5128098726272583),\n"," ('慶應義塾', 0.5110232830047607),\n"," ('商学部', 0.5074078440666199),\n"," ('立教大学', 0.5046968460083008),\n"," ('武蔵大学', 0.49976056814193726),\n"," ('法学部', 0.4984593689441681)]"]},"metadata":{},"execution_count":15}],"source":["model.most_similar(positive=['早稲田大学', '資本'], negative=['酒'])"]},{"cell_type":"markdown","metadata":{"id":"NhHkhGSV6zuE"},"source":["```\n","[('経済学部', 0.5606974363327026),\n"," ('明治大学', 0.5386398434638977),\n"," ('中央大学', 0.5302853584289551),\n"," ('一橋大学', 0.5300090909004211),\n"," ('法政大学', 0.5128098726272583),\n"," ('慶應義塾', 0.5110232830047607),\n"," ('商学部', 0.5074078440666199),\n"," ('立教大学', 0.5046968460083008),\n"," ('武蔵大学', 0.49976056814193726),\n"," ('法学部', 0.4984593689441681)]\n","```\n","早稲田から酒を抜いて資本を加えると、狙い通り慶應が出てくる\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":46,"status":"ok","timestamp":1768384902904,"user":{"displayName":"西宏章","userId":"00237858890977261979"},"user_tz":-540},"id":"7pv5uzPF47m8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5aad4fc7-fb0b-427d-f5dd-f2c01a849d90"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('ロンドン', 0.5689326524734497),\n"," ('キングストン・アポン・テムズ', 0.5191486477851868),\n"," ('ブライトン', 0.5082527995109558),\n"," ('グラスゴー', 0.5033513903617859),\n"," ('バーミンガム', 0.4930422008037567),\n"," ('キングストン', 0.49192166328430176),\n"," ('リバプール', 0.4866296947002411),\n"," ('リヴァプール', 0.48628073930740356),\n"," ('サウサンプトン', 0.48453259468078613),\n"," ('コヴェントリー', 0.4837542772293091)]"]},"metadata":{},"execution_count":16}],"source":["model.most_similar(positive=['東京', 'イギリス'], negative=['日本'])"]},{"cell_type":"markdown","metadata":{"id":"PRb9nwKU68mY"},"source":["```\n","[('ロンドン', 0.5689326524734497),\n"," ('キングストン・アポン・テムズ', 0.5191486477851868),\n"," ('ブライトン', 0.5082527995109558),\n"," ('グラスゴー', 0.5033513903617859),\n"," ('バーミンガム', 0.4930422008037567),\n"," ('キングストン', 0.49192166328430176),\n"," ('リバプール', 0.4866296947002411),\n"," ('リヴァプール', 0.48628073930740356),\n"," ('サウサンプトン', 0.48453259468078613),\n"," ('コヴェントリー', 0.4837542772293091)]\n","```\n","うんうん！"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":57,"status":"ok","timestamp":1768384902959,"user":{"displayName":"西宏章","userId":"00237858890977261979"},"user_tz":-540},"id":"O7GXJG1X5KmJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1859add7-9ce9-4f63-ad4c-26815ebcb772"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('パリ', 0.6384394764900208),\n"," ('トゥールーズ', 0.5746783018112183),\n"," ('リヨン', 0.5595680475234985),\n"," ('トゥールコワン', 0.5443728566169739),\n"," ('マルセイユ', 0.5376759171485901),\n"," ('ブリュッセル', 0.5282273888587952),\n"," ('ストラスブール', 0.5218859314918518),\n"," ('ボルドー', 0.521040141582489),\n"," ('エーヌ', 0.5198503732681274),\n"," ('フレンヌ', 0.5132049322128296)]"]},"metadata":{},"execution_count":17}],"source":["model.most_similar(positive=['東京', 'フランス'], negative=['日本'])"]},{"cell_type":"markdown","metadata":{"id":"6mQSoj9_6-Tv"},"source":["```\n","[('パリ', 0.6384394764900208),\n"," ('トゥールーズ', 0.5746783018112183),\n"," ('リヨン', 0.5595680475234985),\n"," ('トゥールコワン', 0.5443728566169739),\n"," ('マルセイユ', 0.5376759171485901),\n"," ('ブリュッセル', 0.5282273888587952),\n"," ('ストラスブール', 0.5218859314918518),\n"," ('ボルドー', 0.521040141582489),\n"," ('エーヌ', 0.5198503732681274),\n"," ('フレンヌ', 0.5132049322128296)]\n","```\n","ですよねー"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1768384902993,"user":{"displayName":"西宏章","userId":"00237858890977261979"},"user_tz":-540},"id":"HqEMrCKu5cu3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e73aa6e0-ccc6-4283-d36e-bd5b296acaa0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('引っ込む', 0.2480604350566864),\n"," ('薬代', 0.2413998693227768),\n"," ('とおす', 0.23622910678386688),\n"," ('ねだる', 0.22946040332317352),\n"," ('こまめ', 0.2268124222755432),\n"," ('たまっ', 0.22511205077171326),\n"," ('知恵者', 0.22372165322303772),\n"," ('なにしろ', 0.22168254852294922),\n"," ('伏せっ', 0.21967369318008423),\n"," ('お節介', 0.21965302526950836)]"]},"metadata":{},"execution_count":18}],"source":["model.most_similar(positive=['年寄り'], negative=['若者'])"]},{"cell_type":"markdown","metadata":{"id":"S0H2jPPo6_gl"},"source":["```\n","[('引っ込む', 0.2480604350566864),\n"," ('薬代', 0.24139989912509918),\n"," ('とおす', 0.23622915148735046),\n"," ('ねだる', 0.22946041822433472),\n"," ('こまめ', 0.2268124222755432),\n"," ('たまっ', 0.22511205077171326),\n"," ('知恵者', 0.22372162342071533),\n"," ('なにしろ', 0.22168254852294922),\n"," ('伏せっ', 0.21967372298240662),\n"," ('お節介', 0.21965301036834717)]\n"," ```\n","身につまされるものがある"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1768384903004,"user":{"displayName":"西宏章","userId":"00237858890977261979"},"user_tz":-540},"id":"9e9QosHZ6L8d","colab":{"base_uri":"https://localhost:8080/"},"outputId":"aa040a27-edda-4a0f-c2cb-7069bc3b851c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('今時', 0.3461727499961853),\n"," ('ドジ', 0.33415570855140686),\n"," ('つまんない', 0.32548433542251587),\n"," ('気取っ', 0.3221811354160309),\n"," ('安物', 0.3214784264564514),\n"," ('からかわ', 0.31971123814582825),\n"," ('大嫌い', 0.3196238875389099),\n"," ('ちょっと', 0.3168351650238037),\n"," ('みたい', 0.304302841424942),\n"," ('女の子', 0.30388161540031433)]"]},"metadata":{},"execution_count":19}],"source":["model.most_similar(positive=['金持ち'], negative=['財産'])"]},{"cell_type":"markdown","metadata":{"id":"8ru3LDhU7EdY"},"source":["```\n","[('今時', 0.3461727797985077),\n"," ('ドジ', 0.33415573835372925),\n"," ('つまんない', 0.32548433542251587),\n"," ('気取っ', 0.3221811354160309),\n"," ('安物', 0.3214784562587738),\n"," ('からかわ', 0.31971123814582825),\n"," ('大嫌い', 0.3196238875389099),\n"," ('ちょっと', 0.3168352246284485),\n"," ('みたい', 0.304302841424942),\n"," ('女の子', 0.30388158559799194)]\n","```\n","きわどいところを攻めてくるのはさすがだ"]},{"cell_type":"markdown","metadata":{"id":"pWIyvbxOSn_d"},"source":["## 意味解析\n","\n","構文解析を施した文章から正しく意味内容を解釈する処理\n","\n","構文解析で自然であった複数の可能性について、さらに意味的に自然かどうかを判定する\n","\n","先ほどの例では、候補に入っていないが、例えば、\n","\n","- 上司が車で待つ\n","- 城址が車で待つ\n","\n","というのは、解釈上異なり、意味的に城址は車で待つことはできないとわかる。\n","\n","計算機は単語の意味そのものは理解できなくとも、前後関係など、他の単語間の繋がりが自然かを踏まえて適切な選択をしなければならない\n"]},{"cell_type":"markdown","metadata":{"id":"q0bCPJ-dVWeQ"},"source":["## その他の解析\n","\n","### 文脈解析\n","\n","複数の文に対して形態素解析と意味解析を行い、文を超えたつながりについて分析する\n","- じょうし が くる まで まつ (上司が来るまで待つ)\n","- じょうし が くるま で まつ (上司が車で待つ)\n","\n","これらは、単独ではどちらが正しいかは判断できず、前後の話の流れから選択する必要がある\n","- 文脈は、文章中に現れる語の関係や文章の背景に隠れた知識などといった複雑な情報が必要となり、意味解析以上に困難な処理となる\n","\n","### 照応解析\n","\n","代名詞や指示語などといった照応詞の指示内容の推定や、ゼロ代名詞と呼ばれる省略された名詞句を補完する処理\n","\n","### 談話解析\n","\n","実際の会話は、他の会話を会話文に入れるなど、複数文によって構成される\n","- 関連した一連の文を対象にして、文のまとまり、文章の構造、意味などを解析する処理"]},{"cell_type":"markdown","metadata":{"id":"gER684L5VyC5"},"source":["## Embedding(埋め込み)\n","\n","自然言語を計算可能な形に変換することをEmbeddingと呼ぶ\n","- シンプルには分かち書きした言葉それぞれにユニークな番号を振ること\n","- 単語や文章等をベクトル表現に変換する操作のことを指す場合が多い\n","\n","Embeddingにより、\n","- 数量表現になりコンピュータが処理できるようになる \\\n","機械学習アルゴリズムは、一般に文字列型を直接処理できない\n","  - 逆伝搬などは関数による数的表現ができなければ計算すらできない\n","- 変換方法次第で精度の向上が見込める \\\n","単に計算可能な形にするだけでなく、ベクトルの表現方法を工夫することで単語や文章の特徴をベクトル表現に組み込むことができる\n","  - 例えば、近い意味の単語同士を近いベクトルとなるように変換するなど\n"]},{"cell_type":"markdown","metadata":{"id":"-LKvgyp1XV7L"},"source":["## 実は自然言語処理は簡単、英語などの言語ならね\n","\n","日本語はともかく、英語などでは古くから自然言語処理が研究されてきた\n","\n","DNNによる自然言語解析ができるようになったため、単純なEmbeddingでも、DNNの方でうまく関連をつけてくれるようになり、高い精度を要求しないのであれば、複雑な形態素解析を行う必要がない\n","\n","ただ、英語ではつまらないので、とにかくこの授業は「日本語解析」にこだわる\n","- 精度が悪かろうが、時間が掛かろうが、こだわる\n","- なぜって？機械学習を学ぶことは、結局データをどのように理解し、どのようにDNNに食べさせるかの方が重要だから、それを学びたいから"]},{"cell_type":"markdown","metadata":{"id":"aqwNjTdUDvoz"},"source":["## 形態素解析(Morphological Analysis)\n","\n","形態素解析は、自然言語処理分野で主に事前処理として用いられ、対象言語の文法や単語の品詞情報をもとに文章を形態素(単語が意味を持つ最小の単位)に分解する解析を意味する\n","\n","- 文章を形態素解析することで文字列同士・集合同士の類似度計算が可能となる\n","- 文書検索分野では文字列を形態素解析し名詞のみを検索対象とするなどしている\n","- MeCabが優れていることはわかるが、一方で形態要素解析は完ぺきではないことも理解する\n","  - 一意にとれない文章が存在する  \n","「にわにはにわにわとりがいる」という文章を解析する場合、「庭には二羽、鶏がいる」と「庭にハニワ、二羽、鳥がいる」の二通りの分解がある。つまり、意図しない結果になる場合がある。\n","  - 辞書が異なると解析結果も異なる  \n","辞書を持っており、その辞書の内容から単語の品詞情報を取得する。辞書には単語の品詞情報が含まれているが、異なる辞書間で単語の種類や品詞情報が共通化されているわけではないため、利用する辞書によって分解が異なる。\n","- MeCabほど精度は高くないが、インストールが簡単なJanomeがある\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8b3eJl3weVh8"},"source":["### MeCabの特徴\n","\n","MeCabの特徴は次の通り\n","\n","1. 辞書やコーパス(テキストや発話を大規模に集めてデータベース化した言語資料)に依存しない汎用的な設計である\n","\n","1. 解析モデルとしてbi-gramマルコフモデルを利用(後述)\n","1. 高い解析精度があり、他のChaSenやKAKASIに比べ高速\n","1. 辞書引きアルゴリズムおよびデータ構造に高速なTRIE構造であるDouble-Arrayを用いている\n","  - 再入可能なライブラリ\n","  - 各種スクリプト言語をバインディング(perl/ruby/python/java/C#)\n","1. 解探索アルゴリズムにViterbi(ビタビ)を利用\n","  - 観測された事象系列を結果として生じる隠された状態の最も尤もらしい並び（ビタビ経路）を探す動的計画法アルゴリズムの一種で、隠れマルコフモデルに基づく\n","    - 隠れた状態への最適経路は、一つ前の隠れた状態までの最短経路と無関係に決まる\n","  - 隠れた状態までの最短経路のコストの計算量は、各隠れた状態にいたる経路の総数の加算回数となり、計算量は隠れた状態数に比例する\n","1. 連接表は2次元テーブルで実装される\n","1. 品詞の階層は無制限多階層である\n","1. 制約付き解析やN-best解を与えることができる"]},{"cell_type":"markdown","metadata":{"id":"Xa5MF3pVrq14"},"source":["### bi-gramマルコフモデルについて\n","\n","#### まずはN-gramの概要\n","- 文書を文字単位の記号列と考え隣接したN個の記号毎の出現頻度(度数と呼ぶ)を集計する。隣接した1個の記号からなる記号列(つまり1文字)毎の度数をuni-gram、2個の記号をbi-gram、3個の記号ならをtri-gram,…と呼ぶ\n","- N-gramを利用すると文法情報を用いずに分解できるため言語に依存しない文書の分割が可能となる。さらに言語学的に意味を持たない記号列についても集計が可能となる\n","\n","#### マルコフ連鎖\n","- 確率過程の一種であるマルコフ過程のうち、とりうる状態が離散的な過程であり、特に時間が離散的である場合をさす。未来の挙動が過去の挙動と無関係で現在の値だけで決定される（マルコフ性）系列である\n","\n","#### bi-gramマルコフモデル\n","- あるタイミングの単語の生起確率は直前の1単語にのみ依存すると仮定したモデルで、単純マルコフ過程となる。なお、N-gramに拡張した場合あるタイミングの単語の生起確率は直前のN-1単語にのみ依存すると定義しN-1重マルコフ過程に従うことを表す\n","- ある単語列$W=w_1,w_2,…w_n$が与えられたとき、単語列を$W$コーパス内の単語の生起確率を$C$とすると，同時生起確率$P(W)$は以下の式で定義される．\n","\n","$$P(W)=∏^n_{i=1}P(w_i|w_i−1)=∏_n^{i=1}\\left (\\frac{C(w_i,w_i−1)}{C(w_i−1)}\\right )$$\n","\n","- 例えば「私はAIが嫌い」という単語列の同時生起確率Pを表す式は、BOSを文章開始、EOSを文章の終わりを示す符号とすると以下のようになる．\n","\n","$P(私はAIが嫌い)=P(私|BOS)P(は|私)P(AI|は)P(が|AI)P(嫌い|が)P(EOS|嫌い)$\n","\n","  - BOSやEOSの生起確率は、文章には必ず開始と終了があるため1となる。また、各単語の生起確率はコーパス内での各単語の度数/全単語数で計算する\n","\n","コスト推定はコーパスから学習し、その学習モデルとして、条件付き確率場(Conditional Random Fields:CRF)を用いる\n","\n","- CRFは系列ラベリングの一手法で、系列データが与えられると対応する系列ラベルを出力することができる\n","- MeCabの入力の系列データは単語分割済みの文字列配列(例えば慶應)である\n","- MeCABの出力は品詞情報などを保持したオブジェクトの配列(例えば固有名詞)である\n","- ある関数の引数について、定められた条件に合致するかどうかを1か0で返す関数(普通のif構文)を組成関数と呼び、t番目の単語($x_t$)と、その対象となる一つ前の単語($y_t$)、さらにその一つ前の単語($y_{t-1}$)にのみ依存すると仮定する\n","\n","#### CRFの計算式\n","\n","組成関数を$\\phi$、確率の総和を1にするための正規化項を$Z$とすると、  \n","\n","$$P(y|x)=\\frac{1}{Z(x,\\alpha)}\\exp(\\alpha^T\\phi(x,y))$$  \n","$$Z(x,\\alpha)=\\sum_y \\exp(\\alpha^T\\phi(x,y))$$  \n","$$\\alpha^T\\phi(x,y)=\\sum_{t,i}\\alpha_i\\phi_i(x_t,y_{t-1},y_t)$$"]},{"cell_type":"markdown","metadata":{"id":"sAVWm19Nlb8M"},"source":["### ビタビアルゴリズム\n","\n","例えば次のような道路の最短経路を探す場合、普通に探すと組み合わせ爆発により計算コストはあっという間に増えてしまう\n","- そこで川に掛けられた橋に注目し、橋までの最短距離を段階的に（川ごとに）求める\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/viterbi1.gif\" width=400>\n","\n","まず、橋から橋への最短ルートを地図から読み取りその距離を求める。例として次の図が得られる\n","- 第１段階はＡ川の橋a1,a2,a3を渡るときで、それぞれスタート地点から一本の道しかなく、その距離を橋の名称と一緒に赤色で記述する\n","- 第２段階はＢ川を渡るとき。橋b1へは３本の道があるが、その中で最短の道を太線で表記し、その距離を橋の名称と一緒に赤色で記述する。この時、3回の加算計算でよく、この操作を、b2, b3に対しても行う\n","- これらの処理をゴールまで行うと、ゴールから太線に沿ってスタート地点まで、分岐することなく遡ることができ、最短経路となる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/viterbi2.gif\" width=500>\n","\n","この場合、結果は次の図のようになる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/viterbi3.gif\" width=400>\n"]},{"cell_type":"markdown","metadata":{"id":"jQaYJfqX2LAa"},"source":["# 課題2 (Word2Vec)\n","\n","Word2Vecを試して、愉快な単語の足し算、引き算を一つ導き出し、その面白さを簡単に説明しなさい"]},{"cell_type":"markdown","metadata":{"id":"lFv1IcTyXc8P"},"source":["# 課題3 (文章生成モデル)\n","\n","英語であるが、次のOPT-13B文章生成モデルを用いて、簡単な話を作成しなさい\n","\n","なお、下記のコードは、ここまでのプログラムを実行したままでは、メモリがクラッシュするため、必ず分割して実行すること\n","- 別のスクリプトに下記プログラムを貼り付けて実行するとよい\n","\n","```\n","!pip install transformers\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","# OPT-13Bモデル・トークナイザの読み込み\n","model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-13b\", torch_dtype=torch.float16).cuda()\n","tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-13b\", use_fast=False)\n","# 次のpromptを変えれば、その後に続く文章を生成することができる\n","# - 現在候補は5個、最大長さは40としている\n","prompt = \"Hello, I'm am conscious and\"\n","input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n","# 確率が高いTop 5を生成\n","generated_ids = model.generate(input_ids, do_sample=True, num_return_sequences=5, max_length=40)\n","generated_tokens = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n","```\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1F4ifdHNnrAUsDv2pj0EXDImHsM_x_E9M","timestamp":1628197853609}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}