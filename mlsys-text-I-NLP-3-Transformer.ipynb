{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1F4ifdHNnrAUsDv2pj0EXDImHsM_x_E9M","timestamp":1628197853609}],"gpuType":"T4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"64ee62d4b8b04e9880c103abf19affcd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_360281624be845c5ba337af8b1230885","IPY_MODEL_8c83027cad38415a887dafe4a8bf4808","IPY_MODEL_f3956cf1f6904293ae5ad522bc495790"],"layout":"IPY_MODEL_bd6eb41d41f64366b44c8b9115f3de48"}},"360281624be845c5ba337af8b1230885":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3be47ce2fd7f4aada2a31fc315a72ce9","placeholder":"​","style":"IPY_MODEL_980382701ad64b54818a8b49cf656b07","value":"README.md: "}},"8c83027cad38415a887dafe4a8bf4808":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a38d6c434ae54b8792ffa5e2b2bafadd","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_db2d395d79d74b52a66aadecd45697a3","value":1}},"f3956cf1f6904293ae5ad522bc495790":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e75e7c021ea54c17a8bdc6222dd8e30a","placeholder":"​","style":"IPY_MODEL_c7858e6df59e472aa00740d626bc9d81","value":" 7.81k/? [00:00&lt;00:00, 486kB/s]"}},"bd6eb41d41f64366b44c8b9115f3de48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3be47ce2fd7f4aada2a31fc315a72ce9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"980382701ad64b54818a8b49cf656b07":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a38d6c434ae54b8792ffa5e2b2bafadd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"db2d395d79d74b52a66aadecd45697a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e75e7c021ea54c17a8bdc6222dd8e30a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7858e6df59e472aa00740d626bc9d81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"085b59eade3f4f85a45cae3a023ff9e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_af346e77793a412bab0d6f8844835f61","IPY_MODEL_8a21f4565ea74e2991546a20a0aac2ba","IPY_MODEL_2a9f61bc272c44aba276e5eb2b25a984"],"layout":"IPY_MODEL_d2ea81366fc840a5af0bd3e83ea13ad9"}},"af346e77793a412bab0d6f8844835f61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7e76d10d9f54662b82c8102a5ea90cf","placeholder":"​","style":"IPY_MODEL_f3fcf11797f74cc5b014cf0c2e3fac99","value":"plain_text/train-00000-of-00001.parquet: 100%"}},"8a21f4565ea74e2991546a20a0aac2ba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_815f933ac786483fb46aa57dc313238c","max":20979968,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13acc8fb84524969a468646625997ffc","value":20979968}},"2a9f61bc272c44aba276e5eb2b25a984":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_991fd59782084434b5d0267d646cec07","placeholder":"​","style":"IPY_MODEL_422bb954b5ec48de805a628b7ff393b0","value":" 21.0M/21.0M [00:00&lt;00:00, 34.4MB/s]"}},"d2ea81366fc840a5af0bd3e83ea13ad9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7e76d10d9f54662b82c8102a5ea90cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3fcf11797f74cc5b014cf0c2e3fac99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"815f933ac786483fb46aa57dc313238c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13acc8fb84524969a468646625997ffc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"991fd59782084434b5d0267d646cec07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"422bb954b5ec48de805a628b7ff393b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df7f4a1c9aea4e5e9336c3e1d3a7ad3e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7d0431fad2f46719066a6c2dfd226ef","IPY_MODEL_967185d4b8024385b0b50af8ada043de","IPY_MODEL_7badd33b792e4386b42594b3cdcda746"],"layout":"IPY_MODEL_378b4e4976fe4879b63f9937fa3eabee"}},"d7d0431fad2f46719066a6c2dfd226ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b61a253db2b49ad9e9c4cb84ffa8e4c","placeholder":"​","style":"IPY_MODEL_9577196a4a944422a1d3d24db14cd0db","value":"plain_text/test-00000-of-00001.parquet: 100%"}},"967185d4b8024385b0b50af8ada043de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbdaece280854e4c98bce6d80b4b5b80","max":20470363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_23f6d9b31e0f408c9f191e8797f6c333","value":20470363}},"7badd33b792e4386b42594b3cdcda746":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cd70b3ed440401a93309ea8d62ac59d","placeholder":"​","style":"IPY_MODEL_c0622b945736420f87210d06d235f3ce","value":" 20.5M/20.5M [00:00&lt;00:00, 81.0MB/s]"}},"378b4e4976fe4879b63f9937fa3eabee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b61a253db2b49ad9e9c4cb84ffa8e4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9577196a4a944422a1d3d24db14cd0db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbdaece280854e4c98bce6d80b4b5b80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23f6d9b31e0f408c9f191e8797f6c333":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9cd70b3ed440401a93309ea8d62ac59d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0622b945736420f87210d06d235f3ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b38d017450e4eb297536835c8383e4c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0f7b13b0f97749ac97047f54987155fd","IPY_MODEL_448e0a8afb204eea92c7e0a0f884a239","IPY_MODEL_98d9daa7470346abb9ea0c412dd060e0"],"layout":"IPY_MODEL_de861fbd56b84428abb02145cdaa0a7f"}},"0f7b13b0f97749ac97047f54987155fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_285b021c2ecf4ac482d29fcaace54544","placeholder":"​","style":"IPY_MODEL_36b2b9380fff46f089a170fe5929cd02","value":"plain_text/unsupervised-00000-of-00001.p(…): 100%"}},"448e0a8afb204eea92c7e0a0f884a239":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29e9d8cbb5be4e7b951bcba7ef877179","max":41996509,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac8aa861f8304a6e9b1ab80b858ee380","value":41996509}},"98d9daa7470346abb9ea0c412dd060e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83191d45c3974d35ab0ad607ab8c3031","placeholder":"​","style":"IPY_MODEL_d116a4c7543d45be9b72d5869cc5e4d8","value":" 42.0M/42.0M [00:00&lt;00:00, 90.5MB/s]"}},"de861fbd56b84428abb02145cdaa0a7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"285b021c2ecf4ac482d29fcaace54544":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36b2b9380fff46f089a170fe5929cd02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29e9d8cbb5be4e7b951bcba7ef877179":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac8aa861f8304a6e9b1ab80b858ee380":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"83191d45c3974d35ab0ad607ab8c3031":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d116a4c7543d45be9b72d5869cc5e4d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c3ad583896a417bbf2f03a4908194a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ebc18c9b65594f27bb227a4202d554e2","IPY_MODEL_0982c66f91224227af0620fd20379e75","IPY_MODEL_f0b84155f75c431aa49b46b19dd60098"],"layout":"IPY_MODEL_9b3d3e3340934138bafe0a09d88eda15"}},"ebc18c9b65594f27bb227a4202d554e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b18ff24ac5b4e87aa7e33bd1447926e","placeholder":"​","style":"IPY_MODEL_510f786116684be7af8088bb96d76efe","value":"Generating train split: 100%"}},"0982c66f91224227af0620fd20379e75":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_309961f5c4bb435f9c2af804d2e819e8","max":25000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07979e5ce3de47ca8206c9905e5c2a21","value":25000}},"f0b84155f75c431aa49b46b19dd60098":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16273c3269334913b24cdb3e4e545351","placeholder":"​","style":"IPY_MODEL_31973416332d487685406736623ffec3","value":" 25000/25000 [00:00&lt;00:00, 96428.91 examples/s]"}},"9b3d3e3340934138bafe0a09d88eda15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b18ff24ac5b4e87aa7e33bd1447926e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"510f786116684be7af8088bb96d76efe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"309961f5c4bb435f9c2af804d2e819e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07979e5ce3de47ca8206c9905e5c2a21":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16273c3269334913b24cdb3e4e545351":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31973416332d487685406736623ffec3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0568cca62bee470a898350fb4e3b7f0f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74fd33975a7b4df5910b2c3f1699fcdb","IPY_MODEL_a8df1944e78a45bb84dfe36470f1099a","IPY_MODEL_3bddcf45663a4e1491b92822eea6645b"],"layout":"IPY_MODEL_51c1e9d3994c4154914c774464ce0b42"}},"74fd33975a7b4df5910b2c3f1699fcdb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccedc935438542b99ff5932366800718","placeholder":"​","style":"IPY_MODEL_5e583d0c4c474685b810506c687fd961","value":"Generating test split: 100%"}},"a8df1944e78a45bb84dfe36470f1099a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_35665fda4d4840df8b4b4c502fbd85f3","max":25000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c15897f684d5431997877dcf17dff432","value":25000}},"3bddcf45663a4e1491b92822eea6645b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_986244fe2a804fdcb5ad46073d21afbe","placeholder":"​","style":"IPY_MODEL_ff81a4f4cc4f4ad9b6c01f854b120351","value":" 25000/25000 [00:00&lt;00:00, 105812.97 examples/s]"}},"51c1e9d3994c4154914c774464ce0b42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccedc935438542b99ff5932366800718":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e583d0c4c474685b810506c687fd961":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35665fda4d4840df8b4b4c502fbd85f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c15897f684d5431997877dcf17dff432":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"986244fe2a804fdcb5ad46073d21afbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff81a4f4cc4f4ad9b6c01f854b120351":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"150b9d62e41140e6ab847bf0bc31949f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e8850b7c83e24af8915377555cc567ae","IPY_MODEL_edb292a7a259416faa8476051660c031","IPY_MODEL_1a8c84bae1da40939271fd2251845c32"],"layout":"IPY_MODEL_8b67ed3ccfce417ab4064186957604b5"}},"e8850b7c83e24af8915377555cc567ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_666b35a49c474bfba818a724a2dc1f6f","placeholder":"​","style":"IPY_MODEL_e2fcab047c05419db98afac5fbac4d62","value":"Generating unsupervised split: 100%"}},"edb292a7a259416faa8476051660c031":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_37154c504bbe4c6fad59a5fe3dcaf1d0","max":50000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_35ee513c7d5b47bba468d710b1bd28f0","value":50000}},"1a8c84bae1da40939271fd2251845c32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e0885e20e0c4a9aa904578e121e10cb","placeholder":"​","style":"IPY_MODEL_c09516ee96b44669b777997c9735c11d","value":" 50000/50000 [00:00&lt;00:00, 173513.06 examples/s]"}},"8b67ed3ccfce417ab4064186957604b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"666b35a49c474bfba818a724a2dc1f6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2fcab047c05419db98afac5fbac4d62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37154c504bbe4c6fad59a5fe3dcaf1d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35ee513c7d5b47bba468d710b1bd28f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e0885e20e0c4a9aa904578e121e10cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c09516ee96b44669b777997c9735c11d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b157c29e9c54c6eb4b2ec76ef2811ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7427e062220e488485cf8e535c6dee30","IPY_MODEL_cf1c70ef81eb4df0a71b3dc22554d826","IPY_MODEL_3f9b1f6bb6b644f495323033d42c8270"],"layout":"IPY_MODEL_1fbfc802c2584584a04dbf4d66c15ac5"}},"7427e062220e488485cf8e535c6dee30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b07c5cb9359d4537b606d2a9b26a40a7","placeholder":"​","style":"IPY_MODEL_3dc14059be8c4663ad978cf6ad85f061","value":"README.md: "}},"cf1c70ef81eb4df0a71b3dc22554d826":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_303fb2264cf5431da5e1c21ec8127d76","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bef788f78ea94e0eb1d3a7d808919b2d","value":1}},"3f9b1f6bb6b644f495323033d42c8270":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dbf9fa85da74af28c65cc01414cab3b","placeholder":"​","style":"IPY_MODEL_58e4462f33bb4f3786dabf2ebdc8cc59","value":" 10.5k/? [00:00&lt;00:00, 976kB/s]"}},"1fbfc802c2584584a04dbf4d66c15ac5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b07c5cb9359d4537b606d2a9b26a40a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3dc14059be8c4663ad978cf6ad85f061":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"303fb2264cf5431da5e1c21ec8127d76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"bef788f78ea94e0eb1d3a7d808919b2d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7dbf9fa85da74af28c65cc01414cab3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58e4462f33bb4f3786dabf2ebdc8cc59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd201dc0da9045d3a1225f8a4fbb9c1e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34c2c3feff4f43ed853af0453701e69e","IPY_MODEL_32685b8facfc4024adb7e57fd661919e","IPY_MODEL_52b13e0f9cdf4524a2909f54203f5d98"],"layout":"IPY_MODEL_86a72381e03a48f1b4dce25a625f3dbe"}},"34c2c3feff4f43ed853af0453701e69e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a9224357d4249fd853c3df5c824bb83","placeholder":"​","style":"IPY_MODEL_ce268779211148d9935ca503e6c680f5","value":"wikitext-2-raw-v1/test-00000-of-00001.pa(…): 100%"}},"32685b8facfc4024adb7e57fd661919e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ac4de40c2e74f7888c4f8b617b50ff0","max":732610,"min":0,"orientation":"horizontal","style":"IPY_MODEL_156998c81cdc41bd8f73184d67668162","value":732610}},"52b13e0f9cdf4524a2909f54203f5d98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_131013a276984418bb54831be29caabd","placeholder":"​","style":"IPY_MODEL_a56ee9c4d8974d35916b2eb4c52e1388","value":" 733k/733k [00:00&lt;00:00, 58.1kB/s]"}},"86a72381e03a48f1b4dce25a625f3dbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a9224357d4249fd853c3df5c824bb83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce268779211148d9935ca503e6c680f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ac4de40c2e74f7888c4f8b617b50ff0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"156998c81cdc41bd8f73184d67668162":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"131013a276984418bb54831be29caabd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a56ee9c4d8974d35916b2eb4c52e1388":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4bb44d69c33b4a28943d228194da8438":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_016c3c93653c47849d5a083cb17d08af","IPY_MODEL_c50c36009309467080ef7f005eb15b22","IPY_MODEL_8577602f6e2e4aacaa1449e61b3fe8a1"],"layout":"IPY_MODEL_707d751a31354bf78c2d25a4da6f584a"}},"016c3c93653c47849d5a083cb17d08af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_295eafb9edbb4bef84794eea830c9bbc","placeholder":"​","style":"IPY_MODEL_a4a693748472485cb6b92a67a8bebfa7","value":"wikitext-2-raw-v1/train-00000-of-00001.p(…): 100%"}},"c50c36009309467080ef7f005eb15b22":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b589e92a3c864c6094c1a8dedbb7df4a","max":6357543,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66471754c0794626b66b0169efe5ead5","value":6357543}},"8577602f6e2e4aacaa1449e61b3fe8a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f038e3e38934416b5344fcc57ea8243","placeholder":"​","style":"IPY_MODEL_a14076b80d134010a11fa58586cf9792","value":" 6.36M/6.36M [00:00&lt;00:00, 454kB/s]"}},"707d751a31354bf78c2d25a4da6f584a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"295eafb9edbb4bef84794eea830c9bbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4a693748472485cb6b92a67a8bebfa7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b589e92a3c864c6094c1a8dedbb7df4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66471754c0794626b66b0169efe5ead5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f038e3e38934416b5344fcc57ea8243":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a14076b80d134010a11fa58586cf9792":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce06ca0296f847baa4a832a42bbaa139":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d8f59be8570f4ec18689b4bb3b098fd2","IPY_MODEL_70b29cf9a6c44376b6f6857555a7eda8","IPY_MODEL_e9c07450e8d24535969db6fbc5d4a544"],"layout":"IPY_MODEL_f612573213d54a64ac01a2f8534d4738"}},"d8f59be8570f4ec18689b4bb3b098fd2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f52bba504fc044cea1f8f1b38aa36830","placeholder":"​","style":"IPY_MODEL_92e9b1b0937246179005d7093c4db6da","value":"wikitext-2-raw-v1/validation-00000-of-00(…): 100%"}},"70b29cf9a6c44376b6f6857555a7eda8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ed46dfde52a40d191f06a9f9f40b65d","max":657209,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ebabf697fc24de7b53f41068c539434","value":657209}},"e9c07450e8d24535969db6fbc5d4a544":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17aa0a6a6b8b4d85a69e41a4a52650d5","placeholder":"​","style":"IPY_MODEL_71cf783772474087b880fb75ea2d46c2","value":" 657k/657k [00:00&lt;00:00, 218kB/s]"}},"f612573213d54a64ac01a2f8534d4738":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f52bba504fc044cea1f8f1b38aa36830":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92e9b1b0937246179005d7093c4db6da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ed46dfde52a40d191f06a9f9f40b65d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ebabf697fc24de7b53f41068c539434":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"17aa0a6a6b8b4d85a69e41a4a52650d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71cf783772474087b880fb75ea2d46c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4328dc5e42da4309a7a31256feaa2611":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f754f44e48144adbc9552d4e34d9895","IPY_MODEL_b0b9367204214957b3b1ec405eb1a921","IPY_MODEL_9ffed447759d47d9b170ef10ff48e4e0"],"layout":"IPY_MODEL_14026009e195409f8e966fba6ca031fc"}},"7f754f44e48144adbc9552d4e34d9895":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f63a5fda80ef40578eaf8a95f8943309","placeholder":"​","style":"IPY_MODEL_12d7548145f544f6bb3e33c0f5fe56b3","value":"Generating test split: 100%"}},"b0b9367204214957b3b1ec405eb1a921":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7774020d24ed451d89754d4e7c431668","max":4358,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c4cf56525814d338c5ef258489eaf11","value":4358}},"9ffed447759d47d9b170ef10ff48e4e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4765384adc6a426cb9c92b772de0bb5b","placeholder":"​","style":"IPY_MODEL_7ccdb44370b549c0ae013d37bf40b88c","value":" 4358/4358 [00:00&lt;00:00, 149363.26 examples/s]"}},"14026009e195409f8e966fba6ca031fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f63a5fda80ef40578eaf8a95f8943309":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12d7548145f544f6bb3e33c0f5fe56b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7774020d24ed451d89754d4e7c431668":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c4cf56525814d338c5ef258489eaf11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4765384adc6a426cb9c92b772de0bb5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ccdb44370b549c0ae013d37bf40b88c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"890af45bd3f147bf90be78a2526a35d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d70ba381a5a74f9080e802a2f14c5533","IPY_MODEL_c5cc1a5fb060449a902a0d60de59220b","IPY_MODEL_7a560d62bfd44fe7956f77be9a17b512"],"layout":"IPY_MODEL_0f14b7ffb85f49b489b103c0627b8324"}},"d70ba381a5a74f9080e802a2f14c5533":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86b7058147754a65b70906df2aeefd77","placeholder":"​","style":"IPY_MODEL_982be505c3d54b1eb96f25929d069da9","value":"Generating train split: 100%"}},"c5cc1a5fb060449a902a0d60de59220b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6bd3b5600f44bb785546d9087c4106e","max":36718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a9277340fb6443cd84e1460a04643615","value":36718}},"7a560d62bfd44fe7956f77be9a17b512":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_903b4595aad54ce1902d302e50f8217d","placeholder":"​","style":"IPY_MODEL_76cb031e72a04fc2b23384f04e17e5b8","value":" 36718/36718 [00:00&lt;00:00, 519967.10 examples/s]"}},"0f14b7ffb85f49b489b103c0627b8324":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86b7058147754a65b70906df2aeefd77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"982be505c3d54b1eb96f25929d069da9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6bd3b5600f44bb785546d9087c4106e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9277340fb6443cd84e1460a04643615":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"903b4595aad54ce1902d302e50f8217d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76cb031e72a04fc2b23384f04e17e5b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"709d558ea5bf48be81c69787b5573ee5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c5cffaa57ef403e890538883426de1f","IPY_MODEL_8ff1ef6b78334caba4e1c9762577bd69","IPY_MODEL_d4ccb2c48e0744609451032f75772ec8"],"layout":"IPY_MODEL_8b06a2cd4f434c939aca862083837f1c"}},"6c5cffaa57ef403e890538883426de1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_286d630501be4cb5aac220aee192fe0f","placeholder":"​","style":"IPY_MODEL_4794e3e8926b4e56a38f390092dcaaa2","value":"Generating validation split: 100%"}},"8ff1ef6b78334caba4e1c9762577bd69":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_33dc2e1e90654f018fdc2bd17e9b8f9b","max":3760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fdd957442abe4efe87f144300600c383","value":3760}},"d4ccb2c48e0744609451032f75772ec8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00699c3d4a1540c69ff03a566363eb50","placeholder":"​","style":"IPY_MODEL_5d97424881174163b573001d21353990","value":" 3760/3760 [00:00&lt;00:00, 136483.94 examples/s]"}},"8b06a2cd4f434c939aca862083837f1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"286d630501be4cb5aac220aee192fe0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4794e3e8926b4e56a38f390092dcaaa2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33dc2e1e90654f018fdc2bd17e9b8f9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdd957442abe4efe87f144300600c383":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"00699c3d4a1540c69ff03a566363eb50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d97424881174163b573001d21353990":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"gU-Arpc9zElH"},"source":["---\n",">「ドライバーが車を選ぶんじゃない。車がドライバーを選ぶんだ。人間と機械の間には、神秘的な絆があるんだ」 \\\n",">（ボビー:映画トランスフォーマーより）\n","---"]},{"cell_type":"markdown","source":["## なぜTransformerが重要なのか\n","\n","Transformerは、自然言語処理に適する方法として見出されたが、これにはどのような経緯があったのか、簡単に説明する\n"],"metadata":{"id":"_eDIB5jStfZc"}},{"cell_type":"markdown","source":["### 自然言語処理はなぜ困難なのか\n","\n","まず、言語データは画像データと本質的に扱い方が異なる\n","\n","- 画像データは画素の集まりであり、CNNでは画像全体から近隣の画素の特徴をとらえて処理する\n","- 言語データは単語を逐次的に聞いて処理する\n","  - つまり、過去の単語の入力情報を保持し、文脈を理解する必要がある\n","  - 例えば、「まいった」だけではわからないが、「失敗してまいった」「神社にまいった」となればわかる\n","\n","言語データの性質から、逐次的に処理する仕組みが必要\n","- 従来は、この性質から、RNN (Recurrent Neural Network)やLSTM (Long short-term memory)などが利用されてきた\n","  - 内部状態として過去の状態を記録することができるため\n","- 一方で、RNN、LSTMは学習時間が長く大きなモデルを構築するのが困難であった\n","  - 文章の単語を1stepに1単語ずつモデルに投入するため、バッチにより並列的に大量に処理できるCNNと異なり時間がかかる\n","\n","処理速度を稼ぐため、CNNやFCを利用する試みもなされた\n","- 処理速度は向上するが、やはり文章の離れた単語間の関係性を考慮できないため、精度の向上が困難であった\n","  - 主語と述語は文章の最初と最後であり、この主述関係を理解しようとするとCNNや勾配消失の大きいRNNでは困難であることは容易に想像できる\n","\n","RNNとは全く異なるアプローチ\n","- TransformerではEncoderおよびDecoderのいずれにもRNNのような再帰構造をもたず、Attentionが利用されている\n","- その優れた特徴から、自然言語処理以外の分野でも利用が進む"],"metadata":{"id":"rVw9AeeL5sI2"}},{"cell_type":"markdown","metadata":{"id":"Zd4rO-jl1Xe4"},"source":["# Transformer\n","- 2017年に導入されたディープラーニングモデルの一種\n","  - 主に自然言語処理で利用されている\n","- RNNと同様自然言語などの時系列データ処理向けに設計されているが、再帰や畳み込みは利用していない\n","- Attention層のみで構築されている(後述)\n","- 翻訳やテキスト要約などの各種タスクに利用可能\n","- 並列化が容易で訓練時間を削減できる\n","- 「Attention is All You Need」という論文で著名になった\n","- 機械翻訳タスクにおいてRNNを用いたモデルよりも精度がよく、訓練コストが小さいことから革命的であり、NLPではRNNに印籠を渡し現在の主流の方法である\n","  - この後登場するBERT、ELECTRA、GPTなどすべてTransformerを基本としている\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_ku4J5yu4iy0"},"source":["### Transformerの構造\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/transformer.png\" width=500>\n","\n","Seq2Seq同様EncoderとDecoderで構成\n","\n"]},{"cell_type":"markdown","source":["#### Encoderの構造\n","\n","文章から意味ベクトルを抽出する\n","\n","1. Embedding層により入力文章をベクトルに圧縮、つまり分散表現に変換する\n","1. Positional Encoder層で文章内のどこにあるかという位置情報を加える\n","1. Multi-Head Attention層\n","  - 最も本質的かつ重要な層\n","1. normalization(正規化)によりデータの偏りを削減する\n","  - batch normalizationではなくlayer normalizationが行なわれる\n","  - Add & Normで学習速度を高めている\n","1. Feed Forward層\n","  - 2層で活性化関数はReLU\n","\n","以上のMulti-Head AttentionからFeed Forward、Add&Normまでを1セットとして、実際のモデルでは例えば6セット繰り返される\n","  - 出力されたベクトルはDecoderに渡される\n","  - 特にPositionwise fully connected feed-forward networkと呼ばれる\n","\n","n文字入ると、Multi-Head Attentionはn入力について以外はn並列で処理している\n","\n","以上で、Encoderが構成される\n","\n","なお、文字は512次元でベクトル化される"],"metadata":{"id":"UF2mhLBJgGhi"}},{"cell_type":"markdown","source":["#### Decoderの構造\n","\n","抽出された意味ベクトルから文章を生成する\n","\n","1. Embedding層により入力文章をベクトルに圧縮(分散表現を獲得)\n","1. Positional Encoder層で位置情報を追加\n","1. Masked Multi-Head Attention層、先ほどと同様であるがAttention内のsoftmax関数を通す直前の値にマスキングが適用されている\n","  - 特定のkeyに対して、Attention weightを0にすることで入力した単語の先読みによる「カンニング」を防ぐ\n","  - 入力に予測すべき結果が入らないようにする\n","1. normalization（正規化）などで先ほどと同様\n","1. Multi-Head Attention層（Encoderの出力を入力として使用）\n","1. normalization（正規化）など\n","1. Positionwise fully connected feed-forward network(先ほどと同じ)\n","1. normalization（正規化）など\n","- 例えば、以上を6回繰り返す\n"],"metadata":{"id":"o1skr29TgJck"}},{"cell_type":"markdown","metadata":{"id":"ZCbAQSWygRj8"},"source":["### Transformerの構成要素\n","\n","- Attention\n","  -「文章中のどの単語に注目すればよいかを表すスコア」のこと\n","  - Query、Key、Valueの3つのベクトルで求める\n","    - Query: Inputのうち「検索をかけたいもの」\n","    - Key: 検索対象とQueryの近さ、どれだけ似ているかを測る\n","    - Value: Keyに基づき、適切なValueを出力する\n","  - Self-Attention\n","    - 下図でInputとMemoryが同一のAttention\n","      - 文法の構造や、単語同士の関係性などを獲得するのに使用される\n","  - SourceTarget-Attention\n","    - 下図でInputとMemoryが異なるAttention\n","      - TransformerではDecoderで使用される\n","  - Multi-Head Attention\n","    - Attentionを複数並列して並べたもの(後述)\n","  - Masked Multi-Head Attention\n","    - Multi-Head Attentionにマスクをつけたもの\n","    - 特定の key に対してAttention weight を0にする\n","    - TransformerではDecoderで使われる\n","    - 入力した単語が先読みを防ぐために 情報をマスクで遮断する、言わば「カンニング」を防ぐ\n","  - Attentionは可視化できる\n","    - すでに示したが、attentionは可視化でき、どの単語に注目しているかを知ることができる\n","- Position-wise Fully-connected Feedforward Network\n","  - 2層からなる全結合ニューラルネットワーク\n","  - 単語の位置ごとに個別の順伝播ネットワークとなる\n","    - これにより他単語との影響関係を排除することができる\n","  - パラメータは全てのネットワークで共通\n","$FNN(x) = ReLU(xW_1+b_1)\\cdot W_2+b_2$\n","- Positional Encoding ($PE$)\n","  - 「単語の位置」の情報をベクトルに加える\n","    - 本当に加えるだけで次元を増やさない\n","  - $pos$は位置を表し、$2i$および$2i+1$はEmbeddingの何番目の次元か、$d_{model}$が次元数を示す\n","偶数番目：$PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})$\n","奇数番目：$ PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})$"]},{"cell_type":"markdown","metadata":{"id":"Qqqr2QeuiwaR"},"source":["<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/attention2.png\" width=800>\n","\n","- 丸角(緑)がベクトル(テンソル)、四角角(青)が処理を表す\n","- **InputとMemoryはそれぞれ異なる埋め込みベクトルを表し、例えば2つの異なる文章を表す**\n","- Inputについて全結合層で各単語のQueryを作成する\n","- Memoryについても同様に全結合層でKeyを作成しQueryとの内積をとって関連度合い見る\n","  - 同じ向きを向いていれば掛け算となる\n","  - 垂直である、つまり関連しなければ0\n","  - この値を関連度(logit)とする\n","- logitにSoftmaxを適用して0から1の間に調整して出力、この結果が Attention weightとなる\n","  - メモリのどの単語に注意を払うかの重みづけ\n","  - QueryとKeyの関連が大きいとAttention weightが大きくなる\n","    - 正しくMemoryの単語に注意を向けるように,keyが正しくAttentionに向けられるように学習される\n","- Memoryから全結合層を経て、Memoryの各単語に対する埋め込みベクトルであるValueを算出する\n","  - ValueとAttention weightとの内積を求める\n","    - Attention weightに従ってValueを選択することを意味する\n","- 最後に全結合層を挟んで出力を得る\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SUEwYu73qKFn"},"source":["### InputとMemory\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/input-memory.png\" width=600>\n","\n","各文章は分かち書きされIDで表現された後、Embeddingにより埋め込みベクトルに変換される\n","\n","### Attention Weightの算出\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/attention-weight.png\" width=600>\n","\n","QueryとKeyの内積を算出してInputとMemoryの各単語の関連度であるlogitを算出、Softmaxを用いてAttention weightとする\n","- Memoryのどの単語に注意を払うかの重み付け\n","\n","例えば、Inputのスポーツという単語に対して、Memoryの「野球」 「が」 「得意」の各単語について正しく注意を向けるように学習する\n","- ここでは野球が高い値になるようになる\n","\n","### valueとの内積\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/value-naiseki.png\" width=600>\n","\n","この内積は、value、ここでは「野球」「が」「得意」の各単語のValueとAttention weightを掛け合わせて総和を計算することになる\n","\n","最も注目するべきvalueの値が算出されているといえるが、他の単語との関連性も考慮した値となっている"]},{"cell_type":"markdown","metadata":{"id":"ooi7J-rSvL7e"},"source":["### Multi-Head Attention\n","\n","Multi-Head Attentionの構成要素は次のような図で表現されるが、これはこれまでの説明で理解できるであろう\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/mhattention.jpg\" width=200>\n","\n","ここで、Transformerでも用いられるMulti-Head Attentionでは、この図のように$Q$、$K$、$V$に同じ入力$X$を与えている\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/transformer-mha.png\" width=200>\n","\n","- 実際にTransformerの構造図を見るとわかる\n","- Queryつまり入力に$X$を与えるのは理解できるが、$K$にも$V$にも入れるのは、意味不明に感じるであろう\n","\n","だが、先に示したMulti-Head Attentionの説明の通り、再掲すると、\n","\n",">数式では次のように表すことができる\n",">\n",">$$MHA(Q, K, V) = concat(head_i)W^O$$\n",">\n",">ここで\n",">\n",">$$head_i=Attention(QW^Q_i, KW^K_i, VW^V_i)$$\n",">\n",">である\n",">\n",">Q, K, Wに対して、$W^Q_i$, $W^K_i$, $W^V_i$という重み行列を掛けて、Attentionを求め、さらに$W^O$という重み行列を掛けて、行列を1次元ベクトルに変換するといった動作となる\n",">\n",">例えば、Transformerでは、$W^Q_i$, $W^K_i$, $W^V_i$は一般に8次元であり、入力列を8個の列に重みを掛けて拡張し、それに対してAttentionを求め、さらに一列にするという動作である\n","\n","つまり、$W^Q_i$, $W^K_i$, $W^V_i$という重み行列を掛けており、この重み行列で表されるアファイン変換によりXをねじって曲げたベクトルとの比較を行っていると考えることができる\n","- Transformerでは$W^Q_i$, $W^K_i$, $W^V_i$という重み行列を掛けることで、大きさが$1/8$になった8個のベクトルに変換され、それぞれで計算して、最後にconcatで1つに戻すといった処理が行われており、8個に分割したそれぞれについて、アファイン変換を行い、それらの類似度に合った値を生成して、最後に結合するといった処理を行っている\n","- Xについて、8分割したどの部分をどのように変換したベクトルと、どの部分をどのように変換したベクトルがどの程度一致したら、どの部分で表されるどのような値を出力しなさい、といった表現になる"]},{"cell_type":"markdown","source":["## DecoderにおけるAttention\n","\n"],"metadata":{"id":"c7Y-69bZ9TI_"}},{"cell_type":"markdown","source":["次のような入力形態となっている\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/transformer-mha-dec.png\" width=200>\n","\n","$V$と$K$はEncoderからの入力で、$Q$はDecoderの入力からきている\n","\n","翻訳では、$V$と$K$に元の言語の文章A、$Q$に翻訳先の言語の文章Bを入力して、AとBの類似度を得る、さらにAから作った値を返す、という意味になる"],"metadata":{"id":"iiPxmugjRojs"}},{"cell_type":"markdown","source":["## Positional Encoding\n","\n","Postional Encoding層は、系列データ内の各要素に、要素のデータ内における位置情報を付与する\n","- 文章の場合、Positional Encodingによって、各単語ベクトルに、その単語が文章内で何番目に登場するかという情報を付与する\n","\n","次の式で算出した値を固定値として、入力に加算する\n","\n","$PE_{(pos,2i)} = sin(pos/10000^{2i/d_{model}})$\n","\n","$PE_{(pos,2i+1)} = cos(pos/10000^{2i/d_{model}})$\n","\n","このPositional Encodingの値を図示すると次のようになる\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/pos_encoding.png\" width=400>\n"],"metadata":{"id":"imYDkjsFTgPT"}},{"cell_type":"markdown","source":["## Transformerにおいて交換されるデータの形\n","\n","何が入ってきて何が出ていくのか\n","\n","Transformerでは、常に$単語数 \\times 埋め込み次元数$で与えられるテンソルが各ブロック間で受け渡される\n","\n","例外もあり、\n","- embedding層の前では各行が語彙数次元のone-hotベクトルとなっている\n","- 最後の出力では語彙数次元の確率分布ベクトルとなっている\n","\n","であるが、Transformerブロック内では、$単語数 \\times 埋め込み次元数$の行列の各行に各種変換を施すという処理が繰り返される\n","- この処理は各行独立という意味ではなく、例えばSelf-Attentionでは行と単語の関係に注目している\n","\n","また、Transformerでは、RNNの隠れ状態のような文脈ベクトル、つまり文意を1つのベクトルで表した潜在空間表現の類を明確に生成していない\n"],"metadata":{"id":"wCDnsBsGR2Cv"}},{"cell_type":"markdown","source":["## Transformerの出力\n","\n","Transformer において各層から得られる出力ベクトルは、しばしば「embedding」と呼ばれることがあるが、厳密には Transformer の出力は文字（あるいはトークン）そのものの embedding ではない。この点を正確に理解することは、Transformer の動作原理や表現能力を理解する上で極めて重要\n","\n","\n"],"metadata":{"id":"XLRbQWEazFAa"}},{"cell_type":"markdown","source":["### まず「embedding」とは何か\n","\n","一般に embedding とは、離散的な記号（文字・単語・トークンなど）をそれ自体の意味を表す連続値ベクトルに写像したものを指す\n","\n","embedding層がpytorchにはあるが、内容はハッシュテーブルであり、ハッシュの各エントリを学習するように構成される\n","- クラス分類などワンホットかつ大量にあるときに計算コストを削減する手法として利用される\n","- なお、FC層を使ったembeddingもあるが、これは一般的な数値入力に対して実施する\n","\n","Transformer における 入力 embedding は典型例であり、各トークンIDに対して学習可能な固定のベクトルが割り当てられる\n","\n","この embedding は、文脈に依存せず、同じトークンであれば、どこに現れても同じベクトルという性質を持つ"],"metadata":{"id":"xHFGSsrGzbrA"}},{"cell_type":"markdown","source":["### Transformerの出力は何を表しているのか\n","\n","Transformer の各層の出力は、次の処理を経て得られる\n","- 入力 embedding + 位置情報\n","- Self-Attention による情報混合\n","- Feed Forward Network による非線形変換\n","- 残差接続・正規化\n","\n","ここで重要なのは、Self-Attention の存在である\n","\n","- Self-Attention により、各位置のベクトルは\n","- 「そのトークン自身」＋「文中の他のトークンから集約された情報」\n","\n","の混合表現になることから、Transformer の出力ベクトルは、「この位置にあるトークンが、この文脈の中で果たしている役割」を表す 文脈依存表現（contextualized representation） である"],"metadata":{"id":"buA8zGKn0AGu"}},{"cell_type":"markdown","source":["### 同じ文字でも出力が変わるという決定的な違い\n","\n","ここが embedding と Transformer 出力の本質的な違い\n","\n","- 入力 embeddingは同じトークンなら常に同じベクトル\n","- Transformer の出力は同じトークンでも、文脈が違えば全く異なるベクトル\n","\n","つまり、トークンそのものの embeddingではなく文脈を反映した状態表現である"],"metadata":{"id":"_s_PNgcg0UPC"}},{"cell_type":"markdown","source":["### 実際はどうなっているのか\n","\n"],"metadata":{"id":"JRuCSVAa1Abn"}},{"cell_type":"markdown","source":["以下は「1024次元・語彙1万」という具体条件で、“出力＝埋め込み”の誤解がどこで生まれるかを、形状（テンソルの次元）と計算で潰す説明です。数式は最小限ですが、計算の流れは具体的に書きます。\n","\n","#### 前提（この例で固定する設定）\n","\n","- 語彙数（トークン種類数）: $V=10000$\n","- 埋め込み次元: $d_{model}=1024$\n","- 入力系列長: L=128\n","- 1層の self-attention（multi-head でも同じ)\n","- バッチは1として説明（バッチ次元は省略）\n","\n","###「入力埋め込み」は $10000\\times1024$ の表\n","\n","学習パラメータとして\n","\n","$$E \\in \\mathbb{R}^{V\\times d_{model}}=\\mathbb{R}^{10000\\times 1024}$$\n","\n","がある\n","\n","トークンID $t \\in \\{1,…,10000\\}$ に対し、入力埋め込みは\n","\n","$$x=E[t] \\in \\mathbb{R}^{1024}$$\n","\n","つまり語彙表の中から一つとってくるだけである\n","\n","系列長 $L$ の入力なら、\n","\n","$$X \\in \\mathbb{R}^{L\\times 1024}$$\n","\n","が入力となる\n","\n","また、位置埋め込み等を加算しても形状は同じである"],"metadata":{"id":"RJ4UOOwG1LMH"}},{"cell_type":"markdown","source":["#### Self-Attentionの内部計算（形状つき）\n","\n","Transformer層は、入力 $X$ から次を作る\n","\n","(a) Q, K, V の線形変換\n","\n","学習パラメータ\n","$$W_Q, W_K, W_V \\in \\mathbb{R}^{1024\\times 1024}$$\n","として、\n","$$Q=XW_Q, K=XW_K, V=XW_V$$\n","を求め、形状はすべて、\n","$$Q, K, V \\in \\mathbb{R}^{L\\times 1024}$$\n","である\n","\n","つまり、この時点で入力埋め込みの値ではなくなる\n","- $W_Q$などにより、埋め込み空間が別の基底に写され、混ざる\n"],"metadata":{"id":"eCtgNfDY3tSG"}},{"cell_type":"markdown","source":["(b) 注意（attention）重み\n","\n","スコア行列\n","$$S=\\frac{QK^\\mathsf{T}}{1024}$$\n","であり、その形状は\n","$$S \\in \\mathbb{R}^{L\\times L}$$\n","である\n","\n","softmax を各行にかけると、\n","$$ A = softmax(S) \\in \\mathbb{R}^{L\\times L}$$\n","となる"],"metadata":{"id":"rZmKymFm4-4K"}},{"cell_type":"markdown","source":["(c) 出力（文脈混合）\n","\n","$$Y =AV$$\n","であり、形状は\n","$$ Y \\in \\mathbb{R}^{L\\times 1024}$$\n","\n","この $Y$ の各行 $y_i \\in \\mathbb{R}^{1024}$は\n","\t​\n","$$ y_i = \\sum^L_{j=1} A_{ij}v_j$$\n","\n","つまり、位置$i$の出力は、系列中の全位置の$v_j$の重み付き和であり、トークン$t_i$の埋め込み$E[t_i]$ ではない\n","\n","同じトークンでも周囲が違えば$A_{ij}$ が変わるので、出力は変わる"],"metadata":{"id":"rlCMU0gV5qfj"}},{"cell_type":"markdown","source":["#### 出力の形状\n","\n","出力は、$L \\times 1024$のベクトルであり、各要素は入力の文字埋め込みではない\n","\n","次トークン予測をする言語モデルでは、最後に語彙へ写像する必要があるため、これを語彙に戻さなければならない\n","\n","出力$y$の$i$番目の要素を$y_i$とし、語彙$W_{out} \\in \\mathbb{R}^{1024 \\times 10000}$があった時、\n","\n","なお、出力の単語埋め込み$W_{out}$は、入力の単語埋め込み$W_{in}$と一般的に同じであるが、違ってもかまわない\n","\n","言語モデルにおいて、softmax をかける直前の、生のスコア（未正規化対数尤度）、つまりlogitsは、\n","\n","$$ logits_i = y_iW_{out}+b$$\n","\n","として求まり、その形状は、\n","\n","$$logits \\in \\mathbb{R}^{L\\times 10000}$$\n","となる\n","\n","logitsは確率ではなく、大小関係と差だけが意味を持つ量である\n","\n","これに、softmaxをかけて確率分布として、選択するべき単語の確率を得ることができる"],"metadata":{"id":"JYVsj2mY047e"}},{"cell_type":"markdown","source":["### 学習時と推論時の違い\n","\n","Transformer 言語モデルでは、 **学習時（training）と推論時（inference / generation）** で、\n","同じモデル・同じ計算グラフを使いながらも、出力の使い方が根本的に異なるので注意が必要である\n","\n","- 学習では「全部の出力」を利用\n","- 推論では「一番右（最後）」のみ利用\n","\n","\n"],"metadata":{"id":"oRS1qHvaxs_1"}},{"cell_type":"markdown","metadata":{"id":"7b32cba3"},"source":["#### 学習時：全ての位置の出力を同時に使う（並列）\n","\n","言語モデル学習の典型は **次トークン予測** である\n","\n","$$\n","(x_1, x_2, \\dots, x_L)\n","$$\n","\n","に対して、正解（教師）を\n","$$\n","(x_2, x_3, \\dots, x_{L+1})\n","$$\n","\n","として学習\n","\n","位置 $i$ の出力 $y_i$ は「次トークン $x_{i+1}$」を予測するために利用する\n","\n","学習時は **正解系列が全文分わかっている** ため、位置 $i=1\\dots L$ すべてについて同時に損失を計算できる\n","\n","\n","典型的な損失（平均）：\n","$$\n","\\mathcal{L}\n","= \\frac{1}{L}\n","\\sum_{i=1}^{L}\n","\\mathrm{CrossEntropyLoss}(\\text{logits}_i,\\; x_{i+1})\n","$$\n","\n","この方式は\n","- GPUで **並列化** できる\n","- 収束が速い（teacher forcing）\n","- 学習が安定しやすい  \n","という利点がある\n","\n"]},{"cell_type":"markdown","metadata":{"id":"a92d82c2"},"source":["#### causal mask（未来を見ないための必須条件）\n","自己回帰モデルでは「未来の情報を参照してはいけない」ため、Self-Attention では **causal mask** を利用する\n","\n","- 位置 $i$ は $1\\dots i$ までしか attend できない\n","- $i+1$ 以降はマスクされる\n","\n","このため、学習時に「全位置の損失を同時に計算していても」、\n","各位置の予測は **未来を見ずに** 行われる"]},{"cell_type":"markdown","metadata":{"id":"8cdc4c2b"},"source":["### 推論時：最右端（最後）の出力だけを使う（逐次生成）\n","\n","推論（生成）では、次に来るトークンは未知であるため、次の処理を繰り返す\n","\n","1. 現在の系列 $(x_1,\\dots,x_t)$ を入力  \n","1. forward で $\\text{logits}\\in\\mathbb{R}^{t\\times V}$ を得る  \n","1. **最後の位置**の logits $\\text{logits}_t$ から次トークン $x_{t+1}$ を選ぶ（argmax / sampling）  \n","1. それを系列に追加して繰り返す\n","\n","このとき意味を持つのは常に **最右端**の出力のみ\n","\n","学習は本質的に\n","$$\n","p(x_{i+1}\\mid x_{\\le i})\n","$$\n","を各位置で学ぶように設計されます。よって推論時には\n","$$\n","p(x_{t+1}\\mid x_{\\le t})\n","$$\n","が欲しいので、位置 $t$ の出力（最右端）だけを使えば十分である\n","\n","過去の位置 $1\\dots t-1$ の logits は「過去の次トークン」を予測するためのもので、  \n","現在の次トークン生成には不要となる\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2be8dbad"},"source":["### 学習で使われるロス関数：Cross-Entropy（最大尤度）\n","\n","各位置 $i$ での正解トークンを $t^*=x_{i+1}$ とすると\n","\n","$$\n","\\mathrm{CE}_i = -\\log p(t^*\\mid x_{\\le i})\n","$$\n","\n","logits（softmax前）で書くと\n","\n","$$\n","\\mathrm{CE}_i =\n","-\\text{logits}_i[t^*]\n","+ \\log\\sum_{t'} e^{\\text{logits}_i[t']}\n","$$\n","\n","実装では数値安定性のため、`softmax` を明示せず logits を直接入力に取る loss（例：PyTorchの `CrossEntropyLoss`）を使うのが一般的である\n","\n","なお、言語モデル評価でよく使う perplexity は、平均 cross-entropy を指数化した値であり（対数底や単位に注意）、概念的にはcross-entropy が小さいほど perplexity も小さい（良いモデル）といえる\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3d995a33"},"source":["### 学習時に特別にケアすべきこと\n","#### Teacher forcing と exposure bias\n","\n","学習では、モデル出力ではなく **正解トークンを次入力に使う（teacher forcing）** のが基本\n","- これにより学習は安定しますが、推論時（モデル自身の出力を入力に回す）とのギャップが生じることがあり、これを **exposure bias** と呼ぶ\n","- 対策例として scheduled sampling などがありますが、設計・評価が必要となる\n","\n","#### Padding と loss mask（必須）\n","バッチ学習では系列長が揃わないため padding を入れます。  \n","このとき\n","- padding トークンに対しては損失を **計算しない（無視する）** (必須)\n","- これを行わない場合、モデルは「paddingを当てる」ことを学習し、学習が壊れる\n","\n","#### ラベルスムージング（場合によって有効）\n","正解を one-hot（確率1）で固定せず、少量の確率質量を他クラスにも配ることで、\n","- 過信（過度な確率集中）を抑える\n","- 汎化性能が改善する  \n","場合がある\n","\n","ただし、タスクや評価指標によっては逆効果もあるため検証が必要\n","\n","#### 温度（temperature）は通常「推論時」に利用する\n","\n","温度 $T$ は softmax に入る logits のスケール因子：\n","\n","$$\n","p(t) \\propto \\exp(\\text{logits}[t]/T)\n","$$\n","\n","推論時には多様性と破綻のバランス調整に有効であるが、\n","学習時に温度を入れると「学習目標の分布」が変わるため、原則として $T=1$ で学習する\n","\n","例外として、知識蒸留（distillation）では教師分布を平坦化する目的で $T>1$ を学習中に用いることがある\n","\n"]},{"cell_type":"markdown","metadata":{"id":"503f062f"},"source":["# Softmax・logitsと温度（temperature）\n","\n","Transformer/言語モデルでよく出てくる **logits → softmax → 確率** の流れに対して、  **温度（temperature, $T$）がどこに入り、何を変えるのか**を確認する\n","\n","また、推論時の代表的なサンプリング手法（top-k / top-p）や、attentionのスケーリングとの関係、知識蒸留での温度の意味に触れる\n","\n","## 前提（記号）\n","- 語彙数：$V$\n","- logits：$z \\in \\mathbb{R}^V$\n","- softmax：$p = \\mathrm{softmax}(z)$\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dcf176cc"},"outputs":[],"source":["import numpy as np\n","import math\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"ed738430"},"source":["## softmax（温度なし）\n","softmax は logits $z$ から確率 $p$ を作ります：\n","\n","$$\n","p_i = \\mathrm{softmax}(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^{V} e^{z_j}}\n","$$\n","\n","- logits は **確率ではなくスコア**（未正規化）\n","- softmax を通すことで **確率（合計1）** になる\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a08a2263"},"outputs":[],"source":["def softmax(z):\n","    z = np.asarray(z, dtype=np.float64)\n","    z = z - np.max(z)  # 数値安定化（定数シフトはsoftmaxを変えない）\n","    e = np.exp(z)\n","    return e / np.sum(e)"]},{"cell_type":"markdown","metadata":{"id":"65fe39a5"},"source":["## 温度付き softmax の定義\n","\n","温度 $T>0$ を導入すると：\n","\n","$$\n","p_i(T) = \\frac{e^{z_i/T}}{\\sum_{j=1}^{V} e^{z_j/T}}\n","$$\n","\n","**温度は logits を $1/T$ 倍する**のと同じ\n","- $T < 1$：差が強調されて分布が **鋭く**（より確信的）\n","- $T > 1$：差が圧縮されて分布が **平坦に**（多様性増）\n","\n","極限：\n","- $T \\to 0$：argmax に近づく（ほぼ一択）\n","- $T \\to \\infty$：一様分布に近づく\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"006c2965"},"outputs":[],"source":["def softmax_temperature(z, T):\n","    z = np.asarray(z, dtype=np.float64)\n","    if T <= 0:\n","        raise ValueError(\"Temperature T must be > 0.\")\n","    return softmax(z / T)"]},{"cell_type":"markdown","metadata":{"id":"7cb0d4b3"},"source":["## 数値例\n","例として logits を\n","\n","$$\n","z = [10,\\ 9,\\ 1]\n","$$\n","\n","とします。温度を変えて確率を見比べます。\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2607a34f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768455602888,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"494827e1-4a79-4aa0-9077-eb7692ea8a96"},"outputs":[{"output_type":"stream","name":"stdout","text":["T=0.5: p=[8.80797066e-01 1.19202920e-01 1.34145215e-08] (sum=1.000000)\n","T=1.0: p=[7.30992629e-01 2.68917160e-01 9.02116571e-05] (sum=1.000000)\n","T=2.0: p=[0.61818465 0.37494794 0.00686741] (sum=1.000000)\n"]}],"source":["z = np.array([10.0, 9.0, 1.0])\n","for T in [0.5, 1.0, 2.0]:\n","    p = softmax_temperature(z, T)\n","    print(f\"T={T}: p={p} (sum={p.sum():.6f})\")"]},{"cell_type":"markdown","metadata":{"id":"6e5bf74b"},"source":["## 温度が分布の「鋭さ」をどう変えるか\n","同じ logits に対して、温度 $T$ を連続的に変えると確率がどう動くかをプロット"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a0f98262","colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"status":"ok","timestamp":1768455603127,"user_tz":-540,"elapsed":238,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"e62d1f18-db76-4ebc-dba3-bc3b4c8f72d6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAdeVJREFUeJzt3Xd4U+X/PvA7SZN0L7oHbdllFShQCjJUsAwRRAUBZVhQFHBUPgpf2Y66EFCWioADpAgoPwVFKGUvoSxltrRQoJvulTZ5fn+kDQ3dMx3367pyJefJOSfvnKTt3ec85xyJEEKAiIiIqImQGroAIiIiotrEcENERERNCsMNERERNSkMN0RERNSkMNwQERFRk8JwQ0RERE0Kww0RERE1KQw3RERE1KQw3BAREVGTwnBDyMzMxLRp0+Dk5ASJRII333wTABAfH49nn30WLVq0gEQiwYoVKwxaZ1WU9Z6IDOmff/5B3759YWZmBolEgvPnzxu6pEZl0KBB6Ny5c62tLzo6GhKJBJ9//nmF8y5evBgSiUSvzdPTE1OmTNFNHzx4EBKJBAcPHqz0a2/atKmKVVNlGBm6AKobmzZtwtSpU8t8/sSJE+jTpw8A4KOPPsKmTZuwYMECtG7dGt7e3gCAt956C3v37sWiRYvg5OSEnj171nqdH330ETp27IjRo0fX+npLe0/1WUNjd+/ePXzzzTcYPXo0unXrZuhyGr38/Hw899xzMDY2xvLly2FqagoPDw+sWbMGpqamen8kqenYsmULEhIS+A9WPZPw2lJNU1G4Wbp0Kby8vEo8P3ToUNjZ2QEA+vTpAyMjIxw9elRvHicnJwwePBg//fRTndVpbm6OZ599ttb/eynrPdVnDY3dmTNn0KtXL2zcuJF/eGvB1atX4e3tjW+//RbTpk3TtXfu3Bl2dnaV+m+/uRs0aBCSkpLw77//1sr6oqOj4eXlhc8++wxz5swpd96CggIUFBTA2NhY1+bp6YlBgwbpfndoNBqoVCooFApIpdodI08++ST+/fdfREdH661PCIG8vDzI5XLIZLJaeT/0AHtumrhhw4ZV2OOSkJCAjh07ltpubW1dR5XVrbLeU3OWm5ur90u3uddR3xISEgCg0f5M1YWsrCyYmZkZuoxKMTIygpFR+X8ypVKpXvgpj0QiqfS8VA2CmqSNGzcKAOKff/4pc56wsDABoMStaNmHb0VSUlLEG2+8Idzc3IRCoRCtW7cWH3/8sVCr1XrrV6vVYsWKFaJz585CqVQKOzs7ERAQoKuptNeYPHlyue8rPj5evPTSS8LBwUEolUrRtWtXsWnTpgrfU1RUVKnrq6iGO3fuiKlTpwoHBwehUChEx44dxXfffVfqdgwJCRGLFy8WLi4uwtzcXDzzzDMiNTVV5ObmijfeeEPY29sLMzMzMWXKFJGbm1uijpkzZ4qffvpJtGvXTiiVStGjRw9x6NChEjVXpaaff/5ZvPfee8LFxUVIJBKRkpIikpOTxdtvvy06d+4szMzMhIWFhRg6dKg4f/58hdtx48aNQgghPDw8Sv2sBg4cKAYOHFipOoQQ4uTJkyIgIEBYWloKExMTMWDAAHH06NFSP6uHVfRdEEKIqKgoAUB89tln4uuvvxatWrUSCoVC9OzZU5w+fbrC11CpVGLx4sWiTZs2QqlUCltbW9GvXz/x999/680XGhoqHnnkEWFqaiqsrKzEU089JS5fvqx7fvLkySW25cCBA4WHh0ep7UI8+Bk+cuSImD17trCzsxNWVlbi5ZdfFnl5eSIlJUW8+OKLwtraWlhbW4v//e9/QqPR6NX12WefCX9/f2FrayuMjY1Fjx49xC+//KI3z4YNGwSAEt+hDz/8UAAQu3fvLncbeXh4iBEjRoi9e/cKHx8foVQqhbe3t9ixY4fefEXv5+DBg+LVV18V9vb2wtraWvf86tWrRceOHYVCoRDOzs7itdde031PigwcOFB06tRJnDlzRvj7+wtjY2Ph6ekp1q5dqzdfXl6eWLBggejRo4ewtLQUpqam4pFHHhEHDhzQm6/49+OLL74QLVu2FMbGxmLAgAHi0qVLevMuWrRI7/dg0Xsv/nNQ9H0PCwvT1fvw5+vh4aH32kU/U0WuXLkinnnmGWFjYyOUSqXw9fUVu3bt0punst/L5ow9N01cWloakpKS9NokEglatGgBb29v/Pjjj3jrrbfg5uaGt99+GwDQvXt3/Pjjj3jxxRcxZMgQTJo0SbdsdnY2Bg4ciLt37+KVV15By5Ytcfz4ccybNw+xsbF6g44DAwOxadMmDBs2DNOmTUNBQQGOHDmCkydPomfPnvjxxx8xbdo09O7dGy+//DIAoHXr1mW+l5ycHAwaNAgRERGYNWsWvLy88Msvv2DKlClITU3FG2+8UeZ7sre3L3Wd5dUQHx+PPn36QCKRYNasWbC3t8eff/6JwMBApKenl9iHHhwcDBMTE8ydOxcRERH46quvIJfLIZVKkZKSgsWLF+PkyZPYtGkTvLy8sHDhQr3lDx06hJCQELz++utQKpVYs2YNhg4ditOnT+sGUVa1pvfffx8KhQJz5sxBXl4eFAoFLl++jN9++w3PPfccvLy8EB8fj6+//hoDBw7E5cuX4eLiAm9vbyxduhQLFy7Eyy+/jP79+wMA+vbtW+bnU57S6jhw4ACGDRsGX19fLFq0CFKpFBs3bsRjjz2GI0eOoHfv3mWurzLfheK2bNmCjIwMvPLKK5BIJPj0008xZswY3Lx5E3K5vMzXWbx4MYKDg3XfkfT0dJw5cwbh4eEYMmQIAGD//v0YNmwYWrVqhcWLFyMnJwdfffUV+vXrh/DwcHh6euKVV16Bq6srPvroI7z++uvo1asXHB0dkZWVhdmzZ8Pc3BzvvfceAMDR0VGvhtmzZ8PJyQlLlizByZMn8c0338Da2hrHjx9Hy5Yt8dFHH2HPnj347LPP0LlzZ72f15UrV+Kpp57CxIkToVKpsHXrVjz33HP4448/MGLECADA1KlTsXPnTgQFBWHIkCFwd3fHpUuXsGTJEgQGBmL48OEVfr43btzAuHHjMGPGDEyePBkbN27Ec889h7/++ku3nYq89tprsLe3x8KFC5GVlaXbzkuWLMHgwYPx6quv4tq1a1i7di3++ecfHDt2TO8zSklJwfDhwzF27FiMHz8e27Ztw6uvvgqFQoGXXnoJAJCeno7169dj/PjxmD59OjIyMvDdd98hICAAp0+fLjGG7IcffkBGRgZmzpyJ3NxcrFy5Eo899hguXbpU4vOoivfeew9paWm4c+cOli9fDkC7G7ws//33H/r16wdXV1fMnTsXZmZm2LZtG0aPHo0dO3bg6aef1m2vir6XzZ6h0xXVjbJ6XwAIpVKpN2/Rf14PQ2FvQnHvv/++MDMzE9evX9drnzt3rpDJZOL27dtCCCEOHDggAIjXX3+9xHqL/3dpZmZWYW9NkRUrVggA4qefftK1qVQq4e/vL8zNzUV6enqF76k0ZdUQGBgonJ2dRVJSkl77888/L6ysrER2drYQ4sF/a507dxYqlUo33/jx44VEIhHDhg3TW97f31/331uRos/mzJkzurZbt24JY2Nj8fTTT1e7platWunaiuTm5pboZYuKihJKpVIsXbpU1/bPP/+U+p+lEFXvuXm4Do1GI9q2bSsCAgL0vg/Z2dnCy8tLDBkypMS6i6vsd6Hov+MWLVqI+/fv6+bdtWuXACB+//33cl/Hx8enwu9Rt27dhIODg0hOTta1XbhwQUilUjFp0qQS2+LhnpNOnTrpbbMiRT/DD28jf39/IZFIxIwZM3RtBQUFws3NrcR6Hv7sVSqV6Ny5s3jsscf02mNjY4Wtra0YMmSIyMvLE927dxctW7YUaWlp5b53IYSu96l4T01aWppwdnYW3bt3L/F+HnnkEVFQUKBrT0hIEAqFQjzxxBN638tVq1YJAGLDhg26tqKekGXLluna8vLydJ9B0c9fQUGByMvL06szJSVFODo6ipdeeknXVvT9MDExEXfu3NG1nzp1SgAQb731lq6tOj03QggxYsSIEj/vxV+7+M/X448/Lrp06aLXs6vRaETfvn1F27ZtdW2V+V42d81rp3cztHr1auzbt0/v9ueff1Z7fb/88gv69+8PGxsbJCUl6W6DBw+GWq3G4cOHAQA7duyARCLBokWLSqzj4cMpK2vPnj1wcnLC+PHjdW1yuRyvv/46MjMzcejQoeq9qVIIIbBjxw6MHDkSQgi99xoQEIC0tDSEh4frLTNp0iS9/zD9/PwghND9N1m8PSYmBgUFBXrt/v7+8PX11U23bNkSo0aNwt69e6FWq6tV0+TJk2FiYqLXplQqdeNd1Go1kpOTYW5ujvbt25dYvrY8XMf58+dx48YNTJgwAcnJybr3kZWVhccffxyHDx+GRqMpc31V/S6MGzcONjY2uuminqibN2+WW7e1tTX+++8/3Lhxo9TnY2Njcf78eUyZMgW2tra69q5du2LIkCHYs2dPueuvjMDAQL2fmaLvVWBgoK5NJpOhZ8+eJd5P8W2ekpKCtLQ09O/fv8Tn7OTkpPtd0b9/f5w/fx4bNmyApaVlpWp0cXHR9SoAgKWlJSZNmoRz584hLi5Ob97p06frDaDdv38/VCoV3nzzTb1xWNOnT4elpSV2796tt7yRkRFeeeUV3bRCocArr7yChIQEnD17Vrc9FAoFAO0g3/v376OgoAA9e/Ys9Ts+evRouLq66qZ79+4NPz+/Wvn8Kuv+/fs4cOAAxo4di4yMDN3PRHJyMgICAnDjxg3cvXsXQMXfS+KA4iavd+/etXoI940bN3Dx4sUyd/MUDZqMjIyEi4uL3i/8mrp16xbatm1bYiBq0WHet27dqrXXSkxMRGpqKr755ht88803pc5T9F6LtGzZUm/aysoKAODu7l6iXaPRIC0tDS1atNC1t23btsRrtGvXDtnZ2UhMTIRUKq1yTaUdKafRaLBy5UqsWbMGUVFRUKvVuueK11ObHq6j6Jfy5MmTy1wmLS1NL5AUV9XvwsOfTdF6U1JSyq176dKlGDVqFNq1a4fOnTtj6NChePHFF9G1a1e912nfvn2JZb29vbF3794aD5qtyvfq4ffzxx9/4IMPPsD58+eRl5enay/tH4znn38eP/30E3bv3o2XX34Zjz/+eKVrbNOmTYl1tmvXDoD2iCQnJydd+8PfhbK2oUKhQKtWrUp8li4uLiW2Z/HXKjrFxffff49ly5bh6tWryM/PL/P1gbJ/9rZt21bKu60bEREREEJgwYIFWLBgQanzJCQkwNXVtcLvJTHcUBVpNBoMGTIE77zzTqnPF/2SaeyKeg1eeOGFMv8AP/yLpKzDOctqF1U8C0N1anq41wbQntdnwYIFeOmll/D+++/D1tYWUqkUb775Zrm9JcWV1fumVqtLfb8P11H0Op999lmZ59Apb2xCVVX3MxgwYAAiIyOxa9cu/P3331i/fj2WL1+OdevW6R3OXZeq8r0q/n6OHDmCp556CgMGDMCaNWvg7OwMuVyOjRs3YsuWLSWWTU5OxpkzZwAAly9fhkajqZMj2kr7Tta2n376CVOmTMHo0aPxv//9Dw4ODpDJZAgODkZkZGSdv351FP1MzJkzBwEBAaXO06ZNGwAN43vZ0DHcUJW0bt0amZmZGDx4cIXz7d27F/fv3y+396Yqu6g8PDxw8eLFEr90r169qnu+Okqrwd7eHhYWFlCr1RW+19pSWhfz9evXYWpqquspq42atm/fjkcffRTfffedXntqaqru3EdA+Z+NjY0NUlNTS7TfunULrVq1qrCGokHblpaW1XovdfVdKI2trS2mTp2KqVOnIjMzEwMGDMDixYsxbdo03etcu3atxHJXr16FnZ1dhb021d1NW5EdO3bA2NgYe/fuhVKp1LVv3Lix1PlnzpyJjIwMBAcHY968eVixYgWCgoIq9VpFvQ7F38v169cBaM8FU57i27D4d0elUiEqKqrE9+PevXslesMefq3t27ejVatW2Llzp15Npe0mB8r+2auo9sqo7Odb9N7lcnmlfibK+14SL79AVTR27FicOHECe/fuLfFcamqqbhzJM888AyEElixZUmK+4v9dmpmZlfpHsjTDhw9HXFwcQkJCdG0FBQX46quvYG5ujoEDB1bx3ZRdg0wmwzPPPIMdO3aUesKwxMTEar1WeU6cOKE3HiAmJga7du3CE088AZlMVms1yWSyEj0Wv/zyi25/fpGiPx6lfT6tW7fGyZMnoVKpdG1//PEHYmJiKlWDr68vWrdujc8//xyZmZklnq/ovdTVd+FhycnJetPm5uZo06aNbhePs7MzunXrhu+//15vO/3777/4+++/K3WkUVV+BqpCJpNBIpHo7XaMjo7Gb7/9VmLe7du3IyQkBB9//DHmzp2L559/HvPnz9eFhorcu3cPv/76q246PT0dP/zwA7p166a3S6o0gwcPhkKhwJdffqn3vfzuu++QlpamO6qrSEFBAb7++mvdtEqlwtdffw17e3vdmLWiXq3i6zt16hROnDhRag2//fab3vf/9OnTOHXqFIYNG1bRW6+QmZkZ0tLSKpzPwcEBgwYNwtdff43Y2NgSzxf/majoe0nsuWny/vzzT91/s8X17du3Uv9hP+x///sf/t//+3948sknMWXKFPj6+iIrKwuXLl3C9u3bER0dDTs7Ozz66KN48cUX8eWXX+LGjRsYOnQoNBoNjhw5gkcffRSzZs0CoP0jt3//fnzxxRdwcXGBl5cX/Pz8Sn3tl19+GV9//TWmTJmCs2fPwtPTE9u3b8exY8ewYsUKWFhYVPn9lFfDxx9/jLCwMPj5+WH69Ono2LEj7t+/j/DwcOzfvx/379+v1uuVpXPnzggICNA7FByAXkCsjZqefPJJLF26FFOnTkXfvn1x6dIlbN68ucT3oXXr1rC2tsa6detgYWEBMzMz+Pn5wcvLC9OmTcP27dsxdOhQjB07FpGRkfjpp5/KPZS/OKlUivXr12PYsGHo1KkTpk6dCldXV9y9exdhYWGwtLTE77//XubydfVdeFjHjh0xaNAg+Pr6wtbWFmfOnMH27dt1319Au2tt2LBh8Pf3R2BgoO5QcCsrKyxevLjC1/D19cXatWvxwQcfoE2bNnBwcMBjjz1W49pHjBiBL774AkOHDsWECROQkJCA1atXo02bNrh48aJuvoSEBLz66qt6P5erVq1CWFgYpkyZgqNHj1a4e6pdu3YIDAzEP//8A0dHR2zYsAHx8fFl9hIVZ29vj3nz5mHJkiUYOnQonnrqKVy7dg1r1qxBr1698MILL+jN7+Ligk8++QTR0dFo164dQkJCcP78eXzzzTe6Af1PPvkkdu7ciaeffhojRoxAVFQU1q1bh44dO5Yaptu0aYNHHnkEr776KvLy8rBixQq0aNGizN3vVeHr64uQkBAEBQWhV69eMDc3x8iRI0udd/Xq1XjkkUfQpUsXTJ8+Ha1atUJ8fDxOnDiBO3fu4MKFCwAq971s9ur/AC2qD+UdCo6HDj+syqHgQgiRkZEh5s2bJ9q0aSMUCoWws7MTffv2FZ9//rneodAFBQXis88+Ex06dBAKhULY29uLYcOGibNnz+rmuXr1qhgwYIAwMTGp9En8pk6dKuzs7IRCoRBdunQp81Dlyh4qWV4N8fHxYubMmcLd3V3I5XLh5OQkHn/8cfHNN9/o5inrEN+yTqRYdEhpYmKirq1oW//000+ibdu2QqlUiu7du+sdUlobNQmhPRT87bffFs7OzsLExET069dPnDhxosRh3EJoD5nu2LGjMDIyKvG9WbZsmXB1dRVKpVL069dPnDlzpsxDwUurQwghzp07J8aMGSNatGghlEql8PDwEGPHjhWhoaGlzv/wdqjou1D8JG0PAyAWLVpU7mt88MEHonfv3sLa2lqYmJiIDh06iA8//FDvey6EEPv37xf9+vUTJiYmwtLSUowcOVLvJH7lbYu4uDgxYsQIYWFhUepJ/Crz/RFCe6JAMzMzvbbvvvtO933q0KGD2LhxY4lDmseMGSMsLCxEdHS03rJFh8t/8skn5W6j4ifx69q1q+61KvvzUGTVqlWiQ4cOQi6XC0dHR/Hqq69W6iR+Hh4eYtWqVXrzaTQa8dFHHwkPDw/dz9Iff/whJk+erHdYdvHvx7Jly4S7u7tQKpWif//+4sKFC3rrrO6h4JmZmWLChAnC2tq6Uifxi4yMFJMmTRJOTk5CLpcLV1dX8eSTT4rt27fr5qns97I547WliBoAiUSCmTNnYtWqVYYuhahKPD090blzZ/zxxx+GLoVIh2NuiIiIqElhuCEiIqImheGGiIiImhSOuSEiIqImhT03RERE1KQw3BAREVGT0uxO4qfRaHDv3j1YWFjU2WnPiYiIqHYJIZCRkQEXF5cKTyzZ7MLNvXv3SlxNl4iIiBqHmJgYuLm5lTtPsws3Radlj4mJgaWlpYGrISIiospIT0+Hu7t7pS6v0uzCTdGuKEtLS4YbIiKiRqYyQ0o4oJiIiIiaFIYbIiIialIYboiIiKhJaXZjboiIiIpTq9XIz883dBkEQKFQVHiYd2Uw3BARUbMkhEBcXBxSU1MNXQoVkkql8PLygkKhqNF6GG6IiKhZKgo2Dg4OMDU15YldDazoJLuxsbFo2bJljT4PhhsiImp21Gq1Lti0aNHC0OVQIXt7e9y7dw8FBQWQy+XVXo9BBxQfPnwYI0eOhIuLCyQSCX777bcKlzl48CB69OgBpVKJNm3aYNOmTXVeJxERNS1FY2xMTU0NXAkVV7Q7Sq1W12g9Bg03WVlZ8PHxwerVqys1f1RUFEaMGIFHH30U58+fx5tvvolp06Zh7969dVwpERE1RdwV1bDU1udh0N1Sw4YNw7Bhwyo9/7p16+Dl5YVly5YBALy9vXH06FEsX74cAQEBdVUmERERNSKN6jw3J06cwODBg/XaAgICcOLECQNVRERE1DgMGjQIb775pqHLqBeNKtzExcXB0dFRr83R0RHp6enIyckpdZm8vDykp6fr3YiIiBqrxhZSDDFWtlGFm+oIDg6GlZWV7ubu7l5nr3U8MgmqAk2drZ+IiKgxMdRY2UYVbpycnBAfH6/XFh8fD0tLS5iYmJS6zLx585CWlqa7xcTE1Elt0UlZmPDtKfgHh+KDPy4jIiGjTl6HiIiarylTpuDQoUNYuXIlJBIJJBIJoqOjAQCHDh1C7969oVQq4ezsjLlz56KgoKDMde3evRtWVlbYvHkzACAmJgZjx46FtbU1bG1tMWrUKN26i1579OjR+Pzzz+Hs7IwWLVpg5syZ5Z7dufhYWW9vb8yaNQvPPvssli9fXivboyyN6jw3/v7+2LNnj17bvn374O/vX+YySqUSSqWyrkvD7fvZcLBQIiEjD+uPRmH90Sg82t4eLw9ojT6tbDkin4iogRNCICe/ZocgV5eJXFapvxMrV67E9evX0blzZyxduhSA9twwd+/exfDhwzFlyhT88MMPuHr1KqZPnw5jY2MsXry4xHq2bNmCGTNmYMuWLXjyySeRn5+PgIAA+Pv748iRIzAyMsIHH3yAoUOH4uLFi7pDtMPCwuDs7IywsDBERERg3Lhx6NatG6ZPn15qvWWNla3r3WoGDTeZmZmIiIjQTUdFReH8+fOwtbVFy5YtMW/ePNy9exc//PADAGDGjBlYtWoV3nnnHbz00ks4cOAAtm3bht27dxvqLegMaGeP43Mfw6Hridj6Twz2X4lH2LVEhF1LRJ9WtvhfQAf4etgYukwiIipDTr4aHRca5tQil5cGwFRR8Z9kKysrKBQKmJqawsnJSde+Zs0auLu7Y9WqVZBIJOjQoQPu3buHd999FwsXLtS7XtPq1avx3nvv4ffff8fAgQMBACEhIdBoNFi/fr0uZG3cuBHW1tY4ePAgnnjiCQCAjY0NVq1aBZlMhg4dOmDEiBEIDQ0tM9xUNFa2rL0uNWXQcHPmzBk8+uijuumgoCAAwOTJk7Fp0ybExsbi9u3buue9vLywe/duvPXWW1i5ciXc3Nywfv36BnMYuJFMise9HfG4tyOik7Kw/uhNbPvnDk7evI9n1h7H0E5OmP+kN9xseNIoIiKqPVeuXIG/v79e70+/fv2QmZmJO3fuoGXLlgCA7du3IyEhAceOHUOvXr108164cAERERGwsLDQW29ubi4iIyN10506dYJMJtNNOzs749KlS3X1tqrNoOFm0KBBEEKU+XxpI6oHDRqEc+fO1WFVtcPTzgwfjO6CVwe1wVehN/DL2Tv46784hF1LwOzH2uCVga0hlzWqIU9ERE2aiVyGy0sN88+yiVxW8Uy1oHv37ggPD8eGDRvQs2dPXRjKzMyEr6+vbvxNcfb29rrHD18SQSKRQKMp+0Ca6oyVrQ2NasxNY+RqbYKPn+mKKf08sWjXfzgVdR+f/30de/+Lx7KxPmjnaFHxSoiIqM5JJJJK7RoyNIVCUeLyBN7e3tixYweEELrAcuzYMVhYWMDNzU03X+vWrbFs2TIMGjQIMpkMq1atAgD06NEDISEhcHBwgKWlZa3VWp2xsrWBXQf1pIOTJba+3AfLx/nA0tgIl+6m4ckvj+LrQ5FQa8ruvSIiIirO09MTp06dQnR0NJKSkqDRaPDaa68hJiYGs2fPxtWrV7Fr1y4sWrQIQUFBeuNtAKBdu3YICwvDjh07dAN7J06cCDs7O4waNQpHjhxBVFQUDh48iNdffx137typdq0zZszAzZs38c477+Dq1atYs2YNtm3bhrfeeqsmm6BCDDf1SCKR4OnubtgXNBCPtreHSq1B8J9XMfbrE4i5n23o8oiIqBGYM2cOZDIZOnbsCHt7e9y+fRuurq7Ys2cPTp8+DR8fH8yYMQOBgYGYP39+qeto3749Dhw4gJ9//hlvv/02TE1NcfjwYbRs2RJjxoyBt7c3AgMDkZubW6OenKKxsvv27YOPjw+WLVtWL2NlJaK8QS9NUHp6OqysrJCWllarXW9VJYTAL2fuYOkfl5GZVwBLYyOseL4bHuvgWPHCRERUI7m5uYiKioKXlxeMjY0NXQ4VKu9zqcrfb/bcGIhEIsHYXu7Y+9YAdG9pjfTcAry06Qw+23uVu6mIiIhqgOHGwFytTRDysj+m9PUEAKwOi8SL351CYkaeYQsjIiJqpBhuGgCFkRSLn+qEL8d3h6lChuORyRj51VH8ezfN0KURERE1Ogw3DchTPi7YNbMfWtmbIS49F8+tO4G//o0zdFlERESNCsNNA9PW0QK/vtYP/dvaISdfjRk/ncXag5HlnuyQiIiIHmC4aYCsTOTYOKUXJvl7AAA++esq5vxyEXkFhrmgGxERUWPCcNNAGcmkWDqqM5aO6gSZVIId4XcwZcM/SM8t+9LyRERExHDT4E3y98TGKb1grjTCiZvJGLvuBOLTcw1dFhERUYPFcNMIDGhnj5BX+sDeQomrcRkYs+Y4IhIyDF0WERFRg8Rw00h0crHCzlf7opWdGe6m5uCZtSdw9tZ9Q5dFRESNxKBBg3TXkmrqGG4aEXdbU2x/tS+6t7RGWk4+Jnx7Cn//x0PFiYiak8YUUmJjYzFhwgS0a9cOUqm03upmuGlkbM0U2DKtDwZ7OyCvQIMZP53F5lO3DF0WERFRCXl5ebC3t8f8+fPh4+NTb6/LcNMImShkWPeCL8b3dodGAO/9+i+W77vOc+EQETVxU6ZMwaFDh7By5UpIJBJIJBJER0cDAA4dOoTevXtDqVTC2dkZc+fORUFBQZnr2r17N6ysrLB582YAQExMDMaOHQtra2vY2tpi1KhRunUXvfbo0aPx+eefw9nZGS1atMDMmTORn1/2Ubyenp5YuXIlJk2aBCsrq1rZBpXBcNNIGcmk+OjpLnhzcFsAwMrQG1iw619edJOIqLqEAFRZhrlV8p/TlStXwt/fH9OnT0dsbCxiY2Ph7u6Ou3fvYvjw4ejVqxcuXLiAtWvX4rvvvsMHH3xQ6nq2bNmC8ePHY/PmzZg4cSLy8/MREBAACwsLHDlyBMeOHYO5uTmGDh0KlUqlWy4sLAyRkZEICwvD999/j02bNmHTpk21sfVrlZGhC6Dqk0gkeHNwO9iZK7Fg17/46eRt3M9SYfm4blAayQxdHhFR45KfDXzkYpjX/r97gMKswtmsrKygUChgamoKJycnXfuaNWvg7u6OVatWQSKRoEOHDrh37x7effddLFy4EFLpg76M1atX47333sPvv/+OgQMHAgBCQkKg0Wiwfv16SCQSAMDGjRthbW2NgwcP4oknngAA2NjYYNWqVZDJZOjQoQNGjBiB0NBQTJ8+vTa3Ro0x3DQBL/TxgK2ZAm9uPY89l+KQmv0PvpnUE+ZKfrxERM3BlStX4O/vrwsmANCvXz9kZmbizp07aNmyJQBg+/btSEhIwLFjx9CrVy/dvBcuXEBERAQsLCz01pubm4vIyEjddKdOnSCTPfjn2dnZGZcuXaqrt1Vt/OvXRAzv4gxrEzmm/3AGxyOT8fw3J7Bpam/YmSsNXRoRUeMgN9X2oBjqtetB9+7dER4ejg0bNqBnz566MJSZmQlfX1/d+Jvi7O3tH5Qpl+s9J5FIoNFo6rboamC4aUL6trHD1pf9MWXjafx7Nx3Prj2OHwP94G5bPz80RESNmkRSqV1DhqZQKKBW619r0NvbGzt27IAQQhdYjh07BgsLC7i5uenma926NZYtW4ZBgwZBJpNh1apVAIAePXogJCQEDg4OsLS0rL83U0c4oLiJ6eJmhe2v9oWbjQmik7PxzNrjuBKbbuiyiIiolnh6euLUqVOIjo5GUlISNBoNXnvtNcTExGD27Nm4evUqdu3ahUWLFiEoKEhvvA0AtGvXDmFhYdixY4fuvDMTJ06EnZ0dRo0ahSNHjiAqKgoHDx7E66+/jjt37tSo3vPnz+P8+fPIzMxEYmIizp8/j8uXL9donRVhuGmCvOzMsOPVvujgZIGEjDyM/foETkfxbMZERE3BnDlzIJPJ0LFjR9jb2+P27dtwdXXFnj17cPr0afj4+GDGjBkIDAzE/PnzS11H+/btceDAAfz88894++23YWpqisOHD6Nly5YYM2YMvL29ERgYiNzc3Br35HTv3h3du3fH2bNnsWXLFnTv3h3Dhw+v0TorIhHN7OQo6enpsLKyQlpaWpPoeitPWk4+pn3/D/6JToHSSIpVE3pgSEdHQ5dFRGRwubm5iIqKgpeXF4yNjQ1dDhUq73Opyt9v9tw0YVYmcvwY6Kd3NuNtZ2IMXRYREVGdYrhp4ozl2rMZP+frBrVG4J3tF7HuUCTPZkxERE0Ww00zYCST4tNnu2LGwNYAgI//vIoPd1+BhmczJiKiJojhppmQSCSYO6wD5o/wBgCsPxqFOb9cQL664Z2fgIiIqCYYbpqZaf1b4YuxPjCSSrDz3F28/MMZZKvKvrAaERFRY8Nw0wyN6eGGbyf1hLFcirBriXhh/SmkZqsqXpCIiKgRYLhpph7t4IDN0/rAykSO8NupeG7dCcSm5Ri6LCIiohpjuGnGfD1s8MsMfzhZGuNGQiaeWXMcEQkZhi6LiIioRhhumrl2jhbY8VpftLI3w720XIxZcxzHI5MMXRYREVG1MdwQXK1NsH1GX/T0sEF6bgEmbziNneE1u5YIERE1LIMGDdJdS6qpY7ghAICtmQI/TfPDiK7OyFcLBG27gJX7b/Bkf0REDUxjCik7d+7EkCFDYG9vD0tLS/j7+2Pv3r11/roMN6RjLJfhq+e76072t3z/dcz55SJUBTwXDhERVd3hw4cxZMgQ7NmzB2fPnsWjjz6KkSNH4ty5c3X6ugw3pEcq1Z7s78OnO0MmlWBH+B1M3nAaaTn5hi6NiKjZmzJlCg4dOoSVK1dCIpFAIpEgOjoaAHDo0CH07t0bSqUSzs7OmDt3LgoKyj6P2e7du2FlZYXNmzcDAGJiYjB27FhYW1vD1tYWo0aN0q276LVHjx6Nzz//HM7OzmjRogVmzpyJ/Pyy/z6sWLEC77zzDnr16oW2bdvio48+Qtu2bfH777/XyvYoC8MNlWqinwfWT+4JM4UMJ24m45m1x3E7OdvQZRER1RkhBLLzsw1yq+wQgJUrV8Lf3x/Tp09HbGwsYmNj4e7ujrt372L48OHo1asXLly4gLVr1+K7777DBx98UOp6tmzZgvHjx2Pz5s2YOHEi8vPzERAQAAsLCxw5cgTHjh2Dubk5hg4dCpXqwXnQwsLCEBkZibCwMHz//ffYtGkTNm3aVOltrNFokJGRAVtb20ovUx1Gdbp2atQebe+AbTP88dKmfxCRkIlRq49izURf+LduYejSiIhqXU5BDvy2+BnktU9NOAVTuWmF81lZWUGhUMDU1BROTk669jVr1sDd3R2rVq2CRCJBhw4dcO/ePbz77rtYuHAhpNIHfRmrV6/Ge++9h99//x0DBw4EAISEhECj0WD9+vWQSCQAgI0bN8La2hoHDx7EE088AQCwsbHBqlWrIJPJ0KFDB4wYMQKhoaGYPn16pd7n559/jszMTIwdO7bS26Y62HND5erkYoVdMx9BVzcrpGTn48XvTuGnk7cMXRYRERVz5coV+Pv764IJAPTr1w+ZmZm4c+fB0a/bt2/HW2+9hX379umCDQBcuHABERERsLCwgLm5OczNzWFra4vc3FxERkbq5uvUqRNkMplu2tnZGQkJCZWqccuWLViyZAm2bdsGBweHmrzdCrHnhirkZGWMba/443/bL+L3C/cw/7d/cS0uAwtHdoRcxnxMRE2DiZEJTk04ZbDXrg/du3dHeHg4NmzYgJ49e+rCUGZmJnx9fXXjb4qzt7fXPZbL5XrPSSQSaDQVH3SydetWTJs2Db/88gsGDx5cw3dRMYYbqhRjuQxfPt8NHZws8Nnea/jx5C1EJmZizcQesDZVGLo8IqIak0gkldo1ZGgKhQJqtVqvzdvbGzt27IAQQhdYjh07BgsLC7i5uenma926NZYtW4ZBgwZBJpNh1apVAIAePXogJCQEDg4OsLS0rNV6f/75Z7z00kvYunUrRowYUavrLgv/7aZKk0gkmPloG3zzoi9MFTIcj0zGqNXHeMkGIqJ65OnpiVOnTiE6OhpJSUnQaDR47bXXEBMTg9mzZ+Pq1avYtWsXFi1ahKCgIL3xNgDQrl07hIWFYceOHbrz5UycOBF2dnYYNWoUjhw5gqioKBw8eBCvv/663m6tqtqyZQsmTZqEZcuWwc/PD3FxcYiLi0NaWlpNNkGFGG6oyp7o5ISdr/WFm40JbiVnY/Tq4/jzUqyhyyIiahbmzJkDmUyGjh07wt7eHrdv34arqyv27NmD06dPw8fHBzNmzEBgYCDmz59f6jrat2+PAwcO4Oeff8bbb78NU1NTHD58GC1btsSYMWPg7e2NwMBA5Obm1qgn55tvvkFBQQFmzpwJZ2dn3e2NN96o9jorQyKa2Slo09PTYWVlhbS0tFrvemtukjPz8NrmcJyKug8AeGVAK/wvoD2MOA6HiBq43NxcREVFwcvLC8bGxoYuhwqV97lU5e83/wpRtbUwV+KnaX6Y3t8LAPD14Zt44btTSMzIM3BlRETUnDHcUI3IZVK8N6Ij1kzsATOFDCdv3seTXx3B2Vv3DV0aERE1Uww3VCuGd3HGrlmPoI2DOeLT8zDu65PYdCyKF94kIqJ6x3BDtaaNgzl2zeyHEV2dUaARWPz7Zcz++RzSc3ldKiIiqj8MN1SrzJRGWDW+OxY82REyqQR/XIzFiC+P4HxMqqFLIyIqgb3LDUttfR4MN1TrJBIJAh/xwrZX/OFqbYKY+zl4du1xfH0oEhoNf5EQkeEVnWk3O5sXBG5Iii7SWfwSD9XBQ8GpTqXl5OP/dl7C7sLz4AxoZ49lz/nA3kJp4MqIqLmLjY1FamoqHBwcYGpqqnddJqp/Go0G9+7dg1wuR8uWLUt8HlX5+81wQ3VOCIGt/8Rgye//ITdfAztzJZaP80H/tvYVL0xEVEeEEIiLi0NqaqqhS6FCUqkUXl5eUChKXtaH4aYcDDeGcyM+A7O2nMO1eO3lGqb398LbT7SHsbxm3Y9ERDWhVquRn88DHxoChUJR4nIRRRhuysFwY1i5+Wp8sPsyfjp5GwDQ1sEcX4zthi5uVgaujIiIGjKeoZgaLGO5DB+M7oL1k3rCzlyJGwmZeHrNMazcfwP5ao2hyyMioibA4OFm9erV8PT0hLGxMfz8/HD69Oly51+xYgXat28PExMTuLu746233kJubm49VUu1ZXBHR/z91gAM7+KEAo3A8v3X8cza47zCOBER1ZhBw01ISAiCgoKwaNEihIeHw8fHBwEBAUhISCh1/i1btmDu3LlYtGgRrly5gu+++w4hISH4v//7v3qunGqDrZkCqyf0wMrnu8HS2AgX76RhxJdHsf7ITR4yTkRE1WbQMTd+fn7o1asXVq1aBUB7GJi7uztmz56NuXPnlph/1qxZuHLlCkJDQ3Vtb7/9Nk6dOoWjR49W6jU55qZhikvLxTs7LuLw9UQAgK+HDT4e0wVtHS0MXBkRETUEjWLMjUqlwtmzZzF48OAHxUilGDx4ME6cOFHqMn379sXZs2d1u65u3ryJPXv2YPjw4WW+Tl5eHtLT0/Vu1PA4WRnj+6m98OHTnWGmkOHsrRQM//IIVuy/jrwCtaHLIyKiRsRg4SYpKQlqtRqOjo567Y6OjoiLiyt1mQkTJmDp0qV45JFHIJfL0bp1awwaNKjc3VLBwcGwsrLS3dzd3Wv1fVDtkUgkmOjngX1BAzHY2wH5aoEV+29gxJdHeZVxIiKqNIMPKK6KgwcP4qOPPsKaNWsQHh6OnTt3Yvfu3Xj//ffLXGbevHlIS0vT3WJiYuqxYqoOF2sTfDupJ1ZP6AE7cwUiEjLx7LoTWLjrX2TwIpxERFQBI0O9sJ2dHWQyGeLj4/Xa4+Pj4eTkVOoyCxYswIsvvohp06YBALp06YKsrCy8/PLLeO+990o98Y9SqYRSyVP9NzYSiQQjujqjX5sW+GjPFWw7cwc/nLiFv/+Lx4InO2J4FyeeKp2IiEplsJ4bhUIBX19fvcHBGo0GoaGh8Pf3L3WZ7OzsEgGm6OJazexchM2GtakCnz7rgy3T/ODRwhRx6bmYuSUcL3x3ioeNExFRqQy6WyooKAjffvstvv/+e1y5cgWvvvoqsrKyMHXqVADApEmTMG/ePN38I0eOxNq1a7F161ZERUVh3759WLBgAUaOHFnjK4hSw9a3jR32vjkAbw5uC6WRFMcikjF0xRF8tOcKMvMKDF0eERE1IAbbLQUA48aNQ2JiIhYuXIi4uDh069YNf/31l26Q8e3bt/V6aubPnw+JRIL58+fj7t27sLe3x8iRI/Hhhx8a6i1QPTKWy/Dm4HZ4pocblvx+GfuvxOObwzex6/xd/N9wbzzl48JdVURExGtLUeMVdjUBi3//D7eSswEAvb1ssWBER16nioioCeKFM8vBcNO05Oar8e3hm1h9MAK5+dprUz3d3RX/C2gPF2sTA1dHRES1heGmHAw3TdPd1Bx8vvcafj13FwCgNJIi8BEvvDqoNSyM5QaujoiIaorhphwMN03bxTup+GD3FZyO0p70z85cgTcHt8PzvdxhJGtUp3UiIqJiGG7KwXDT9AkhsO9yPD7+8ypuJmUBAFrZmyFoSDsM7+wMqZSDjomIGhuGm3Iw3DQf+WoNtpy6jRX7ryMlW3tmY29nS8x5oh0e6+DAI6uIiBoRhptyMNw0Pxm5+dhwNBrrj9xERuE5cXq0tMacJ9qjbxs7A1dHRESVwXBTDoab5islS4V1hyPx/fFo3ZFVfVu3QNCQdujpaWvg6oiIqDwMN+VguKGE9FysDovAltO3ka/Wfv37tLLF64+1hX/rFtxdRUTUADHclIPhhorE3M/G6rAI7Ai/ows5vh42mPVYGwxqZ8+QQ0TUgDDclIPhhh52NzUHXx+KxNZ/YqAq0O6u6uJqhVmPtcEQb0ceXUVE1AAw3JSD4YbKEp+ei28P38TmU7eRk68GALS2N8P0/q0wursrjOW8OCsRkaEw3JSD4YYqkpyZh/VHo/DTiVu6o6vszJWY0tcDL/TxgLWpwsAVEhE1Pww35WC4ocrKyM3H1tMx2HAsCrFpuQAAE7kM43q5I/ARL7jbmhq4QiKi5oPhphwMN1RV+WoN/rh4D98cjsKV2HQAgFQCDPZ2xJS+njzCioioHjDclIPhhqpLCIGjEUn45vBNHLmRpGtv52iOSf6eGNPDFaYKIwNWSETUdDHclIPhhmrDjfgMfH8iGjvD7yJbpR18bGFshHE93fGivwc8WpgZuEIioqaF4aYcDDdUm9Jy8rH97B38cCIat5Kzde392rTA+N4tMaSjI5RGPMqKiKimGG7KwXBDdUGjETh0PRGbjkfj8I1EFP1U2Zop8KyvG8b1ckdre3PDFklE1Igx3JSD4YbqWsz9bGw7E4NtZ2IQn56na+/tZYsJvVtiaGcnnjOHiKiKGG7KwXBD9aVArcHBa4n4+fRthF1LgKbwJ83KRI6nu7tiTA9XdHG14pFWRESVwHBTDoYbMoTYtBxs++cOtp2Jwd3UHF17a3szjOnhhtHdXeFqbWLAComIGjaGm3Iw3JAhqTUCh28kYmf4Xfz9XxzyCq9lJZEAfbxa4OkerhjW2QkWxnIDV0pE1LAw3JSD4YYaivTcfPx1KQ47z93ByZv3de3Gcime6OiEp7u7ol8bOyiMpAaskoioYWC4KQfDDTVEd1Kysev8PewMv4PIxCxdu5WJHAGdHDGiqwv6tm4BuYxBh4iaJ4abcjDcUEMmhMClu2nYGX4Xuy/FIjHjwdFWNqZyDO3shBFdXNCnlS2MGHSIqBlhuCkHww01FmqNwOmo+9h96R7+vBSH5CyV7jlbM0Vh0HFGby9b9ugQUZPHcFMOhhtqjArUGpyOuo8/LsXir3/jcL9Y0LEykePxDg54opMjBrSz5/WtiKhJYrgpB8MNNXYFag1O3EzG7oux+PtyvF7QURpJ0b+tHZ7o6ITHvB1gZ640YKVERLWH4aYcDDfUlKg1AmdvpeDv/+Lw9+V43L7/4PpWEgnQ08MGQzo64rEODmhtb84TBhJRo8VwUw6GG2qqhBC4Hp+pCzqX7qbpPe9ua4JH2zvg0fYO6NOqBUwUvAQEETUeDDflYLih5uJuag72/ReH0KsJOHXzPlRqje45pZEU/q1b6MJOyxamBqyUiKhiDDflYLih5ihbVYDjEckIu5aAsKsJuJeWq/d8Kzsz9G9rh35t7NCndQtY8gzJRNTAMNyUg+GGmjshBG4kZCLsagLCriXgTHQKCjQPfg3IpBL4uFnhkbb26N/WDt3crXmoOREZHMNNORhuiPSl5+bjeEQyjkYk4lhEMqKSsvSeN1PI0KdVC/RrY4f+be3QxoEDk4mo/jHclIPhhqh8d1KycSwiCUduJOF4ZLLeoeYA4GipRJ9WLeDn1QJ+rWzRys6MYYeI6hzDTTkYbogqT6MRuBybjmMRSTgakYTTUfd1VzIvYm+hRG8vW/TxsoVfqxZoy54dIqoDDDflYLghqr7cfDXCb6XgZNR9nLqZjHMxqVA9FHZszRTo7WkLv1a28PNqgQ5OFpBKGXaIqGYYbsrBcENUe3Lz1Tgfk4pTN+/jVFQywm+nIDdfP+xYGhuhh4cNfFvawNfDBj7u1jBT8hIRRFQ1DDflYLghqjuqAg0u3knFqaj7OHkzGWdvpSBbpdabRyaVwNvZAr4tbbShx8MGrtYm3JVFROViuCkHww1R/SlQa3A1LgNnou/j7O1UhN9Kwd3UnBLzOVkaw9fDBt1bWqN7S2t0crGCsZxnUCaiBxhuysFwQ2RYsWk5OHsrBWdvpSD8Vgr+u5eud54dQNu7097RAj7uVvBxs4aPuzXaOpjDiOfbIWq2GG7KwXBD1LDkqNS4cCcVZ2+l4NztFJyPSUNSZl6J+UzkMnR2tYSPmzW6ulujm5s13G25O4uouWC4KQfDDVHDJoRAbFouLt5JxfmYNFy8k4qLd9KQmVdQYl4bUzm6ulmjq5sVOrlYopOLFdxsGHiImiKGm3Iw3BA1PhqNwM2kTFyIScOFO6m4EJOKK7EZehcDLWJlIkdHZ0t0dtWGnc6ulvCyM4eMh6MTNWoMN+VguCFqGvIK1Lgam4ELd1Lx7900/HcvHdfjM5CvLvkrzUQug7ezBTq5aHt4Ortaoa2jOZRGHLRM1Fgw3JSD4Yao6VIVaHA9PgOX76Xj33vawHMlNr3E4egAYCSVoLW9OTo4W6C9kwW8nSzR3skCzlbG3K1F1AAx3JSD4YaoeVFrBKKSsvDfvTS90JOanV/q/JbGRuhQGHQ6OFugg5MF2jlawMJYXs+VE1FxDDflYLghIiEE7qXl4lpcOq7GZeBqbAauxWUgMjGzxGHpRdxsTNDByeJB8HGygKedGeQ8PJ2oXjDclIPhhojKoirQIDIxE1cLQ8+1wuATl55b6vxGUgk87czQ1sEcbR3M0cbRAm0dzOFlZ8aTEBLVMoabcjDcEFFVpWarHoSduAxcjUvH9bgMZJUylgcApBKgpa0p2jhYoK1jYfBxMEdre3NeV4uomhhuysFwQ0S1oeh8PBEJmbiRkImIhAzciNc+TsspfTwPALham6CtozbotLI3Qys77b2DhZIDmYnKwXBTDoYbIqpLQggkZuYhIiFTG3ziM3EjIQMRCZlIylSVuZyZQgavYmHHy84Mre3N4WlnBnP29hAx3JSH4YaIDCUlS4WIRG3giUjIRFRSJm4mZSHmfjbKGMcMAHC0VMLLzgyt7M3Rys6sMPyYw93GhNfbomaD4aYcDDdE1NCoCjS4fT8LNxOzcDMpC1GJWbiZlImopKxye3uMpBK0bGEKzxZmaGlrCo+ixy1M4W5jCoURgw81HVX5+82+TiIiA1MYSdHGwQJtHCxKPJeWna8LOjcTsxCVlIXIxExEJ2chN1+jDUSJWSWWk0oAZysTeNqZoqWtWWHwefCYA5upKWPPDRFRI6TRCMSm5yIqMQu37mfhdnI2opOzcCs5G7eSs5GTX/qRXEXszJXasNPCFB62ZoUhSNvzY20q5+BmanC4W6ocDDdE1NQVDWrWBp5s3E7OQnRyNm7dz8at5Kwyz85cxFxpBDcbE7jZmMLd1gTuNqZwszGBu632nmdrJkNoVOFm9erV+OyzzxAXFwcfHx989dVX6N27d5nzp6am4r333sPOnTtx//59eHh4YMWKFRg+fHilXo/hhoiau7ScfF1Pz+372YhOytIFn/j0vAqXtzaVlwg87oVByNXaFCYKnsCQal+jGXMTEhKCoKAgrFu3Dn5+flixYgUCAgJw7do1ODg4lJhfpVJhyJAhcHBwwPbt2+Hq6opbt27B2tq6/osnImqkrEzk6OJmhS5uViWey1GpcTc1GzEpObhzv/A+JRsx97X3Kdn5SM3OR2p2Gi7dTSt1/XbmylKDj5uNKZytjHn2ZqpzBu258fPzQ69evbBq1SoAgEajgbu7O2bPno25c+eWmH/dunX47LPPcPXqVcjl1esWZc8NEVH1ZeTm405KDu6k5CDmfrb2PiVb9zgzr6DCddiZK+FqbQwXaxPdrWja1doEtmYKjvmhEhrFbimVSgVTU1Ns374do0eP1rVPnjwZqamp2LVrV4llhg8fDltbW5iammLXrl2wt7fHhAkT8O6770ImK/0/gby8POTlPehmTU9Ph7u7O8MNEVEtE0IgLSdfF3xiUrL1QtCdlJwKBzoDgNJICldd8DEuFoC09+z9aZ4axW6ppKQkqNVqODo66rU7Ojri6tWrpS5z8+ZNHDhwABMnTsSePXsQERGB1157Dfn5+Vi0aFGpywQHB2PJkiW1Xj8REemTSCSwNlXA2lSBzq4ld3kJIZCanY+7qTm4V3jTPs7VtSVk5CGvQIObSdpz/pTl4d4fZytjOFuZwMnKGM5WxnCwUPIEh81YtcJNWFgYHn300dqupUIajQYODg745ptvIJPJ4Ovri7t37+Kzzz4rM9zMmzcPQUFBuuminhsiIqpfEokENmYK2JiVHn4AIK9Ajfi0PL0AdC8tB3dTc3E3JRv3UnORk69GUmYekjLzcOFO6eN+pBLA3kIJJysTOFkq9YKPk6U2CDlaKaE0Yg9QU1StcDN06FC4ublh6tSpmDx5crXCgp2dHWQyGeLj4/Xa4+Pj4eTkVOoyzs7OkMvlerugvL29ERcXB5VKBYVCUWIZpVIJpVJZ5fqIiKj+KY1kaFl4/p3SlNX7E5uWi7i0XMSm5SI+PRcFGoH49DzEp+fhQjmv18JMoQs9jpaF4cfKpPBeO22q4AkPG5tqfWJ3797Fjz/+iO+//x5LlizBY489hsDAQIwePbrUgFEahUIBX19fhIaG6sbcaDQahIaGYtasWaUu069fP2zZsgUajQZSqba78fr163B2dq706xIRUeNVmd4fjUYgKSsP8Wl5iE3LQVx6brHwk6MLQXkFGiRnqZCcpcJ/99LLfE1LY6PCnh5jOFoo4WhpDEdLJRwstbu/HC2NYW+hhJy7wRqMGg8oDg8Px8aNG/Hzzz8DACZMmIDAwED4+PhUuGxISAgmT56Mr7/+Gr1798aKFSuwbds2XL16FY6Ojpg0aRJcXV0RHBwMAIiJiUGnTp0wefJkzJ49Gzdu3MBLL72E119/He+9916l6uXRUkREVNQDFJuWi7h0bc9PfGHoKQpDsak5yFJVPAAaACQSbS+Qg4U2+DhaGsOhMAQ5WhjrAlELcyVkUh4JVh31OqC4R48ecHJyQosWLfDxxx9jw4YNWLNmDfz9/bFu3Tp06tSpzGXHjRuHxMRELFy4EHFxcejWrRv++usv3SDj27dv63poAMDd3R179+7FW2+9ha5du8LV1RVvvPEG3n333Zq+DSIiakaK9wB1dCn7D2VGbj7i0nJxLy0XCem5SMjIQ3x6buEtT9dWoBFIylQhKVOFy7Flv27RWCDHwl4fB0vjwvBTFIi097amCkgZgqqt2j03+fn52LVrFzZs2IB9+/ahZ8+eCAwMxPjx45GYmIj58+cjPDwcly9fru2aa4Q9N0REVJs0GoH72SrEp+ciIT1PF3ziM7TTCRnaMJSYkQdNJf/iGkklsDNXwt6i8Fb88UNtzeUiqHV+npvZs2fj559/hhACL774IqZNm4bOnTvrzRMXFwcXFxdoNJqqrr5OMdwQEZEhqDUCyZl5hQOdcxGf8aD3R9cTlJGH5Kw8VOUvs6lCVjIAlRKGWpgpoTBqvOOC6ny31OXLl/HVV19hzJgxZR6JZGdnh7CwsOqsnoiIqMmRSSXaQciWxuiC0gdDA0C+WqM91D1DhcRMbY9PYoY2+BQ9TszMQ0J6HnLy1chWqXVXg6+Ijam87ABkbqx7bG0ib9S7xarVc3P48GH07dsXRkb62aigoADHjx/HgAEDaq3A2saeGyIiaiqy8gp0YScx46FbsbakTO24oMoykkpga6aAnbkSLcwVsDdXws5CCTtzBVqYPXhsb66EjZmiXo4Uq/PdUjKZDLGxsSUubpmcnAwHBweo1ZUbXW4IDDdERNTcaDQCqTn5xYJPbplBKCU7v8rrtzGV64KQnbkSHZwsMOuxtrX6Hup8t5QQotSLmiUnJ8PMzKw6qyQiIqI6Ii3sibE1U6C9k0W586oKNLifpUJSpjb0JGeqCneTaXuAkrNUhb1BKtzP0g6STsnOR0p2Pm4kaNcRm5Zb6+GmKqoUbsaMGQNAewjdlClT9MbbqNVqXLx4EX379q3dComIiKjeKIykcCo8Q3NF1BqB1GxV4WHweYU3FWxM5fVQadmqFG6srLQDoIQQsLCwgImJie45hUKBPn36YPr06bVbIRERETVIMqkELcy1Jydsj/J7hOpTlcLNxo0bAQCenp6YM2cOd0ERERFRg1Pjyy80NhxQTERE1PjUyYDiHj16IDQ0FDY2NujevXupA4qLhIeHV75aIiIiolpU6XAzatQo3QDioqt4ExERETU03C1FREREDV5V/n433otMEBEREZWi0rulbGxsyh1nU9z9+/erXRARERFRTVQ63KxYsaIOyyAiIiKqHZUON5MnT67LOoiIiIhqRaXDTXp6um4AT3p6ernzcqAuERERGUqVxtwUXQnc2tq61PE3RRfUbMhXBSciIqKmrdLh5sCBA7C1tQUAhIWF1VlBRERERDXB89wQERFRg1cnl194WEpKCr777jtcuXIFANCxY0dMnTpV17tDREREZAjVOonf4cOH4enpiS+//BIpKSlISUnBl19+CS8vLxw+fLi2ayQiIiKqtGrtlurSpQv8/f2xdu1ayGQyAIBarcZrr72G48eP49KlS7VeaG3hbikiIqLGp84vvxAREYG3335bF2wAQCaTISgoCBEREdVZJREREVGtqFa46dGjh26sTXFXrlyBj49PjYsiIiIiqq5KDyi+ePGi7vHrr7+ON954AxEREejTpw8A4OTJk1i9ejU+/vjj2q+SiIiIqJIqPeZGKpVCIpGgotkb+kn8OOaGiIio8amTQ8GjoqJqXBgRERFRXat0uPHw8KjLOoiIiIhqRbVP4gcAly9fxu3bt6FSqfTan3rqqRoVRURERFRd1Qo3N2/exNNPP41Lly7pjcMpuphmQx5zQ0RERE1btQ4Ff+ONN+Dl5YWEhASYmpriv//+w+HDh9GzZ08cPHiwlkskIiIiqrxq9dycOHECBw4cgJ2dHaRSKaRSKR555BEEBwfj9ddfx7lz52q7TiIiIqJKqVbPjVqthoWFBQDAzs4O9+7dA6AddHzt2rXaq46IiIioiqrVc9O5c2dcuHABXl5e8PPzw6effgqFQoFvvvkGrVq1qu0aiYiIiCqtWuFm/vz5yMrKAgAsXboUTz75JPr3748WLVogJCSkVgskIiIiqopqXRW8NPfv34eNjY3uiKmGimcoJiIianzq5AzFZYmJiQEAuLu713RVRERERDVWrQHFBQUFWLBgAaysrODp6QlPT09YWVlh/vz5yM/Pr+0aiYiIiCqtWj03s2fPxs6dO/Hpp5/C398fgPbw8MWLFyM5ORlr166t1SKJiIiIKqtaY26srKywdetWDBs2TK99z549GD9+PNLS0mqtwNrGMTdERESNT1X+fldrt5RSqYSnp2eJdi8vLygUiuqskoiIiKhWVCvczJo1C++//z7y8vJ0bXl5efjwww8xa9asWiuOiIiIqKoqPeZmzJgxetP79++Hm5sbfHx8AAAXLlyASqXC448/XrsVEhEREVVBpcONlZWV3vQzzzyjN81DwYmIiKghqHS42bhxY13WQURERFQranQSv8TERN2FMtu3bw97e/taKYqIiIiouqo1oDgrKwsvvfQSnJ2dMWDAAAwYMAAuLi4IDAxEdnZ2bddIREREVGnVCjdBQUE4dOgQfv/9d6SmpiI1NRW7du3CoUOH8Pbbb9d2jURERESVVq2T+NnZ2WH79u0YNGiQXntYWBjGjh2LxMTE2qqv1vEkfkRERI1PnZ/ELzs7G46OjiXaHRwcuFuKiIiIDKpa4cbf3x+LFi1Cbm6uri0nJwdLlizRXWuKiIiIyBCqdbTUihUrMHTo0BIn8TM2NsbevXtrtUAiIiKiqqjWmBtAu2tq8+bNuHr1KgDA29sbEydOhImJSa0WWNs45oaIiKjxqcrf7yr33OTn56NDhw74448/MH369GoXSURERFQXqjzmRi6X6421ISIiImpIqjWgeObMmfjkk09QUFBQK0WsXr0anp6eMDY2hp+fH06fPl2p5bZu3QqJRILRo0fXSh1ERETU+FVrQPE///yD0NBQ/P333+jSpQvMzMz0nt+5c2el1xUSEoKgoCCsW7cOfn5+WLFiBQICAnDt2jU4ODiUuVx0dDTmzJmD/v37V+ctEBERUVUIAajzgfxsID8HKMgBCvIKH+dqb/mF98ZWQJvHDVZqtcKNtbV1iauCV9cXX3yB6dOnY+rUqQCAdevWYffu3diwYQPmzp1b6jJqtRoTJ07EkiVLcOTIEaSmptZKLURERI2SOh9QZWqDRn7OgwCSn60NHMWnC3IrmKf4fMXbcgChrlw97n0aT7jRaDT47LPPcP36dahUKjz22GNYvHhxtY+QUqlUOHv2LObNm6drk0qlGDx4ME6cOFHmckuXLoWDgwMCAwNx5MiRar02ERFRvRNC29uhytKGEVVWFR8Xny72vFpVv+9DIgXkpoCREjAy0d7LTR5MO3as33oeUqVw8+GHH2Lx4sUYPHgwTExM8OWXXyIxMREbNmyo1osnJSVBrVaXONuxo6Oj7hDzhx09ehTfffcdzp8/X6nXyMvLQ15enm46PT29WrUSEVEzJoS25yIvA8hL195y04tNZxROpz+Y1rUVzlMURDS1M161VFIjbeiQmxTeTAEj44faij1X9Njo4TZTQG5c9jwyOSCR1N37qKEqhZsffvgBa9aswSuvvAIA2L9/P0aMGIH169dDKq3W2OQqycjIwIsvvohvv/0WdnZ2lVomODgYS5YsqePKiIioQRNCGy5yUoHc1LLvc9NKhpKisFLbocTIBFCYFd7Miz0unFaal/JcKfMVPZabAUaK2q2xkapSuLl9+zaGDx+umx48eDAkEgnu3bsHNze3Kr+4nZ0dZDIZ4uPj9drj4+Ph5ORUYv7IyEhER0dj5MiRujaNRgMAMDIywrVr19C6dWu9ZebNm4egoCDddHp6Otzd3atcKxERNQDqfCD7PpCdrL3lpJQfVoqHltoIJxIpoLQAlJaFNwvAuPC+eLuu7aHnigcTqazm9VCpqhRuCgoKYGxsrNcml8uRn59frRdXKBTw9fVFaGio7nBujUaD0NBQzJo1q8T8HTp0wKVLl/Ta5s+fj4yMDKxcubLU0KJUKqFUKqtVHxER1SF1gTacFAWV7GQgpyi43Ndvz04GslOAvLSavaZMARhbAybWpd8bWz0UTB4KKgqzBr07hrSqFG6EEJgyZYpeWMjNzcWMGTP0DgevyqHgQUFBmDx5Mnr27InevXtjxYoVyMrK0h09NWnSJLi6uiI4OBjGxsbo3Lmz3vLW1tYAUKKdiIjqmUajDStZCUBmApCVqL1lJmjbspL0g0tuajVfSAKY2gImtoCJTdlBpcS9jXbMCMNJk1elcDN58uQSbS+88EKNChg3bhwSExOxcOFCxMXFoVu3bvjrr790g4xv375dL+N5iIioFOoCIDtJP6AUPc5MLHZfeKvsocI6Em34MG3x4GZiqw0vxdtMWzxoM7biLh0qV7UvnNlY8cKZRETQDrDNvg9k3AMy4oCM2JL36bHa8CI0VVu3iQ1g5gCYOwBmdoWP7QEze8DU7qEgY82gQpVSpxfOJCKiBk6VBaTd1QaX9NhSgksckBlX+XOjSKTaIKILKUXBxf7BfdFjUzsesUMGx3BDRNSYqAu0wSTtjv4t/S6QFqMNNTn3K78+UzvA0hmwcAYsnEq/N7Nn7wo1Kgw3REQNiSobSL0FpNwCUm8D6UUB5q72PiO2cuNaFBaApUthcHEpPbiYO7KXhZokhhsiovqkLtAGlpRbD0JMSvSDx1kJFa9DKtcGFyu3BzdLV8DKHbBy1U4bW9X5WyFqqBhuiIhqW04qcD8SuB9VLLhEa8NL2p2Ke16UVoCNB2DdsjCwuBWGlsLHZg4AjyIlKhPDDRFRdeRlagNMcmTh/c0H09lJ5S8rUwDWHoUBpvDexvPBYxObenkLRE0Vww0RUVnU+drel6RrQHJEYZC5qb3PjCt/WXNHwLa1NrQ8HF7MndjzQlSHGG6IiFTZQPINIPG6NsgkFt7u3wQ05VxexrSFNsC0aAO0aFX4uDVg20p7un4iMgiGGyJqPnLTgISr+gEm6RqQGgOgjPOZys0Au7ba28NBxsS6PqsnokpiuCGipkddoB3/Ev8vEP9f4e0ykHa77GVMbAH79oBdO8C+A2DfDrBrrz0KibuQiBoVhhsiatwyEwpDzOXCEPOvtkdGnVf6/BYu2hCjF2Taay8TQERNAsMNETUOGg2QEgXEngdiL2hv8f9pL9ZYGrkZ4NgRcOwEOHYGHDpqp3kkElGTx3BDRA2PRq09IqkoyNw7D8RdBPLSS5lZoh3E69gJcOhUGGY6aY9M4u4komaJ4YaIDEsI7VFJd84A98ILg8wlID+r5LwyJeDUGXDuBjh3BZy6APbegMK0vqsmogaM4YaI6lf2feBuOHDnH+DuGeDuWSAnpeR8clNteHHuBjj7aG/27QGZvN5LJqLGheGGiOpOgQqIvwTcOasNMnfOaI9iephMqQ0vrr6AS3fApZv2kGteiZqIqoHhhohqT246cOc0cPskcOuENtAU5Jacz7Y14NYLcOupDTSOnXl1aiKqNQw3RFR9GfHA7RMPbnGXAKHRn8fEBnDtWRhkegKuPQBTW8PUS0TNAsMNEVVeSjQQdeRBmLl/s+Q81h6AR1+gZR+gZV/tmX0lknovlYiaL4YbIipbRjwQfQS4eRCIOgyk3npoBol2l5KHf2GY8QcsXQxRKRGRDsMNET2QkwrcOgbcPKQNM4lX9J+XGmnHyHj00/bOuPXi9ZWIqMFhuCFqzgpU2t1LkQe0YSb2fMkxM05dAK+B2puHP692TUQNHsMNUXOTehu4sQ+I2K8NNKpM/edbtCkMMwMAz/6AWQvD1ElEVE0MN0RNXX6udldTRCgQsQ9Iuq7/vJk90PpxoNUgbaCxcjVImUREtYXhhqgpykwArv8FXPtTOxg4P/vBcxIZ4N4baDNYe3PqymswEVGTwnBD1BQIoe2RubYHuLpHe2kDiAfPWzgDbR4H2gzR9tBwEDARNWEMN0SNlUYNxJx6EGgevqyBS3eg/Qig/VDt4do81wwRNRMMN0SNibpAO37m8m/Ald+BrMQHz8kU2jEz7YcD7YfxfDNE1Gwx3BA1dEWB5r9ftYEmO+nBc8bWQLsAbaBp8zgP0yYiAsMNUcOkLgBuHQX++61koDGxATo8CXR6WttTI5MbrEwiooaI4YaooRACiL0AXAwBLm0HshIePGdiA3iPBDqOZqAhIqoAww2RoaXeBi79AlwIAZKuPWg3sQW8n2SgISKqIoYbIkPITQMu79IGmltHH7TLlECH4UDX57VjaBhoiIiqjOGGqL5oNEDUISD8B+DqbkCd9+A5z/5A13FAx6cAYyvD1UhE1AQw3BDVtYw44NxPwLkfgZToB+32HbSBpstzgLW7wcojImpqGG6I6oJGrb04Zfj3wPW9gFBr25WW2jDT40XAuRtPrEdEVAcYbohqU+ptIPxHbU9Nxr0H7e59AN/J2sHBClODlUdE1Bww3BDVlBDasTSnv9VeCkFotO0mtoDPeKDHJMChg2FrJCJqRhhuiKorLxO4uFUbahKvPmj37A/4TtGel8ZIabDyiIiaK4Yboqq6f1MbaM5tBvLStG1yM8DneaD3y+ylISIyMIYbosqK+Qc4/qX2cggQ2jbbVtpA020CD+EmImogGG6IyqPRANf/BI5/Bdw+8aC9zWDAbwbQ+nFAKjVcfUREVALDDVFp8nOBCz8DJ1YByRHaNqlce14a/5mAY0fD1kdERGViuCEqTpUFnNmo3f2UGa9tM7YCer4E9H4FsHQ2bH1ERFQhhhsiAMhNB/75FjixGshO1rZZugF9ZwHdXwCUFoatj4iIKo3hhpq37PvAqXXaW27hkU82XkD/IO3FK40Uhq2PiIiqjOGGmqecVO14mpNrAVWmts2uPTBgDtBpDCDjjwYRUWPF3+DUvKiytL00x74EclO1bY5dtKHG+yke+URE1AQw3FDzUJCnHSh8ZBmQlaBts+8APPp/2lDDC1gSETUZDDfUtKkLgAtbgIOfAOl3tG02nsCg/wO6PAtIZQYtj4iIah/DDTVNQgAR+4G/FwCJV7RtFi7AwHe0Rz/J5Iatj4iI6gzDDTU9cf8Cf88HboZpp01sgP5zgF7TALmxYWsjIqI6x3BDTUd6LBD2gfaClhCATKG97tOAOdqAQ0REzQLDDTV++Tnao5+OrQDys7VtnZ4GHl8E2HoZtDQiIqp/DDfUeAkBXPsT+GsukHpL2+bWGwj4EHDvbdjaiIjIYBhuqHFKjgT+fBeI2KedtnQFnnhfewI+HtZNRNSsMdxQ46LK1p6r5viXgFqlvVJ331naAcNKc0NXR0REDUCDOB3r6tWr4enpCWNjY/j5+eH06dNlzvvtt9+if//+sLGxgY2NDQYPHlzu/NSEXN0NrO4NHPlcG2xaPw68dhIYvJjBhoiIdAwebkJCQhAUFIRFixYhPDwcPj4+CAgIQEJCQqnzHzx4EOPHj0dYWBhOnDgBd3d3PPHEE7h79249V071Jj0WCHkB2DoBSIsBrFoC4zYDL+wA7NoYujoiImpgJEIIYcgC/Pz80KtXL6xatQoAoNFo4O7ujtmzZ2Pu3LkVLq9Wq2FjY4NVq1Zh0qRJFc6fnp4OKysrpKWlwdLSssb1Ux3SaIBzPwB/LwTy0gCpEdDvDe0uKIWpoasjIqJ6VJW/3wYdc6NSqXD27FnMmzdP1yaVSjF48GCcOHGiUuvIzs5Gfn4+bG1tS30+Ly8PeXl5uun09PSaFU31I+kG8PsbwK1j2mmXHsBTXwFOnQ1bFxERNXgG3S2VlJQEtVoNR0dHvXZHR0fExcVVah3vvvsuXFxcMHjw4FKfDw4OhpWVle7m7u5e47qpDqnzgcOfA2v7aYON3BQICAam7WewISKiSmnUR0t9/PHH2Lp1Kw4ePAhj49JPqz9v3jwEBQXpptPT0xlwGqr4y8CvrwBxF7XTrR8HnlwO2HgYti4iImpUDBpu7OzsIJPJEB8fr9ceHx8PJyencpf9/PPP8fHHH2P//v3o2rVrmfMplUoolcpaqZfqiEYNnFgFHPhAexSUiQ0w7FOgy3M8Zw0REVWZQXdLKRQK+Pr6IjQ0VNem0WgQGhoKf3//Mpf79NNP8f777+Ovv/5Cz54966NUqiv3bwKbRgD7FmqDTdsA7eHdXccy2BARUbUYfLdUUFAQJk+ejJ49e6J3795YsWIFsrKyMHXqVADApEmT4OrqiuDgYADAJ598goULF2LLli3w9PTUjc0xNzeHuTnPddJoCAGc2QD8vQDIzwIU5sDQYKD7iww1RERUIwYPN+PGjUNiYiIWLlyIuLg4dOvWDX/99ZdukPHt27chlT7oYFq7di1UKhWeffZZvfUsWrQIixcvrs/Sqboy4oBdM4GI/dppj0eA0asBG0+DlkVERE2Dwc9zU994nhsDu7EP+HUGkJ0EyJTA4EWA36uA1ODnkyQiogas0ZznhpqRAhUQukQ7cBgAHLsAz6wHHDoYti4iImpyGG6o7iVHAttfAmLPa6d7vwIMWQrISz98n4iIqCYYbqhuXQgBdgcBqkztId6jVgMdRhi6KiIiasIYbqhuqLKA3XOAC1u00x79gDHfAlauhq2LiIiaPIYbqn3JkdqreCdcBiRSYOBcYMAcQCozdGVERNQMMNxQ7bryB/Dbq0BeOmDuCDy7AfB8xNBVERFRM8JwQ7VDXQCEfQAcXa6dbukPPLcJsCj/MhpERES1jeGGai4zEdjxEhB1WDvdZyYwZAkgkxu2LiIiapYYbqhm7pwBtk0C0u8CcjNg1FdA52cMXRURETVjDDdUfec2A3+8qb3gZYu2wLifeFI+IiIyOIYbqjqNWnsV76KzDXd4Ehi9FjDm5SyIiMjwGG6oanLTtGcbLrro5cB3tYd689pQRETUQDDcUOUlRwI/Pw8kXQeMTICn1wKdnjZ0VURERHoYbqhyIsOAX6YAuamApSvw/BbApZuBiyIiIiqJ4YYqdvpb4M93AaEG3HoB4zYDFo6GroqIiKhUDDdUNo0a+HsBcHK1dtpnPPDkCl7Nm4iIGjSGGyqdKhvYOR24+od2+vGFwCNBgERi2LqIiIgqwHBDJWUmaAcO3z0LyBTaw7y7PGvoqoiIiCqF4Yb0JV4HNj8LpN4CTGy0A4c9+hq6KiIiokpjuKEHoo8CWydoz2Vj4wVM3A7YtTF0VURERFXCcENal7YDv84ANPmAW29g/M+AmZ2hqyIiIqoyhhsCTq4D/npX+7jjKODprwG5iWFrIiIiqiaGm+ZMCODA+8CRZdrp3q8AQz/mpRSIiKhRY7hprtQFwO63gPAftNOPzQf6z+Gh3kRE1Ogx3DRH+bnAjkDtOWwkUuDJ5YDvFENXRUREVCsYbpqb3DTg5wnAraOATAk8+x3gPdLQVREREdUahpvmJCMe+OkZIP4SoLTUnsPGq7+hqyIiIqpVDDfNxf2bwI9PAynRgJkD8MIOwLmroasiIiKqdQw3zUHsBeCnZ4GsBMDGE3jxV8C2laGrIiIiqhMMN01d1BHtWYfz0gHHLtoeGwtHQ1dFRERUZxhumrLL/w/YMQ1Q5wEejwDjtwDGVoauioiIqE4x3DRVZzcBf7wFCA3Q4Ungme8AubGhqyIiIqpzDDdNjRDAkc+BAx9op3tMAkYsB2T8qImIqHngX7ymRKMB/poLnP5aO91/jvbMwzzrMBERNSMMN01FgQr47VXg3+3a6aGfAH1mGLYmIiIiA2C4aQryMoFtLwKRBwCpETB6HdD1OUNXRUREZBAMN41dVjKw5Tng7llAbgqM+xFoM9jQVRERERkMw01jlnJLezmF5BuAiS0w8RfAraehqyIiIjIohpvGKvYisPlZIDMesHQDXtwJ2Lc3dFVEREQGx3DTGN08CGx9AVBlAI6dtT02li6GroqIiKhBYLhpbC7+oj0qSpMPePYHnt/Msw4TEREVIzV0AVRJQgDHvgR2TtMGm05jtNeJYrAhIiLSw56bxkCjAf5+Dzi5RjvdZybwxAeAlNmUiIjoYQw3DZ0qC/j1FeDK79rpJz4A+s42bE1EREQNGMNNQ5Z+D/j5eSD2AiBTAKPW8OR8REREFWC4aajunQN+Hg9kxAKmLYDntwAt+xi6KiIiogaP4aYhurwL2PkKUJAD2HsDE7YCNp6GroqIiKhRYLhpSNQFwIGlwLGV2uk2Q4BnNwDGloati4iIqBFhuGkoMuKB7S8Bt45qp/vMBIYsBWT8iIiIiKqCfzkbguhjwPap2kspKMyBUauATk8buioiIqJGieHGkNQFwNHlwMFgQKi142vG/QjYtTV0ZURERAAAtUaNrIIsZOdnIys/C5n5mcjKzypxy8zPRJZKe+9u4Y5Z3WcZrGaGG0NJuAr8NkN7VBQAdB0HPLkcUJgZti4iImr0CjQFyMrXBpKiMFL8se5WkIUslf59pioT2QXZunlyCnKq/Ppd7bsy3DQrGjVwYjVw4ANAnae9fMKwz4CuYwGJxNDVERGRgeRr8vV6Rx5+XFaPSWm3XHVurddnJDWCmdwM5nJzmMpNdfdmRmawUFjonjOTm8HZ3LnWX79KtRr01ZubuEvA7reBmFPa6TaDgae+4hW9iYgamXx1PrILspGdn627L9p1UzSdU5BT5vM5+TkllldpVLVep0KqgJncTBdGzORmlb7pwkvhY4VMUev11RWGm/qQlaQdV3NmAyA0gMICCPgQ6DGJvTVERHVIrVEjV52LnIIc5OTnIEedUyJ0FE0/HE4eDiHFny/QFNRZzUqZsvzgYWQGM4X23lzxoPfEXGEOUyNTvR4UuUxeZ3U2ZAw3dSknVXuxyxOrAVWmtq3jaG2wsXIzZGVERA1CgaYAuQWF4aPYLVedqw0jRY8ffr7YMuUtXxe9IcUpZUqYGpnCVG4KEyMTmMpNdQGjqN3UyBQmchO96YefL768XNo8A0ltYripC6m3gVNfA2c3PQg1zj7AkPeBVgMNWhoRUXmEENrAoc5FnjoPuQWF9+pc5BVo71VqlW66rHny1Hl6j4sHkeyCbN3jfE1+vbwvCSQwMTKBsZExTIxMyg0XZkZmeu2lhRQzuRlMjExgJOWf0YaoQXwqq1evxmeffYa4uDj4+Pjgq6++Qu/evcuc/5dffsGCBQsQHR2Ntm3b4pNPPsHw4cPrseJSFOQBV3cD534EIsMACG27vTfw6DzA+ynugiKiCgkhoNKooFJrb/mafN3j4u26xxoV8tX5pT5fFDDy1A9uDweR0kKJRmjq/X0XhY+im7GRsTZMFAskxR+X+bzMGCbywvXICu/lJlBIFZDwd3CzYfBwExISgqCgIKxbtw5+fn5YsWIFAgICcO3aNTg4OJSY//jx4xg/fjyCg4Px5JNPYsuWLRg9ejTCw8PRuXNnA7yDQpf/H7Bz2oNpr4FA39naQcP8gSIyKLVGjQJRgAJNAfLV+XqP80V+ibZSH2vyS23TtRfe681bGEzy1fl6YUQXQIqHE82DMNOQGMuMoTRSQilT6h4by4yhlCn1HhsbFbYV3opPPxxMioeTojDC8EG1SSKEEIYswM/PD7169cKqVasAABqNBu7u7pg9ezbmzp1bYv5x48YhKysLf/zxh66tT58+6NatG9atW1fh66Wnp8PKygppaWmwtKy9azapctOQtPEJoPVj2nE11u4AAIHSN29pm72seUtrLnO9tfB6pbaXWVodvV4Z6yhLaesoa/mG/L6r+uMoIKARGmiEBkIIaKC9L3qsaxcaCJTerlumcF0l2qu4LghAAw3UGjXUQv3gXqihERoUaAqgERpdW/H5NEKDAlH4fLHlSjyvKWX50tZfGGoM0RNRW4ykRlBIFVDKlJDL5FBIFVDICm9SBeQyOZQype5xUXvRPKWFj6LHJcJKYWApmoeBgxqSqvz9NmjPjUqlwtmzZzFv3jxdm1QqxeDBg3HixIlSlzlx4gSCgoL02gICAvDbb7+VOn9eXh7y8vJ00+np6TUvvBRXMqLxgmk2EPuH9kZEDZYEEhhJjSCXymEkNdJ7XNZ9VR/LpXLdrawwopAp9ANL8eAiU0AulUMqkRp6cxE1OgYNN0lJSVCr1XB0dNRrd3R0xNWrV0tdJi4urtT54+LiSp0/ODgYS5YsqZ2CyyGFFMYy41Kfq8p/PhKUPm9p6yhz3jLaS2uuy9drEO+7zE3RcN93WcuX9XpSiRRSiRQSSCCRSPSm9e4lkpLzoVi7RKKbV6+9rPlLeT2JRKKbRyaRQSaVae8lMkglUhhJjfTui54rPp/eMlIpjCQVL1N8PplU9uCxRFZq+JBJZZX+jIio8TH4mJu6Nm/ePL2envT0dLi7u9f663Sx74J/Xvin1tdLREREVWPQcGNnZweZTIb4+Hi99vj4eDg5OZW6jJOTU5XmVyqVUCqVtVMwERERNXgG3ZmrUCjg6+uL0NBQXZtGo0FoaCj8/f1LXcbf319vfgDYt29fmfMTERFR82Lw3VJBQUGYPHkyevbsid69e2PFihXIysrC1KlTAQCTJk2Cq6srgoODAQBvvPEGBg4ciGXLlmHEiBHYunUrzpw5g2+++caQb4OIiIgaCIOHm3HjxiExMRELFy5EXFwcunXrhr/++ks3aPj27duQSh90MPXt2xdbtmzB/Pnz8X//939o27YtfvvtN8Oe44aIiIgaDIOf56a+1dV5boiIiKjuVOXvN0+gQERERE0Kww0RERE1KQw3RERE1KQw3BAREVGTwnBDRERETQrDDRERETUpDDdERETUpDDcEBERUZPCcENERERNisEvv1Dfik7InJ6ebuBKiIiIqLKK/m5X5sIKzS7cZGRkAADc3d0NXAkRERFVVUZGBqysrMqdp9ldW0qj0eDevXuwsLCARCIxdDkNSnp6Otzd3RETE8PrblUTt2HNcPvVHLdhzXD71VxdbUMhBDIyMuDi4qJ3Qe3SNLueG6lUCjc3N0OX0aBZWlryh7qGuA1rhtuv5rgNa4bbr+bqYhtW1GNThAOKiYiIqElhuCEiIqImheGGdJRKJRYtWgSlUmnoUhotbsOa4farOW7DmuH2q7mGsA2b3YBiIiIiatrYc0NERERNCsMNERERNSkMN0RERNSkMNwQERFRk8Jw08ysXr0anp6eMDY2hp+fH06fPl3mvJs2bYJEItG7GRsb12O1Dcvhw4cxcuRIuLi4QCKR4LfffqtwmYMHD6JHjx5QKpVo06YNNm3aVOd1NmRV3YYHDx4s8R2USCSIi4urn4IbmODgYPTq1QsWFhZwcHDA6NGjce3atQqX++WXX9ChQwcYGxujS5cu2LNnTz1U2/BUZ/vx96C+tWvXomvXrroT9Pn7++PPP/8sdxlDfP8YbpqRkJAQBAUFYdGiRQgPD4ePjw8CAgKQkJBQ5jKWlpaIjY3V3W7dulWPFTcsWVlZ8PHxwerVqys1f1RUFEaMGIFHH30U58+fx5tvvolp06Zh7969dVxpw1XVbVjk2rVret9DBweHOqqwYTt06BBmzpyJkydPYt++fcjPz8cTTzyBrKysMpc5fvw4xo8fj8DAQJw7dw6jR4/G6NGj8e+//9Zj5Q1DdbYfwN+Dxbm5ueHjjz/G2bNncebMGTz22GMYNWoU/vvvv1LnN9j3T1Cz0bt3bzFz5kzdtFqtFi4uLiI4OLjU+Tdu3CisrKzqqbrGBYD49ddfy53nnXfeEZ06ddJrGzdunAgICKjDyhqPymzDsLAwAUCkpKTUS02NTUJCggAgDh06VOY8Y8eOFSNGjNBr8/PzE6+88kpdl9fgVWb78fdgxWxsbMT69etLfc5Q3z/23DQTKpUKZ8+exeDBg3VtUqkUgwcPxokTJ8pcLjMzEx4eHnB3dy83nVNJJ06c0NveABAQEFDu9qbSdevWDc7OzhgyZAiOHTtm6HIajLS0NACAra1tmfPwe1i2ymw/gL8Hy6JWq7F161ZkZWXB39+/1HkM9f1juGkmkpKSoFar4ejoqNfu6OhY5viF9u3bY8OGDdi1axd++uknaDQa9O3bF3fu3KmPkhu9uLi4Urd3eno6cnJyDFRV4+Ls7Ix169Zhx44d2LFjB9zd3TFo0CCEh4cbujSD02g0ePPNN9GvXz907ty5zPnK+h4213FLRSq7/fh7sKRLly7B3NwcSqUSM2bMwK+//oqOHTuWOq+hvn/N7qrgVHn+/v56abxv377w9vbG119/jffff9+AlVFz0b59e7Rv31433bdvX0RGRmL58uX48ccfDViZ4c2cORP//vsvjh49auhSGqXKbj/+Hiypffv2OH/+PNLS0rB9+3ZMnjwZhw4dKjPgGAJ7bpoJOzs7yGQyxMfH67XHx8fDycmpUuuQy+Xo3r07IiIi6qLEJsfJyanU7W1paQkTExMDVdX49e7du9l/B2fNmoU//vgDYWFhcHNzK3fesr6Hlf25b4qqsv0ext+DgEKhQJs2beDr64vg4GD4+Phg5cqVpc5rqO8fw00zoVAo4Ovri9DQUF2bRqNBaGhomftKH6ZWq3Hp0iU4OzvXVZlNir+/v972BoB9+/ZVentT6c6fP99sv4NCCMyaNQu//vorDhw4AC8vrwqX4ffwgepsv4fx92BJGo0GeXl5pT5nsO9fnQ5XpgZl69atQqlUik2bNonLly+Ll19+WVhbW4u4uDghhBAvvviimDt3rm7+JUuWiL1794rIyEhx9uxZ8fzzzwtjY2Px33//GeotGFRGRoY4d+6cOHfunAAgvvjiC3Hu3Dlx69YtIYQQc+fOFS+++KJu/ps3bwpTU1Pxv//9T1y5ckWsXr1ayGQy8ddffxnqLRhcVbfh8uXLxW+//SZu3LghLl26JN544w0hlUrF/v37DfUWDOrVV18VVlZW4uDBgyI2NlZ3y87O1s3z8M/xsWPHhJGRkfj888/FlStXxKJFi4RcLheXLl0yxFswqOpsP/4e1Dd37lxx6NAhERUVJS5evCjmzp0rJBKJ+Pvvv4UQDef7x3DTzHz11VeiZcuWQqFQiN69e4uTJ0/qnhs4cKCYPHmybvrNN9/Uzevo6CiGDx8uwsPDDVB1w1B0WPLDt6JtNnnyZDFw4MASy3Tr1k0oFArRqlUrsXHjxnqvuyGp6jb85JNPROvWrYWxsbGwtbUVgwYNEgcOHDBM8Q1AadsOgN736uGfYyGE2LZtm2jXrp1QKBSiU6dOYvfu3fVbeANRne3H34P6XnrpJeHh4SEUCoWwt7cXjz/+uC7YCNFwvn8SIYSo274hIiIiovrDMTdERETUpDDcEBERUZPCcENERERNCsMNERERNSkMN0RERNSkMNwQERFRk8JwQ0RERE0Kww0RERE1KQw3RAQAkEgk5d4WL15s6BJrnaenJ1asWGGQ1168eHGF25yIqsfI0AUQUcMQGxurexwSEoKFCxfi2rVrujZzc3NDlFVlQgio1WoYGdXfrzeVSgWFQlGlZebMmYMZM2bopnv16oWXX34Z06dPr+3yiJod9twQEQDAyclJd7OysoJEItFr27p1K7y9vWFsbIwOHTpgzZo1umWjo6MhkUiwbds29O/fHyYmJujVqxeuX7+Of/75Bz179oS5uTmGDRuGxMRE3XJTpkzB6NGjsWTJEtjb28PS0hIzZsyASqXSzaPRaBAcHAwvLy+YmJjAx8cH27dv1z1/8OBBSCQS/Pnnn/D19YVSqcTRo0cRGRmJUaNGwdHREebm5ujVqxf279+vW27QoEG4desW3nrrLb2eksWLF6Nbt25622bFihXw9PQsUfeHH34IFxcXtG/fHgAQExODsWPHwtraGra2thg1ahSio6NL3d7m5uZ621cmk8HCwkKvjYiqh+GGiCq0efNmLFy4EB9++CGuXLmCjz76CAsWLMD333+vN9+iRYswf/58hIeHw8jICBMmTMA777yDlStX4siRI4iIiMDChQv1lgkNDcWVK1dw8OBB/Pzzz9i5cyeWLFmiez44OBg//PAD1q1bh//++w9vvfUWXnjhBRw6dEhvPXPnzsXHH3+MK1euoGvXrsjMzMTw4cMRGhqKc+fOYejQoRg5ciRu374NANi5cyfc3NywdOlSxMbG6vVcVUZoaCiuXbuGffv24Y8//kB+fj4CAgJgYWGBI0eO4NixYzA3N8fQoUP1whoR1YM6vzQnETU6GzduFFZWVrrp1q1biy1btujN8/777wt/f38hhBBRUVECgFi/fr3u+Z9//lkAEKGhobq24OBg0b59e9305MmTha2trcjKytK1rV27Vpibmwu1Wi1yc3OFqampOH78uN5rBwYGivHjxwshHlxp/LfffqvwfXXq1El89dVXumkPDw+xfPlyvXkWLVokfHx89NqWL18uPDw89Op2dHQUeXl5urYff/xRtG/fXmg0Gl1bXl6eMDExEXv37q2wttJqIaLq4ZgbIipXVlYWIiMjERgYqDcepKCgAFZWVnrzdu3aVffY0dERANClSxe9toSEBL1lfHx8YGpqqpv29/dHZmYmYmJikJmZiezsbAwZMkRvGZVKhe7du+u19ezZU286MzMTixcvxu7duxEbG4uCggLk5OToem5qqkuXLnrjbC5cuICIiAhYWFjozZebm4vIyMhaeU0iqhyGGyIqV2ZmJgDg22+/hZ+fn95zMplMb1oul+seF41hebhNo9FU+bV3794NV1dXveeUSqXetJmZmd70nDlzsG/fPnz++edo06YNTExM8Oyzz1a4i0gqlUIIodeWn59fYr6HXy8zMxO+vr7YvHlziXnt7e3LfU0iql0MN0RULkdHR7i4uODmzZuYOHFira//woULyMnJgYmJCQDg5MmTMDc3h7u7O2xtbaFUKnH79m0MHDiwSus9duwYpkyZgqeffhqANnw8PLhXoVBArVbrtdnb2yMuLg5CCF1AO3/+fIWv16NHD4SEhMDBwQGWlpZVqpWIahcHFBNRhZYsWYLg4GB8+eWXuH79Oi5duoSNGzfiiy++qPG6VSoVAgMDcfnyZezZsweLFi3CrFmzIJVKYWFhgTlz5uCtt97C999/j8jISISHh+Orr74qMZj5YW3btsXOnTtx/vx5XLhwARMmTCjRa+Tp6YnDhw/j7t27SEpKAqA9iioxMRGffvopIiMjsXr1avz5558Vvo+JEyfCzs4Oo0aNwpEjRxAVFYWDBw/i9ddfx507d6q/gYioyhhuiKhC06ZNw/r167Fx40Z06dIFAwcOxKZNm+Dl5VXjdT/++ONo27YtBgwYgHHjxuGpp57SO2Hg+++/jwULFiA4OBje3t4YOnQodu/eXeFrf/HFF7CxsUHfvn0xcuRIBAQEoEePHnrzLF26FNHR0WjdurVu15G3tzfWrFmD1atXw8fHB6dPn8acOXMqfB+mpqY4fPgwWrZsiTFjxsDb2xuBgYHIzc1lTw5RPZOIh3cuExHVkylTpiA1NRW//faboUshoiaEPTdERETUpDDcEBERUZPC3VJERETUpLDnhoiIiJoUhhsiIiJqUhhuiIiIqElhuCEiIqImheGGiIiImhSGGyIiImpSGG6IiIioSWG4ISIioiaF4YaIiIialP8PfJwGFUqLfJEAAAAASUVORK5CYII=\n"},"metadata":{}}],"source":["Ts = np.linspace(0.2, 3.0, 200)\n","ps = np.array([softmax_temperature(z, T) for T in Ts])  # shape: (len(Ts), V)\n","\n","plt.figure()\n","plt.plot(Ts, ps[:, 0], label=\"token 0\")\n","plt.plot(Ts, ps[:, 1], label=\"token 1\")\n","plt.plot(Ts, ps[:, 2], label=\"token 2\")\n","plt.xlabel(\"Temperature T\")\n","plt.ylabel(\"Probability\")\n","plt.title(\"Effect of temperature on softmax probabilities\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"05f73381"},"source":["## 「差だけが効く」：温度と logits 差の関係\n","2クラス（または2つの候補だけ）に注目すると\n","\n","$$\n","\\frac{p_1}{p_2} = \\exp\\left(\\frac{z_1 - z_2}{T}\\right)\n","$$\n","\n","つまり温度は **logits の差 $(z_1-z_2)$ の強調率**\n","\n","この性質により、softmax は定数シフト $z \\mapsto z + c$ に不変"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6915de16","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768455603146,"user_tz":-540,"elapsed":32,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"b8e30921-1b8b-444d-8f3d-ed9297409fe8"},"outputs":[{"output_type":"stream","name":"stdout","text":["max |p1 - p2| = 0.0\n"]}],"source":["# 確認：zに定数を足してもsoftmaxは不変\n","c = 123.4\n","p1 = softmax_temperature(z, 1.0)\n","p2 = softmax_temperature(z + c, 1.0)\n","print(\"max |p1 - p2| =\", np.max(np.abs(p1 - p2)))"]},{"cell_type":"markdown","metadata":{"id":"e30e075f"},"source":["## 推論（生成）で温度を使う理由\n","言語モデル生成では、各ステップで語彙分布 $p(t)$ からサンプリングします\n","\n","- **温度を下げる**：より保守的・決定論的（同じ文脈なら似た出力になりやすい）\n","- **温度を上げる**：探索的・多様（逸脱も増える）\n","\n","学習時（cross-entropy）では原則 $T=1$ を用い、推論時に調整するのが一般的"]},{"cell_type":"markdown","metadata":{"id":"45c7465a"},"source":["# top-k / top-p（nucleus）サンプリング\n","\n","温度だけでなく、**候補集合を切る**のが top-k / top-p です。\n","\n","- **top-k**：上位 k 個の語彙だけ残して再正規化してサンプル\n","- **top-p（nucleus）**：上位から確率を足して累積が p を超える最小集合だけ残してサンプル\n","\n","温度は「分布の鋭さ」、top-k/top-p は「探索範囲の制限」という役割分担になる"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ae5de78b"},"outputs":[],"source":["def top_k_filter(probs, k):\n","    probs = np.asarray(probs, dtype=np.float64)\n","    if k <= 0:\n","        raise ValueError(\"k must be >= 1\")\n","    idx = np.argpartition(probs, -k)[-k:]\n","    mask = np.zeros_like(probs, dtype=bool)\n","    mask[idx] = True\n","    filtered = np.where(mask, probs, 0.0)\n","    s = filtered.sum()\n","    return filtered / s if s > 0 else filtered\n","\n","def top_p_filter(probs, p):\n","    probs = np.asarray(probs, dtype=np.float64)\n","    if not (0 < p <= 1):\n","        raise ValueError(\"p must be in (0, 1].\")\n","    order = np.argsort(probs)[::-1]\n","    sorted_probs = probs[order]\n","    cumsum = np.cumsum(sorted_probs)\n","    keep_n = np.searchsorted(cumsum, p, side=\"left\") + 1\n","    keep_idx = order[:keep_n]\n","    filtered = np.zeros_like(probs)\n","    filtered[keep_idx] = probs[keep_idx]\n","    s = filtered.sum()\n","    return filtered / s if s > 0 else filtered"]},{"cell_type":"markdown","metadata":{"id":"b6441b90"},"source":["同じ logits から、温度とフィルタで分布がどう変形されるかを見る"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ccd4fb76","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768455603147,"user_tz":-540,"elapsed":26,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"7bafa351-33a9-40c2-8269-404da416600e"},"outputs":[{"output_type":"stream","name":"stdout","text":["T=0.7\n","  softmax : [0.707  0.1694 0.0829 0.0406 0.     0.    ]\n","  top-k=3 : [0.7369 0.1766 0.0865 0.     0.     0.    ]  (nonzero= 3 )\n","  top-p=0.9: [0.7369 0.1766 0.0865 0.     0.     0.    ]  (nonzero= 3 )\n","T=1.0\n","  softmax : [5.792e-01 2.131e-01 1.292e-01 7.840e-02 1.000e-04 0.000e+00]\n","  top-k=3 : [0.6285 0.2312 0.1402 0.     0.     0.    ]  (nonzero= 3 )\n","  top-p=0.9: [0.6285 0.2312 0.1402 0.     0.     0.    ]  (nonzero= 3 )\n","T=1.5\n","  softmax : [0.4653 0.2389 0.1712 0.1227 0.0012 0.0008]\n","  top-k=3 : [0.5315 0.2729 0.1955 0.     0.     0.    ]  (nonzero= 3 )\n","  top-p=0.9: [0.4662 0.2394 0.1715 0.1229 0.     0.    ]  (nonzero= 4 )\n"]}],"source":["z_demo = np.array([10.0, 9.0, 8.5, 8.0, 1.0, 0.5])\n","for T in [0.7, 1.0, 1.5]:\n","    p = softmax_temperature(z_demo, T)\n","    pk = top_k_filter(p, k=3)\n","    pp = top_p_filter(p, p=0.9)\n","    print(f\"T={T}\")\n","    print(\"  softmax :\", np.round(p, 4))\n","    print(\"  top-k=3 :\", np.round(pk, 4), \" (nonzero=\", np.count_nonzero(pk), \")\")\n","    print(\"  top-p=0.9:\", np.round(pp, 4), \" (nonzero=\", np.count_nonzero(pp), \")\")"]},{"cell_type":"markdown","metadata":{"id":"6af48422"},"source":["## 知識蒸留（distillation）における温度\n","知識蒸留では、教師モデルの出力分布を「柔らかく」して学生モデルに学習させるために  \n","温度を **学習中**に使うことがあります。\n","\n","概念的には：\n","- 教師：$p_T = \\mathrm{softmax}(z^{(teacher)}/T)$ を作る（$T>1$ で平坦化）\n","- 学生：その分布に近づくように KL などで学習\n","\n","これにより「最大クラス以外の相対関係」も学びやすくなります。\n"]},{"cell_type":"markdown","metadata":{"id":"c16870c7"},"source":["## attention の $1/\\sqrt{d}$ スケーリングと温度の類似点\n","Self-Attention では\n","\n","$$\n","A = \\mathrm{softmax}\\left(\\frac{QK^\\top}{\\sqrt{d}}\\right)\n","$$\n","\n","というスケーリングが入ります。これは「スコアの分散が大きくなり過ぎて softmax が飽和する」のを防ぐため\n","\n","形式的には **softmax の入力をスケールする**点で温度と似ている\n","\n","- 温度：$\\mathrm{softmax}(z/T)$\n","- attention：$\\mathrm{softmax}(\\, (QK^\\top)/\\sqrt{d} \\,)$\n","\n","ただし目的は異なり、\n","- attention のスケーリングは主に **次元依存の安定化**\n","- 生成時 temperature は主に **確率分布の鋭さ調整**"]},{"cell_type":"markdown","metadata":{"id":"219635e9"},"source":["# 課題(logits)\n","1. logits に定数を足しても softmax が変わらないことを、複数ランダム例で確認しなさい\n","2. 同じ logits に対して、温度と top-p を動かして「非ゼロ語彙数」の変化をプロットしなさい\n"]},{"cell_type":"markdown","source":["### Transformerにおける逐次処理\n","\n","RNNと比較すれば並列処理という観点で改善されているが、逐次処理をなくすことはできず、逐次処理が行われる\n","\n","- 推論時のDecoder部の動作について、最初にBOSを入力すると1つめの単語が出力され、その1つ目の単語を入力すると2つ目の単語が出力されという具合に、逐次的な処理が行われる\n","  - 並列的に処理する方法も考案されているが、精度で劣るという結果が得られている\n","  - RNNを取り除いても、完全に逐次処理がなくなったわけではない\n","  - Encoderと、学習時のDecoderは並列処理可能である\n"],"metadata":{"id":"RxmJTQkSTbxY"}},{"cell_type":"markdown","source":["## Transformerにおけるよくある誤解\n","\n","### LSTM vs Transformer\n","\n","LSTMよりもTransformerの方が長い文章処理が得意だ、と言われているが、これは安易にYesといえる問題ではない\n","\n","純粋に方法論・アルゴリズム的観点で答えるなら、LSTMと答えるべきである\n","- 潜在空間の扱いにもよるが、LSTMはシーケンス長よりも長い周期の入力を学習できる(LSTMの節を参照)\n","- Transformerは入力シーケンス長の範囲内のみ考える、つまり、それよりも長い内容はそもそも入力されず、勘案されない\n","\n","LSTMは、長期依存を理論的には保持できるが、勾配が完全に消えないというだけで、系列が数百～数千ステップになると情報保持は困難となる\n","- 依存関係がどこにあるかを探索的に学ばなければならず、遠い依存は弱まる傾向にある\n","\n","Transformerは、全結合的アテンションにより、系列内の任意の位置間の関係を直接参照可能\n","- 全ての位置関係を眺めているので、長期依存を 探索しやすい\n","- ただし、これは長期依存が本質的に得意というより設計的に全距離を直接観測できるからである\n","- その代償として、シーケンス長を$n$とすると、$O(n^2)$で計算コストが増加する\n","  - 長系列では非現実的になる\n","  - Efficient Attention系の研究が盛んである理由\n","\n","### なぜ、LSTM < Transformerなのか\n","\n","Self-Attentionの主要計算は 内積演算（GEMM, General Matrix Multiply）であり、GPUは元々BLASライブラリやTensorCoreでGEMMを極端に効率化できるアーキテクチャを採用している\n","\n","- つまりモデルが長期依存を学べるのではなく計算資源をうまく利用できる\n","- GPUの計算パワーを引き出すことができるために無理やり長い系列を入れ込んで処理している\n","  - つまり、見掛け倒しの長期記憶？である\n","- LSTMの逐次計算（シーケンシャル依存が強い）はGPU実装適していない\n","\n","### Transformerが長期依存に強いと言われる理由\n","\n","まとめると、次の理由となる\n","\n","- Attentionにより、計算的に全依存を一度に見ることができる\n","  - 勾配を時間方向に伝播させる必要がない\n","  - LSTMは時系列を逐次的に逆伝播\n","\n","- GPUとの親和性が高い\n","  - GEMMをフル活用でき長系列でも現実的に学習可能\n","\n","- 実証的に自然言語処理・時系列解析のベンチマークで性能が良い\n","  - 原理的に強いというよりも、実装と計算環境の進化のおかげ"],"metadata":{"id":"1R21CvyHz15Q"}},{"cell_type":"markdown","metadata":{"id":"D1PpwmcMJFRB"},"source":["# Transformerモデルを用いた文章分類\n","\n","シンプルなクラス分類のTransformerモデルをフルスクラッチで実装する\n","- 映画の英語レビューがポジティブな内容かネガティブな内容かを判定させる\n","- どのような単語に注目して判定したのかをSelf-Attentionの結果から可視化する"]},{"cell_type":"markdown","metadata":{"id":"3IBOjXDeJFRE"},"source":["## 事前準備\n","\n","今回はフルスクラッチで記述するため、シンプルである\n","- このあと機能に特化したライブラリは個別に読み込んでいる\n","- なお、PyTorchのTransformerライブラリを用いるなどして、個別モジュールの設計を避けてパーツを組み合わせることで実装することを推奨する\n","- 提供されるライブラリは下記の記述よりも実行速度が速い、最適化されている、より優れた実装が採用されている、なによりも精度が高くなるなど、良いことばかりであり、そもそも利用するという立場では一から設計する意味はほとんどない"]},{"cell_type":"code","source":["!pip install datasets  # Hugging Face"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CaYfoM__4kB6","executionInfo":{"status":"ok","timestamp":1768455612705,"user_tz":-540,"elapsed":9578,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"6182755d-788a-48f0-a3c7-68f216262a1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2026.1.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"]}]},{"cell_type":"code","metadata":{"id":"w1kMABqAJFRF"},"source":["import math\n","import numpy as np\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["nlpライブラリは様々なデータセットを提供している\n","- 映画評論データセットを入手するために利用する"],"metadata":{"id":"6Yp9AeCnpwLj"}},{"cell_type":"code","metadata":{"id":"7qg6t5nnBjqs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768455630817,"user_tz":-540,"elapsed":11021,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"cf31f30b-b4a9-4825-e517-3abf979398c1"},"source":["# nlpライブラリは古いため、新しいdatasetsライブラリを使用\n","!pip install datasets\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2026.1.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"]}]},{"cell_type":"markdown","source":["### 自作トークナイザーの使用\n","\n","ここでは、外部ライブラリに依存しない自作のトークナイザーを使用する\n","- `simple_tokenizer`: 正規表現を使った基本的な英語トークナイザー\n","- `Vocabulary`: 語彙管理クラス（トークンとIDの相互変換）\n","- 外部ライブラリ（transformers, torchtext等）への依存を完全に排除し、互換性を向上\n","\n","**重要な点**\n","今回はフルスクラッチで学習させるため、どのようなTokenizerを用いても構わない\n","- なんなら自作でも構わない（今回はまさにそれ）\n","\n","事前学習済みモデルを利用する場合は、そのモデルが用いたTokenizerを用いなければ正しい結果を得ることができない\n","- 当然であるが、「私」を10に変換していたのが、変わって20に変換されては精度が落ちて当然\n","- 危険なのは、この件に限らず、間違えても頑張って学習する結果、それなりに精度が出るため、「誤りを、誤りと気づきにくい」点に注意が必要である\n"],"metadata":{"id":"a6N8vPoOp4-Z"}},{"cell_type":"code","source":["# 外部ライブラリに依存しない自作トークナイザーを使用\n","# torchtext, transformersは不要です\n","import re\n","from collections import Counter\n","print(\"自作トークナイザーを使用します\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WrkJBTwtoGXN","executionInfo":{"status":"ok","timestamp":1768455630856,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"5ddebf02-b994-4342-99a3-9fb28e8145aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["自作トークナイザーを使用します\n"]}]},{"cell_type":"markdown","metadata":{"id":"aWCmm2TjqToE"},"source":["### データセットの読み込み\n","\n","nlpライブラリに含まれるIMDbデータセットを利用する\n","- IMDbデータセットは、ポジティブかネガティブの好悪感情を表すラベルが付与された25000の映画レビューコメントデータセット\n","- 好意的なレビューは1、否定的なレビューは0が振られている\n","- 感情分析用では鉄板のデータセット\n","\n","https://www.imdb.com/interfaces/"]},{"cell_type":"code","metadata":{"id":"rfEnNpv9HuXI","colab":{"base_uri":"https://localhost:8080/","height":401,"referenced_widgets":["64ee62d4b8b04e9880c103abf19affcd","360281624be845c5ba337af8b1230885","8c83027cad38415a887dafe4a8bf4808","f3956cf1f6904293ae5ad522bc495790","bd6eb41d41f64366b44c8b9115f3de48","3be47ce2fd7f4aada2a31fc315a72ce9","980382701ad64b54818a8b49cf656b07","a38d6c434ae54b8792ffa5e2b2bafadd","db2d395d79d74b52a66aadecd45697a3","e75e7c021ea54c17a8bdc6222dd8e30a","c7858e6df59e472aa00740d626bc9d81","085b59eade3f4f85a45cae3a023ff9e1","af346e77793a412bab0d6f8844835f61","8a21f4565ea74e2991546a20a0aac2ba","2a9f61bc272c44aba276e5eb2b25a984","d2ea81366fc840a5af0bd3e83ea13ad9","e7e76d10d9f54662b82c8102a5ea90cf","f3fcf11797f74cc5b014cf0c2e3fac99","815f933ac786483fb46aa57dc313238c","13acc8fb84524969a468646625997ffc","991fd59782084434b5d0267d646cec07","422bb954b5ec48de805a628b7ff393b0","df7f4a1c9aea4e5e9336c3e1d3a7ad3e","d7d0431fad2f46719066a6c2dfd226ef","967185d4b8024385b0b50af8ada043de","7badd33b792e4386b42594b3cdcda746","378b4e4976fe4879b63f9937fa3eabee","3b61a253db2b49ad9e9c4cb84ffa8e4c","9577196a4a944422a1d3d24db14cd0db","dbdaece280854e4c98bce6d80b4b5b80","23f6d9b31e0f408c9f191e8797f6c333","9cd70b3ed440401a93309ea8d62ac59d","c0622b945736420f87210d06d235f3ce","6b38d017450e4eb297536835c8383e4c","0f7b13b0f97749ac97047f54987155fd","448e0a8afb204eea92c7e0a0f884a239","98d9daa7470346abb9ea0c412dd060e0","de861fbd56b84428abb02145cdaa0a7f","285b021c2ecf4ac482d29fcaace54544","36b2b9380fff46f089a170fe5929cd02","29e9d8cbb5be4e7b951bcba7ef877179","ac8aa861f8304a6e9b1ab80b858ee380","83191d45c3974d35ab0ad607ab8c3031","d116a4c7543d45be9b72d5869cc5e4d8","1c3ad583896a417bbf2f03a4908194a1","ebc18c9b65594f27bb227a4202d554e2","0982c66f91224227af0620fd20379e75","f0b84155f75c431aa49b46b19dd60098","9b3d3e3340934138bafe0a09d88eda15","4b18ff24ac5b4e87aa7e33bd1447926e","510f786116684be7af8088bb96d76efe","309961f5c4bb435f9c2af804d2e819e8","07979e5ce3de47ca8206c9905e5c2a21","16273c3269334913b24cdb3e4e545351","31973416332d487685406736623ffec3","0568cca62bee470a898350fb4e3b7f0f","74fd33975a7b4df5910b2c3f1699fcdb","a8df1944e78a45bb84dfe36470f1099a","3bddcf45663a4e1491b92822eea6645b","51c1e9d3994c4154914c774464ce0b42","ccedc935438542b99ff5932366800718","5e583d0c4c474685b810506c687fd961","35665fda4d4840df8b4b4c502fbd85f3","c15897f684d5431997877dcf17dff432","986244fe2a804fdcb5ad46073d21afbe","ff81a4f4cc4f4ad9b6c01f854b120351","150b9d62e41140e6ab847bf0bc31949f","e8850b7c83e24af8915377555cc567ae","edb292a7a259416faa8476051660c031","1a8c84bae1da40939271fd2251845c32","8b67ed3ccfce417ab4064186957604b5","666b35a49c474bfba818a724a2dc1f6f","e2fcab047c05419db98afac5fbac4d62","37154c504bbe4c6fad59a5fe3dcaf1d0","35ee513c7d5b47bba468d710b1bd28f0","9e0885e20e0c4a9aa904578e121e10cb","c09516ee96b44669b777997c9735c11d"]},"executionInfo":{"status":"ok","timestamp":1768455749119,"user_tz":-540,"elapsed":7331,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"f8a7b624-f72f-4176-c70a-8d927083bcce"},"source":["from datasets import load_dataset\n","raw_train_data, raw_test_data = load_dataset(\"imdb\", split=[\"train\", \"test\"])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["README.md: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64ee62d4b8b04e9880c103abf19affcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"085b59eade3f4f85a45cae3a023ff9e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df7f4a1c9aea4e5e9336c3e1d3a7ad3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["plain_text/unsupervised-00000-of-00001.p(…):   0%|          | 0.00/42.0M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b38d017450e4eb297536835c8383e4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c3ad583896a417bbf2f03a4908194a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0568cca62bee470a898350fb4e3b7f0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"150b9d62e41140e6ab847bf0bc31949f"}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"7t_nwDeOX2Ok"},"source":["例としてデータを表示する\n","- 英語です、がっかりしましたか？"]},{"cell_type":"code","metadata":{"id":"EAB_DeeTX1uu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768455749166,"user_tz":-540,"elapsed":45,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"93f5bca7-b7dd-461c-eadf-7c90a7752c0f"},"source":["print(raw_train_data[\"label\"][0], raw_train_data[\"text\"][0])  # 好意的なコメントの例\n","print(raw_train_data[\"label\"][20000], raw_train_data[\"text\"][20000])  # 否定的なコメントの例"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n","1 After reading some quite negative views for this movie, I was not sure whether I should fork out some money to rent it. However, it was a pleasant surprise. I haven't seen the original movie, but if its better than this, I'd be in heaven.<br /><br />Tom Cruise gives a strong performance as the seemingly unstable David, convincing me that he is more than a smile on legs (for only the third time in his career- the other examples were Magnolia and Born on the Fourth of July). Penelope Cruz is slightly lightweight but fills the demands for her role, as does Diaz. The only disappointment is the slightly bland Kurt Russell. In the movie, however, it is not the acting that really impresses- its the filmmaking.<br /><br />Cameron Crowe excels in the director's role, providing himself with a welcome change of pace from his usual schtick. The increasing insanity of the movie is perfectly executed by Crowe (the brief sequence where Cruise walks through an empty Time Square is incredibly effective). The soundtrack (a distinguishing feature of a Crowe movie) is also sublime.<br /><br />You will be shocked and challenged as a viewer. The plot does seem a little contrived but the issues explored behind it are endlessly discussable. The movie isn't perfect, but its a welcome change of pace for Cruise and Crowe and for those raised on a diet of Hollywood gloss, should be a revelation.\n"]}]},{"cell_type":"markdown","metadata":{"id":"CFIcwJVIaAs-"},"source":["DeepLで訳してみると次のような感じです\n","\n","> 1 ブロムウェル・ハイ」は、カートゥーン・コメディです。ブロムウェル・ハイ』は、『ティーチャーズ』のような学校生活を描いた番組と同時期に放送されていました。私の35年間の教師生活を振り返ると、「ブロムウェル・ハイ」の風刺は「ティーチャーズ」よりもはるかに現実に近いものだと思います。経済的に生き残るために奔走する姿、哀れな教師たちの虚勢を見抜く洞察力のある生徒たち、そしてすべての状況の情けなさは、私が知っている学校とその生徒たちを思い出させてくれます。生徒が何度も学校を燃やそうとしたエピソードを見たとき、すぐに ......... .......... のことを思い出しました。高いですね。古典的なセリフです。検閲官：あなた方の先生の一人をクビにするために来ました。生徒：Bromwell Highへようこそ。私と同年代の大人の多くは、「ブロムウェルハイ」を奇想天外なものだと思っているのではないでしょうか。そうでないのが残念です。\n","\n","> 0 この映画は努力していますが、1960年代のテレビシリーズの面白さが完全に欠けています。私は17歳ですが、ずいぶん前にYouTubeでこのシリーズを見たことがあり、楽しくて仕方がありませんでした。特殊効果は標準的ではなく、平板なカメラワークによって助けられていませんでした。また、「ホームアローン4」、「帽子をかぶった猫」、「きかんしゃトーマス」、「アダムス・ファミリー・リユニオン」などの作品があります。さて、ストーリーのアイデアは良かったのですが、残念ながら出来が悪く、早々に力尽きてしまったので、正直、家族で楽しめる作品ではないと思います。また、ウェイン・ナイトが気合を入れて演じたにもかかわらず、しゃべるスーツにも腹が立ちました。しかし、この映画で最も腹が立ったのは、クリストファー・ロイド、ジェフ・ダニエルズ、ダリル・ハンナという才能ある俳優を無駄にしてしまったことです。ジェフ・ダニエルズはこれまでも良い演技をしてきましたが、彼は何をすべきかわからないようでしたし、エリザベス・ハーリーのキャラクターも残念ながら役立たずでした。ダリル・ハンナは素敵な女優だが、一般的には無視されており、私は彼女が愛の対象になるというアイデアが好きだったが、残念ながら彼女の姿はほとんど見られない。（モンスターの攻撃は、子供たちを魅了するというよりも、怖がらせる可能性が高いのは言うまでもない）同様に、ウォレス・ショーンもある種の政府の工作員として登場する。        1/10 ベサニー・コックス"]},{"cell_type":"markdown","metadata":{"id":"ZsgQNMJxpBnW"},"source":["### 自作Tokenizerと語彙の構築\n","\n","自作のトークナイザーを使用し、IMDbデータセットから語彙を構築する\n","- `simple_tokenizer`: 小文字化、句読点分離などの基本的な前処理を行う\n","- `Vocabulary`クラス: 語彙には`<pad>`（パディング）と`<unk>`（未知語）の特殊トークンを追加\n","- 出現頻度が低すぎる単語（min_freq未満）は`<unk>`として扱う\n"]},{"cell_type":"code","metadata":{"id":"9R0HK29fHrf3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768455753387,"user_tz":-540,"elapsed":3821,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"cb74c6ce-634f-4b4b-dd0c-7215e0a69540"},"source":["# 自作トークナイザーと語彙クラス（外部ライブラリ不要）\n","import re\n","from collections import Counter\n","\n","def simple_tokenizer(text):\n","    \"\"\"基本的な英語トークナイザー（外部ライブラリ不要）\"\"\"\n","    text = text.lower()\n","    # 句読点を分離し、英数字以外をスペースに\n","    text = re.sub(r\"([.!?,;:])\", r\" \\1 \", text)\n","    text = re.sub(r\"[^a-zA-Z0-9\\s.!?,;:]\", \" \", text)\n","    tokens = text.split()\n","    return tokens\n","\n","class Vocabulary:\n","    \"\"\"語彙管理クラス\"\"\"\n","    def __init__(self, specials=['<pad>', '<unk>']):\n","        self.token2idx = {}\n","        self.idx2token = {}\n","        for token in specials:\n","            self._add_token(token)\n","        self.unk_idx = self.token2idx.get('<unk>', 1)\n","\n","    def _add_token(self, token):\n","        if token not in self.token2idx:\n","            idx = len(self.token2idx)\n","            self.token2idx[token] = idx\n","            self.idx2token[idx] = token\n","\n","    def build_from_dataset(self, dataset, tokenizer, min_freq=2):\n","        \"\"\"データセットから語彙を構築\"\"\"\n","        counter = Counter()\n","        for item in dataset:\n","            tokens = tokenizer(item['text'])\n","            counter.update(tokens)\n","\n","        for token, freq in counter.items():\n","            if freq >= min_freq:\n","                self._add_token(token)\n","\n","        return self\n","\n","    def __len__(self):\n","        return len(self.token2idx)\n","\n","    def __call__(self, tokens):\n","        \"\"\"トークンリストをIDリストに変換\"\"\"\n","        return [self.token2idx.get(token, self.unk_idx) for token in tokens]\n","\n","    def lookup_token(self, idx):\n","        \"\"\"IDからトークンに変換\"\"\"\n","        return self.idx2token.get(idx, '<unk>')\n","\n","# トークナイザー関数を設定\n","tokenizer_func = simple_tokenizer\n","\n","# 語彙を構築\n","print(\"IMDbデータから語彙を構築中...\")\n","vocab = Vocabulary(specials=['<pad>', '<unk>'])\n","vocab.build_from_dataset(raw_train_data, tokenizer_func, min_freq=2)\n","\n","# パディングトークンのID\n","PAD_IDX = vocab.token2idx['<pad>']\n","UNK_IDX = vocab.token2idx['<unk>']\n","\n","print(f\"語彙サイズ: {len(vocab)}\")\n","print(f\"PAD_IDX: {PAD_IDX}, UNK_IDX: {UNK_IDX}\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["IMDbデータから語彙を構築中...\n","語彙サイズ: 46946\n","PAD_IDX: 0, UNK_IDX: 1\n"]}]},{"cell_type":"markdown","source":["### Tokenizerの動作確認\n","\n","試しに一文をトークン化して、単語IDに変換する様子を確認する\n"],"metadata":{"id":"qBcib8lrsMTG"}},{"cell_type":"code","source":["# トークナイザーの動作確認\n","sample_text = raw_train_data['text'][0]\n","tokens = tokenizer_func(sample_text)\n","token_ids = vocab(tokens)\n","print(f\"元のテキスト（最初の100文字）: {sample_text[:100]}...\")\n","print(f\"トークン（最初の10個）: {tokens[:10]}\")\n","print(f\"トークンID（最初の10個）: {token_ids[:10]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FlwUvUuYAKRq","executionInfo":{"status":"ok","timestamp":1768455895184,"user_tz":-540,"elapsed":48,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"10b20449-5091-41e2-c464-7b6321a43398"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["元のテキスト（最初の100文字）: I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it w...\n","トークン（最初の10個）: ['i', 'rented', 'i', 'am', 'curious', 'yellow', 'from', 'my', 'video', 'store']\n","トークンID（最初の10個）: [2, 3, 2, 4, 5, 6, 7, 8, 9, 10]\n"]}]},{"cell_type":"markdown","source":["必要なパラメタを定義する\n","- 各データセットの文章数\n","- バッチサイズ\n","- 最大の文章長さ(これ以上の長さは切られる)"],"metadata":{"id":"dmbl19bhsUo4"}},{"cell_type":"code","source":["num_train_data = raw_train_data.num_rows\n","num_test_data = raw_test_data.num_rows\n","batch_size = 32\n","max_seq_len = 256"],"metadata":{"id":"uOMmUJuzINJy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tz0UpoNQYIzs"},"source":["### データの前処理\n","\n","訓練データとテストデータをトークン化し、PyTorchのDataLoaderで使用できる形式に変換する\n","\n","- `tokenize_and_pad`: テキストをトークン化し、固定長にパディング\n","- `tokenize_data`: データセット全体をトークン化してテンソルに変換\n","- `IMDbDataset`: PyTorchのDatasetクラスを継承したカスタムクラス\n","\n","処理内容：\n","- 各テキストをトークン化して語彙IDに変換\n","- `max_seq_len`より長い文章は切り詰め（truncation）\n","- 短い文章は`<pad>`トークンで埋める（padding）\n","- `attention_mask`を作成（実際のトークン=1、パディング=0）\n"]},{"cell_type":"code","metadata":{"id":"Z2UD6DkjXzto","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768455911863,"user_tz":-540,"elapsed":10751,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"3c664700-ae21-442f-c4f3-2d21c1d61a0e"},"source":["# 自作トークナイザーを使ったデータ前処理\n","\n","def tokenize_and_pad(text, max_len):\n","    \"\"\"テキストをトークン化してパディング\"\"\"\n","    tokens = tokenizer_func(text)\n","    token_ids = vocab(tokens)\n","\n","    # truncation\n","    if len(token_ids) > max_len:\n","        token_ids = token_ids[:max_len]\n","\n","    # padding\n","    pad_len = max_len - len(token_ids)\n","    attention_mask = [1] * len(token_ids) + [0] * pad_len\n","    token_ids = token_ids + [PAD_IDX] * pad_len\n","\n","    return token_ids, attention_mask\n","\n","def tokenize_data(dataset, max_seq_len):\n","    \"\"\"データセットをトークン化してPyTorchテンソルに変換\"\"\"\n","    input_ids_list = []\n","    attention_mask_list = []\n","    labels_list = []\n","\n","    for item in dataset:\n","        token_ids, attention_mask = tokenize_and_pad(item['text'], max_seq_len)\n","        input_ids_list.append(torch.tensor(token_ids, dtype=torch.long))\n","        attention_mask_list.append(torch.tensor(attention_mask, dtype=torch.long))\n","        labels_list.append(item['label'])\n","\n","    return {\n","        'input_ids': torch.stack(input_ids_list),\n","        'attention_mask': torch.stack(attention_mask_list),\n","        'label': torch.tensor(labels_list)\n","    }\n","\n","# カスタムDatasetクラス\n","class IMDbDataset(torch.utils.data.Dataset):\n","    def __init__(self, data_dict):\n","        self.input_ids = data_dict['input_ids']\n","        self.attention_mask = data_dict['attention_mask']\n","        self.labels = data_dict['label']\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'input_ids': self.input_ids[idx],\n","            'attention_mask': self.attention_mask[idx],\n","            'label': self.labels[idx]\n","        }\n","\n","print(\"訓練データをトークン化中...\")\n","train_tokenized = tokenize_data(raw_train_data, max_seq_len)\n","train_dataset = IMDbDataset(train_tokenized)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","print(\"テストデータをトークン化中...\")\n","test_tokenized = tokenize_data(raw_test_data, max_seq_len)\n","test_dataset = IMDbDataset(test_tokenized)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n","\n","print(f\"訓練データ数: {len(train_dataset)}, テストデータ数: {len(test_dataset)}\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["訓練データをトークン化中...\n","テストデータをトークン化中...\n","訓練データ数: 25000, テストデータ数: 25000\n"]}]},{"cell_type":"markdown","source":["train_dataloaderから試しにデータを取得する"],"metadata":{"id":"ES7ekokus76v"}},{"cell_type":"code","source":["next(iter(train_loader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8M7xA7-ktYvo","executionInfo":{"status":"ok","timestamp":1768455958540,"user_tz":-540,"elapsed":47,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"4be47060-c81d-45b9-af2e-aa2236fe669e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[  34,  266,   32,  ...,   44,  624, 7286],\n","         [2150,    2,  130,  ...,   14, 2570,   93],\n","         [   7,   58,   14,  ...,    0,    0,    0],\n","         ...,\n","         [  39,  157, 3819,  ...,    0,    0,    0],\n","         [1094, 5661,   45,  ...,    0,    0,    0],\n","         [  39,  379, 1341,  ...,    0,    0,    0]]),\n"," 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         ...,\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0]]),\n"," 'label': tensor([1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n","         1, 0, 0, 0, 0, 0, 1, 1])}"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["語彙数、つまりTokenizerが知っている単語の種類の数をパラメータとして設定する"],"metadata":{"id":"Y-izvBgJvpbb"}},{"cell_type":"code","source":["vocab_size = len(vocab)\n","print(f\"語彙サイズ: {vocab_size}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJ00Kxq20qSZ","executionInfo":{"status":"ok","timestamp":1768455961169,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"6f6eed88-6903-42b3-bd51-c3d2d07da6fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["語彙サイズ: 46946\n"]}]},{"cell_type":"markdown","source":["## Transformerのネットワーク構造\n"],"metadata":{"id":"Revn7i8dCLlO"}},{"cell_type":"markdown","source":["### 各層の結合とデータサイズ\n","\n","入カはミニバッチ数$M(=256)$、一文の単語数$W(=256)$とすると、$M\\times W$\n","\n","処理は次の通りとなる\n","\n","- 内部の単語の表現ベクトル$V(=300)$とすると、Embedderにより、単語一つがV次元のベクトル表現になり、その出力は$M\\times W \\times V$となる\n","  - Embedding層は内部で、まず入力記号OneHotベクトルに変換し、そのOneHotベクトルをより低次のベクトル空間上に線形写像している\n","- Embedderの後、PositionalEncoder、TransformerBlockへと処理が映るが、これらは全て入出力で次元を変更していない\n","- 最後のTransformerBlockの出力がClassificationHeadにおいて、クラス数$C(=2)$に変換され、結果的に$M\\times C$となる"],"metadata":{"id":"ik1knMVh9mBD"}},{"cell_type":"markdown","source":["### 各層の動作内容\n","\n","- Embedding\n","  - ここでは、PyTorchが提供するnn.Embeddingを用いており、誤差逆伝搬により更新される\n","  - その他、fasttextや、Word2Vecなどによる事前学習に基づいた分散表現変換も想定される\n","- PositionalEncoder\n","  - 入カデータに位置情報を足し算する\n","  - Self-Attentionを利用するため、各単語がどの単語と関係するかはAttentionで計算、獲得できる\n","  - すると、入力文章の単語の順番がシャッフルされた場合、同様に処理すると、語順という概念が欠落して同じ結果が出る可能性がある、すなわち語順が考慮されない、という問題を解決する\n","  - 今回のように文章の構造を判断材料に入れたいという場合に導入している\n","\n","- TransformerBlock\n","  - 任意の回数繰り返して利用する\n","    - Transformerの図で$\\times n$と記載されている通り\n","  - ここでは2段構成となっている\n","  - 入力のmaskはAttention Mapの一部の値を0に置き換える\n","  - 文章がmax_lengthの256文字よりも短くパディング、つまり<pad>が埋め込まれている部分についてAttentionを求めないように、その重みを0とする\n","  - 翻訳タスクなどのデコーダ側では、マスクされた単語を補完する、マスク位置を次々とずらすことで文章を完成させるといったタスクを達成するために利用する\n","\n","- ClassificationHead\n","  - 今回のタスクがクラス分けであるため、Transformer標準ではないが、最後に設けて次元数2の出力に変換する"],"metadata":{"id":"RcquWAj4CYWr"}},{"cell_type":"markdown","source":[],"metadata":{"id":"1Gr2vIJ1JK8p"}},{"cell_type":"markdown","source":["### Embedder\n","\n","既述は次の通り\n","\n","主なオプションは次の通り\n","- `num_embeddings（int）`: 埋め込み辞書のサイズ\n","- `embedding_dim（int）`: 各埋め込みベクトルのサイズ\n","- `freeze=True`: ここでは利用していないが、誤差逆伝搬において内部重みの更新を阻止する"],"metadata":{"id":"qMSfC0FSJPZX"}},{"cell_type":"code","metadata":{"id":"iAB9spQJJFRM"},"source":["class Embedder(nn.Module):\n","    def __init__(self, num_embeddings, embedding_dim):\n","        super(Embedder, self).__init__()\n","        self.embeddings = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim)\n","\n","    def forward(self, x):\n","        x_vec = self.embeddings(x)\n","        return x_vec"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Embedderの動作を確認する"],"metadata":{"id":"zWxZYSxo3rAn"}},{"cell_type":"code","source":["# モデル構築\n","net1 = Embedder(vocab_size,300)\n","# 入出力\n","test_batch = next(iter(train_loader))\n","x = test_batch['input_ids']\n","x1 = net1(x)  # 単語をベクトルに\n","print(\"入力のテンソルサイズ：\", x.shape)\n","print(\"出力のテンソルサイズ：\", x1.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1r9QL3S0vJa5","executionInfo":{"status":"ok","timestamp":1768455972099,"user_tz":-540,"elapsed":230,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"957e757f-f8e7-4e36-9b60-1e161dd8b6ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["入力のテンソルサイズ： torch.Size([32, 256])\n","出力のテンソルサイズ： torch.Size([32, 256, 300])\n"]}]},{"cell_type":"markdown","source":["### PositionalEncoder\n","\n","入力された単語の位置を示すベクトル情報`pe`を付加する\n","- 位置の計算式はTransformerの論文のままの標準的な方法\n","- 文章が短く、単語ベクトルがPositional Encodingよりも小さい場合に対応するため、$\\sqrt{V}$を掛けて大きさをある程度そろえる処理が加わっている\n","- `pe`は何度も計算するわけではなく、コンストラクタにおいて、テーブルとして保持している\n","- `pe`は勾配計算の対象外であるため、`requires_grad = False`を忘れないように\n","  - 計算しても動作するがpeが更新され変更される\n","  - 結果として実行速度低下を招く\n","  - 精度低下を招くかどうかはなんともいえない\n","    - 課題としてトライしてみるとよいだろう"],"metadata":{"id":"6goQ4l5B1-md"}},{"cell_type":"code","metadata":{"id":"S-R3xrLWJFRU"},"source":["class PositionalEncoder(nn.Module):\n","    def __init__(self, d_model=300, max_seq_len=max_seq_len, devname='cpu'):\n","        super().__init__()\n","        self.d_model = d_model  # 単語ベクトルの次元数\n","        pe = torch.zeros(max_seq_len, d_model)\n","        pe = pe.to(devname)\n","        for pos in range(max_seq_len):\n","            for i in range(0, d_model, 2):\n","                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n","                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * i)/d_model)))\n","        self.pe = pe.unsqueeze(0) # 表peの先頭に、ミニバッチ次元となる次元を足す\n","        self.pe.requires_grad = False # 勾配を計算しないようにする\n","    def forward(self, x):\n","        # 入力xとPositonal Encodingを足し算する\n","        # xがpeよりも小さいので、大きくする\n","        ret = math.sqrt(self.d_model)*x + self.pe\n","        return ret"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["PositonalEncoderの動作確認を行う"],"metadata":{"id":"CZ4ZKoA6Mi_W"}},{"cell_type":"code","metadata":{"id":"SZoqYmiiJFRX","executionInfo":{"status":"ok","timestamp":1768455972495,"user_tz":-540,"elapsed":397,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"553d67da-8b0d-4d77-8821-65f55bcd369b"},"source":["# モデル構築\n","net2 = PositionalEncoder(d_model=300, max_seq_len=max_seq_len)\n","# 入出力\n","x = test_batch['input_ids']\n","x1 = net1(x)  # 単語をベクトルに\n","x2 = net2(x1)\n","print(\"入力のテンソルサイズ：\", x1.shape)\n","print(\"出力のテンソルサイズ：\", x2.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["入力のテンソルサイズ： torch.Size([32, 256, 300])\n","出力のテンソルサイズ： torch.Size([32, 256, 300])\n"]}]},{"cell_type":"markdown","source":["### TransformerBlock\n","\n","LayerNormalization、Dropout、Attention、FeedForwardで構成\n","\n","- LayerNormalization: 各単語が持つ$V$個の特徴量に対し、その特徴量毎に正規化を行う\n","  - 各特徴量が持つ$V$次元の要素の平均と標準偏差が、それぞれ0と1になるように正規化\n","\n","- Attentionにおいて特徴量が変換\n","- その出力にDropoutしたベクトルとLayerNormalizationの入力のベクトルを足し算する\n","- FeedForwardにより特徴量変換を行う\n","\n","なお、オリジナルのTransformerはMulti-Head Attentionであるが、ここではSingle Attentionで実装している\n","- Single Attentionを複数並列するとMulti-Headになる\n","- Milti-headについては演習で扱う\n","\n","- テキストの隙間埋めパディング`<pad>`の部分のmask値は0であるが、Attentionにおいてはこの部分を-le9というマイナス無限大に近い値に置き換える\n","- 結果的に、その後のSofmax計算で邪魔をしなくなる\n","  - Attention Mapにおいて0になるようにするため\n","\n","<img src=\"https://class.west.sd.keio.ac.jp/dataai/text/mytransformerblock.png\" width=500>"],"metadata":{"id":"v6vSrSptNX8m"}},{"cell_type":"code","metadata":{"id":"i8wcSoeDJFRa"},"source":["class Attention(nn.Module):\n","    def __init__(self, d_model=300):\n","        super().__init__()\n","        # SAGANでは1dConvを使用したが、今回は全結合層で特徴量を変換する\n","        self.q_linear = nn.Linear(d_model, d_model)\n","        self.v_linear = nn.Linear(d_model, d_model)\n","        self.k_linear = nn.Linear(d_model, d_model)\n","        self.out = nn.Linear(d_model, d_model)  # 出力時に使用する全結合層\n","        self.d_k = d_model  # Attentionの大きさ調整の変数\n","\n","    def forward(self, q, k, v, mask):\n","        # 全結合層で特徴量を変換\n","        k = self.k_linear(k)\n","        q = self.q_linear(q)\n","        v = self.v_linear(v)\n","        # Attentionの値を計算する\n","        weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.d_k)  # 値が大きくならないようroot(d_k)で割って調整\n","        mask = mask.unsqueeze(1) # maskを計算\n","        weights = weights.masked_fill(mask == 0, -1e9)\n","        normlized_weights = F.softmax(weights, dim=-1)  # softmaxで正規化\n","        output = torch.matmul(normlized_weights, v)  # AttentionをValueとかけ算\n","        output = self.out(output)  # 全結合層で特徴量を変換\n","        return output, normlized_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Attention層から出力を全結合層2つで特徴量を変換する"],"metadata":{"id":"eOog06Sxcr4T"}},{"cell_type":"code","metadata":{"id":"e1AcDAfjJFRe"},"source":["class FeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n","        super().__init__()\n","        self.linear_1 = nn.Linear(d_model, d_ff)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear_2 = nn.Linear(d_ff, d_model)\n","    def forward(self, x):\n","        x = self.linear_1(x)\n","        x = self.dropout(F.relu(x))\n","        x = self.linear_2(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQ5Y2sDDJFRh"},"source":["class TransformerBlock(nn.Module):\n","    def __init__(self, d_model, dropout=0.1):\n","        super().__init__()\n","        # LayerNormalization層\n","        self.norm_1 = nn.LayerNorm(d_model)\n","        self.norm_2 = nn.LayerNorm(d_model)\n","        # Attention層\n","        self.attn = Attention(d_model)\n","        # Attentionのあとの全結合層\n","        self.ff = FeedForward(d_model)\n","        # Dropout\n","        self.dropout_1 = nn.Dropout(dropout)\n","        self.dropout_2 = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask):\n","        x_normlized = self.norm_1(x)  # 正規化\n","        output, normlized_weights = self.attn(  # Attention\n","            x_normlized, x_normlized, x_normlized, mask)\n","        x2 = x + self.dropout_1(output)\n","        x_normlized2 = self.norm_2(x2)  # 正規化\n","        output = x2 + self.dropout_2(self.ff(x_normlized2)) # 全結合層\n","        return output, normlized_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 動作確認"],"metadata":{"id":"t2Yf3QtkNmmh"}},{"cell_type":"code","metadata":{"id":"KNaVWuNJJFRk","executionInfo":{"status":"ok","timestamp":1768455973049,"user_tz":-540,"elapsed":494,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"db479f45-59cc-4d82-b627-371239428a4a"},"source":["net3 = TransformerBlock(d_model=300)  # モデル構築\n","# maskの作成\n","x = test_batch['input_ids']\n","input_pad = PAD_IDX  # パディングトークンのID\n","input_mask = (x != input_pad)\n","# 入出力\n","x1 = net1(x)  # 単語をベクトルに\n","x2 = net2(x1)  # Positon情報を足し算\n","x3, normlized_weights = net3(x2, input_mask)  # Self-Attentionで特徴量を変換\n","print(\"入力のテンソルサイズ：\", x2.shape)\n","print(\"出力のテンソルサイズ：\", x3.shape)\n","print(\"Attentionのサイズ：\", normlized_weights.shape)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["入力のテンソルサイズ： torch.Size([32, 256, 300])\n","出力のテンソルサイズ： torch.Size([32, 256, 300])\n","Attentionのサイズ： torch.Size([32, 256, 256])\n"]}]},{"cell_type":"markdown","source":["### ClassificationHead\n","\n","評価のPositive/Negativeの2つのクラス分類を出力する\n","\n","ここで、どこを利用して特徴量を抽出するかについて選択肢がいくつかある\n","- 文章全体を用いて特徴量を抽出する\n","  - もちろん可能であり、こちらの方がよさそうですが、問題として文章の長さが異なるためパディングによる悪影響が回避できるかどうかが疑わしいという問題がある\n","  - これは、課題として比較してみるとよいであろう\n","- どこかしらの1つの特徴量を利用する\n","  - こうなるとどこか、ということであるが、先頭単語の特徴量を利用するという方針を選択している\n","  - これは、先頭単語に分類に必要な特徴量が存在するというわけではない\n","  - 学習によって、「そうなるように」能力を獲得させるということである\n","  - これでもうまくいくのだから、DNNはそれなりにミスがあっても、見当違いがあっても、おおらかに、かつ甘んじてそれを受け入れ、その制約の中で頑張って学習する健気な存在である"],"metadata":{"id":"MScWOg5K0RbN"}},{"cell_type":"code","metadata":{"id":"pcrNM1rpJFRn"},"source":["class ClassificationHead(nn.Module):\n","    '''Transformer_Blockの出力を使用し、最後にクラス分類させる'''\n","\n","    def __init__(self, d_model=300, output_dim=2):\n","        super().__init__()\n","\n","        # 全結合層\n","        self.linear = nn.Linear(d_model, output_dim)  # output_dimはポジ・ネガの2つ\n","\n","        # 重み初期化処理\n","        nn.init.normal_(self.linear.weight, std=0.02)\n","        nn.init.normal_(self.linear.bias, 0)\n","\n","    def forward(self, x):\n","        x0 = x[:, 0, :]  # 各ミニバッチの各文の先頭の単語の特徴量（300次元）を取り出す\n","        out = self.linear(x0)\n","\n","        return out\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Transformerの動作確認"],"metadata":{"id":"CL_p27fp2R2H"}},{"cell_type":"code","metadata":{"id":"WUVS-wxoJFRq","executionInfo":{"status":"ok","timestamp":1768455973447,"user_tz":-540,"elapsed":395,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"22810a8c-3281-4ea4-e90e-8c7a8c790a88"},"source":["batch = next(iter(train_loader))  # ミニバッチの用意\n","# モデル構築\n","net3 = TransformerBlock(d_model=300)\n","net4 = ClassificationHead(output_dim=2, d_model=300)\n","# 入出力\n","x =test_batch['input_ids'][0]\n","x1 = net1(x)  # 単語をベクトルに\n","x2 = net2(x1)  # Positon情報を足し算\n","x3, normlized_weights = net3(x2, input_mask)  # Self-Attentionで特徴量を変換\n","x4 = net4(x3)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n","print(\"入力のテンソルサイズ：\", x3.shape)\n","print(\"出力のテンソルサイズ：\", x4.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["入力のテンソルサイズ： torch.Size([32, 256, 300])\n","出力のテンソルサイズ： torch.Size([32, 2])\n"]}]},{"cell_type":"markdown","source":["最終的なTransformerモデルのクラス"],"metadata":{"id":"xXgFUcrH2doO"}},{"cell_type":"code","metadata":{"id":"k8-NHGc3JFRt"},"source":["class TransformerClassification(nn.Module):\n","    def __init__(self, num_embeddings, embedding_dim, d_model=300, max_seq_len=max_seq_len, output_dim=2):\n","        super().__init__()\n","        self.net1 = Embedder(num_embeddings, embedding_dim)\n","        self.net2 = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len, devname=device)\n","        self.net3_1 = TransformerBlock(d_model=d_model)\n","        self.net3_2 = TransformerBlock(d_model=d_model)\n","        self.net4 = ClassificationHead(output_dim=output_dim, d_model=d_model)\n","\n","    def forward(self, x, mask):\n","        x1 = self.net1(x)  # 単語をベクトルに\n","        x2 = self.net2(x1)  # Positon情報を足し算\n","        x3_1, normlized_weights_1 = self.net3_1(\n","            x2, mask)  # Self-Attentionで特徴量を変換\n","        x3_2, normlized_weights_2 = self.net3_2(\n","            x3_1, mask)  # Self-Attentionで特徴量を変換\n","        x4 = self.net4(x3_2)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n","        return x4, normlized_weights_1, normlized_weights_2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["最終的なTransformerモデルのクラスの動作確認"],"metadata":{"id":"kucURlu72kKc"}},{"cell_type":"code","metadata":{"id":"g2dt7_rvJFRv","executionInfo":{"status":"ok","timestamp":1768455975685,"user_tz":-540,"elapsed":2192,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ab0b56ec-4b3f-4e46-edc4-1d237d0dcb66"},"source":["model = TransformerClassification(  # モデル構築(batchは前の値を利用する)\n","\n","    num_embeddings=vocab_size, embedding_dim=300, d_model=300, max_seq_len=max_seq_len, output_dim=2).to(device)\n","\n","# 入出力\n","x = test_batch['input_ids']\n","x = x.to(device)\n","input_mask = (x != input_pad).to(device)\n","out, normlized_weights_1, normlized_weights_2 = model(x, input_mask)\n","\n","print(\"出力のテンソルサイズ：\", out.shape)\n","print(\"出力テンソルのsigmoid：\", F.softmax(out, dim=1))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["出力のテンソルサイズ： torch.Size([32, 2])\n","出力テンソルのsigmoid： tensor([[6.8553e-01, 3.1447e-01],\n","        [7.0590e-01, 2.9410e-01],\n","        [7.0682e-01, 2.9318e-01],\n","        [1.5546e-04, 9.9984e-01],\n","        [9.8479e-01, 1.5214e-02],\n","        [1.3973e-04, 9.9986e-01],\n","        [5.3647e-07, 1.0000e+00],\n","        [1.3032e-04, 9.9987e-01],\n","        [9.9601e-01, 3.9891e-03],\n","        [8.4748e-01, 1.5252e-01],\n","        [6.3207e-05, 9.9994e-01],\n","        [1.0000e+00, 1.8221e-07],\n","        [6.1064e-06, 9.9999e-01],\n","        [5.4062e-02, 9.4594e-01],\n","        [4.3518e-04, 9.9956e-01],\n","        [9.9813e-01, 1.8716e-03],\n","        [6.6183e-01, 3.3817e-01],\n","        [7.0044e-01, 2.9956e-01],\n","        [1.0000e+00, 4.8078e-06],\n","        [1.9338e-03, 9.9807e-01],\n","        [1.2850e-04, 9.9987e-01],\n","        [9.9968e-01, 3.1700e-04],\n","        [1.0630e-04, 9.9989e-01],\n","        [4.3344e-04, 9.9957e-01],\n","        [1.2404e-04, 9.9988e-01],\n","        [6.8568e-01, 3.1432e-01],\n","        [8.8811e-02, 9.1119e-01],\n","        [1.2294e-04, 9.9988e-01],\n","        [6.9446e-01, 3.0554e-01],\n","        [7.1750e-01, 2.8250e-01],\n","        [4.9678e-06, 9.9999e-01],\n","        [9.9774e-01, 2.2645e-03]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"xDdsFS7CXmXk"},"source":["### DatasetとDataLoaderの実装"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bgmPvIq6XmXk"},"outputs":[],"source":["# 辞書オブジェクトにまとめる\n","dataloaders_dict = {\"train\": train_loader, \"val\": test_loader}"]},{"cell_type":"markdown","source":["ネットワークの初期化として、 He の方法 (一様分布)を用いる\n","- 初期化については後で概要についてまとめる"],"metadata":{"id":"ziBFndlzLAQX"}},{"cell_type":"code","source":["def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Linear') != -1:\n","        # Liner層の初期化\n","        nn.init.kaiming_normal_(m.weight)\n","        if m.bias is not None:\n","            nn.init.constant_(m.bias, 0.0)\n","# 訓練モードに設定\n","model.train()\n","# TransformerBlockモジュールを初期化実行\n","model.net3_1.apply(weights_init)\n","model.net3_2.apply(weights_init)\n","model.to(device)  # モデルをGPUへ"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WSvPRAloQTFR","executionInfo":{"status":"ok","timestamp":1768455975730,"user_tz":-540,"elapsed":22,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"f363f909-ba56-42dc-cdf8-868e4c58c4bd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TransformerClassification(\n","  (net1): Embedder(\n","    (embeddings): Embedding(46946, 300)\n","  )\n","  (net2): PositionalEncoder()\n","  (net3_1): TransformerBlock(\n","    (norm_1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n","    (norm_2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n","    (attn): Attention(\n","      (q_linear): Linear(in_features=300, out_features=300, bias=True)\n","      (v_linear): Linear(in_features=300, out_features=300, bias=True)\n","      (k_linear): Linear(in_features=300, out_features=300, bias=True)\n","      (out): Linear(in_features=300, out_features=300, bias=True)\n","    )\n","    (ff): FeedForward(\n","      (linear_1): Linear(in_features=300, out_features=1024, bias=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","      (linear_2): Linear(in_features=1024, out_features=300, bias=True)\n","    )\n","    (dropout_1): Dropout(p=0.1, inplace=False)\n","    (dropout_2): Dropout(p=0.1, inplace=False)\n","  )\n","  (net3_2): TransformerBlock(\n","    (norm_1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n","    (norm_2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n","    (attn): Attention(\n","      (q_linear): Linear(in_features=300, out_features=300, bias=True)\n","      (v_linear): Linear(in_features=300, out_features=300, bias=True)\n","      (k_linear): Linear(in_features=300, out_features=300, bias=True)\n","      (out): Linear(in_features=300, out_features=300, bias=True)\n","    )\n","    (ff): FeedForward(\n","      (linear_1): Linear(in_features=300, out_features=1024, bias=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","      (linear_2): Linear(in_features=1024, out_features=300, bias=True)\n","    )\n","    (dropout_1): Dropout(p=0.1, inplace=False)\n","    (dropout_2): Dropout(p=0.1, inplace=False)\n","  )\n","  (net4): ClassificationHead(\n","    (linear): Linear(in_features=300, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"5hd6Ov0xXmXm"},"source":["### 損失関数と最適化手法を定義"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MyeBmPrMXmXm"},"outputs":[],"source":["# 損失関数の設定\n","criterion = nn.CrossEntropyLoss()\n","# nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n","\n","# 最適化手法の設定\n","learning_rate = 2e-5\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"yqIzemptXmXm"},"source":["### 学習・検証"]},{"cell_type":"markdown","source":["モデルを学習させる関数を作成"],"metadata":{"id":"0bSozxc_CTso"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"eq6aBPOTX9cB"},"outputs":[],"source":["def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n","    torch.backends.cudnn.benchmark = True  # ネットワークがある程度固定であれば高速化る\n","    for epoch in range(num_epochs):  # epochのループ\n","        for phase in ['train', 'val']:  # epochごとの訓練と検証のループ\n","            if phase == 'train':\n","                model.train()  # モデルを訓練モードに\n","            else:\n","                model.eval()  # モデルを検証モードに\n","            epoch_loss = 0.0  # epochの損失和\n","            epoch_corrects = 0  # epochの正解数\n","            for batch in (dataloaders_dict[phase]):  # データローダーからミニバッチを取り出す\n","                inputs = batch['input_ids'].to(device)  # 文章を可能ならばGPUへ\n","                labels = batch['label'].to(device)  # ラベルを可能ならばGPUへ\n","                optimizer.zero_grad()  # optimizerを初期化\n","                with torch.set_grad_enabled(phase == 'train'):  # 順伝搬の計算\n","                    # mask作成\n","                    input_mask = (inputs != input_pad)\n","                    input_mask = input_mask.to(device)\n","                    outputs, _, _ = model(inputs, input_mask)  # Transformerに入力\n","                    loss = criterion(outputs, labels)  # 損失を計算\n","                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n","                    if phase == 'train':  # 訓練時のみ勾配計算と更新\n","                        loss.backward()\n","                        optimizer.step()\n","                    epoch_loss += loss.item() * inputs.size(0)  # lossの合計を更新\n","                    epoch_corrects += torch.sum(preds == labels.data)  # 正解数の合計を更新\n","            # epochごとのlossと正解率\n","            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n","            epoch_acc = epoch_corrects.double(\n","            ) / len(dataloaders_dict[phase].dataset)\n","            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n","                phase, epoch_loss, epoch_acc))\n","    return net"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"80KEK8XJXmXn","outputId":"86cbd616-f09a-41a8-acd3-2b899743370e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768456444113,"user_tz":-540,"elapsed":463527,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10 | train |  Loss: 1.6111 Acc: 0.5266\n","Epoch 1/10 |  val  |  Loss: 1.2461 Acc: 0.5396\n","Epoch 2/10 | train |  Loss: 1.1020 Acc: 0.5717\n","Epoch 2/10 |  val  |  Loss: 1.0389 Acc: 0.5700\n","Epoch 3/10 | train |  Loss: 0.9224 Acc: 0.5937\n","Epoch 3/10 |  val  |  Loss: 0.9259 Acc: 0.5893\n","Epoch 4/10 | train |  Loss: 0.8096 Acc: 0.6169\n","Epoch 4/10 |  val  |  Loss: 0.8560 Acc: 0.6014\n","Epoch 5/10 | train |  Loss: 0.7365 Acc: 0.6393\n","Epoch 5/10 |  val  |  Loss: 0.8205 Acc: 0.6038\n","Epoch 6/10 | train |  Loss: 0.6803 Acc: 0.6606\n","Epoch 6/10 |  val  |  Loss: 0.7786 Acc: 0.6163\n","Epoch 7/10 | train |  Loss: 0.6384 Acc: 0.6773\n","Epoch 7/10 |  val  |  Loss: 0.7572 Acc: 0.6265\n","Epoch 8/10 | train |  Loss: 0.6067 Acc: 0.6914\n","Epoch 8/10 |  val  |  Loss: 0.7548 Acc: 0.6239\n","Epoch 9/10 | train |  Loss: 0.5765 Acc: 0.7086\n","Epoch 9/10 |  val  |  Loss: 0.7307 Acc: 0.6386\n","Epoch 10/10 | train |  Loss: 0.5513 Acc: 0.7229\n","Epoch 10/10 |  val  |  Loss: 0.7208 Acc: 0.6450\n"]}],"source":["# 学習・検証を実行する 15分ほどかかります\n","num_epochs = 10\n","net_trained = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"]},{"cell_type":"markdown","metadata":{"id":"vpzS-7IqXmXn"},"source":["正解率の計算と表示"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2xXiZX_UXmXn"},"outputs":[],"source":["net_trained.eval()   # モデルを検証モードに\n","net_trained.to(device)\n","epoch_corrects = 0  # epochの正解数\n","for batch in (test_loader):  # testデータのDataLoader\n","    inputs = batch['input_ids'].to(device)\n","    labels = batch['label'].to(device)\n","    with torch.set_grad_enabled(False):  # 順伝搬のみ計算\n","        input_mask = (inputs != input_pad)  # mask作成\n","        outputs, _, _ = net_trained(inputs, input_mask)  # Transformerに入力\n","        _, preds = torch.max(outputs, 1)  # ラベルを予測\n","        epoch_corrects += torch.sum(preds == labels.data)  # 結果の計算"]},{"cell_type":"markdown","source":["正解率の出力"],"metadata":{"id":"iNkXv2uL50cq"}},{"cell_type":"code","source":["\n","epoch_acc = epoch_corrects.double() / len(test_loader.dataset)\n","print('テストデータ{}個での正解率：{:.4f}'.format(len(test_loader.dataset),epoch_acc))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AEWYEqR-vUtF","executionInfo":{"status":"ok","timestamp":1768456455569,"user_tz":-540,"elapsed":46,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"f18f3cae-91c6-4866-b700-2413d64273b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["テストデータ25000個での正解率：0.6450\n"]}]},{"cell_type":"markdown","metadata":{"id":"ezyhNu5_XmXn"},"source":["## Attentionの可視化と判定根拠の判断\n","\n"]},{"cell_type":"markdown","source":["### HTML作成関数の実装\n","\n","なぜレビュー文章の内容をポジティブもしくはネガティブとモデルが判定したのか、判定する際に強くAttentionをかけた単語を可視化することで、その判定根拠を探る\n","- XAI(Explainable Artificial Intelligence :説明可能AI)の議論への対応として、説明性を持たせる判定根拠の可視化は重要\n","- 自然言語処理における判定根拠を明確に示す手法は確立していない\n","- Attentionが判定根拠になるかどうかは議論となっている\n","\n","文章の各単語についてAttentionの影響が強い単語の背景(HTMLのbackground-colorスタイル)ほどより赤くハイライトする\n","- Jupyter NotebookはHTML表示に対応するため、HTMLデータとして作成して表示する\n","- 文章の1単語目に埋め込まれているである<cls>の特徴量が分類の判断材料であるため、この特徴量を作成するために利用したSelf-Attentionをnormlized_weights から取り出して仕様する\n","  - TransformerBlockモジュールが2つあるため、1つ目と2つ目のattention\n","が存在する\n","\n","関数は次の2つ\n","- highlight\n","  Attentionの値が大きいと文字の背景が濃い赤になるhtmlを出力させる関数\n","- mk_html\n","  実際にHTMLデータを作成する\n"],"metadata":{"id":"kRk0d28JHpfQ"}},{"cell_type":"code","source":["def highlight(word, attn):\n","    \"\"\"Attentionの値が大きいと文字の背景が濃い赤になるhtmlを出力\"\"\"\n","    if (word == PAD_IDX or word == 0):\n","        return ''\n","    # vocab.lookup_tokenでIDから単語に変換\n","    wordc = vocab.lookup_token(word)\n","    html_color = '#%02X%02X%02X' % (\n","        255, int(255*(1 - attn)), int(255*(1 - attn)))\n","    return '<span style=\"background-color: {}\"> {}</span>'.format(html_color, wordc)\n","\n","def mk_html(index, batch, preds, normlized_weights_1, normlized_weights_2):\n","    \"\"\"HTMLデータを作成\"\"\"\n","    # indexの結果を抽出\n","    sentence = batch['input_ids'][index]  # 文章\n","    label = batch['label'][index]  # ラベル\n","    pred = preds[index]  # 予測\n","    # indexのAttentionを抽出と規格化\n","    attens1 = normlized_weights_1[index, 0, :]  # 1段目、0番目の<cls>についてのattention\n","    attens1 /= attens1.max()\n","    attens2 = normlized_weights_2[index, 0, :]  # 2段目、0番目の<cls>についてのattention\n","    attens2 /= attens2.max()\n","\n","    # ラベルと予測結果を文字に\n","    if label == 0:\n","        label_str = \"Negative\"\n","    else:\n","        label_str = \"Positive\"\n","\n","    if pred == 0:\n","        pred_str = \"Negative\"\n","    else:\n","        pred_str = \"Positive\"\n","\n","    # HTMLを作成\n","    html = '正解ラベル：{}<br>推論結果：{}<br><br>'.format(label_str, pred_str)\n","    html += '[TransformerBlock 1のAttention]<br>'\n","    for word, attn in zip(sentence, attens1):\n","        html += highlight(word.item(), attn.item())\n","    html += \"<br><br>\"\n","    html += '[TransformerBlock 2のAttention]<br>'\n","    for word, attn in zip(sentence, attens2):\n","        html += highlight(word.item(), attn.item())\n","\n","    return html\n"],"metadata":{"id":"F0_auT52jZRq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["実行するたびに異なる文章を評価できる\n","\n","- Positiveな文章ではPositiveな単語が、Negativeでは逆の単語に注目していることがわかる\n","- 結果を見てどのような文章で誤解しているのかなどを解析し、さらなる工夫を施すことが考えられる"],"metadata":{"id":"IVm70SXWqfpp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"C5yH0WycXmXo","outputId":"e1eca989-124b-4946-a4c3-41eb7f03dc11","colab":{"base_uri":"https://localhost:8080/","height":468},"executionInfo":{"status":"ok","timestamp":1768456455597,"user_tz":-540,"elapsed":25,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["正解ラベル：Negative<br>推論結果：Positive<br><br>[TransformerBlock 1のAttention]<br><span style=\"background-color: #FFE4E4\"> ashes</span><span style=\"background-color: #FFF0F0\"> of</span><span style=\"background-color: #FFFEFE\"> time</span><span style=\"background-color: #FFFEFE\"> was</span><span style=\"background-color: #FF0404\"> an</span><span style=\"background-color: #FFD5D5\"> audacious</span><span style=\"background-color: #FFF8F8\"> project</span><span style=\"background-color: #FFFCFC\"> but</span><span style=\"background-color: #FFFEFE\"> ended</span><span style=\"background-color: #FFFEFE\"> up</span><span style=\"background-color: #FFEBEB\"> being</span><span style=\"background-color: #FFF1F1\"> a</span><span style=\"background-color: #FFFEFE\"> pretentious</span><span style=\"background-color: #FFFEFE\"> movie</span><span style=\"background-color: #FFF9F9\"> .</span><span style=\"background-color: #FFFAFA\"> this</span><span style=\"background-color: #FFFEFE\"> film</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFF2F2\"> a</span><span style=\"background-color: #FF9A9A\"> good</span><span style=\"background-color: #FFDCDC\"> example</span><span style=\"background-color: #FFF0F0\"> of</span><span style=\"background-color: #FFF7F7\"> how</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> tell</span><span style=\"background-color: #FFF2F2\"> a</span><span style=\"background-color: #FFFCFC\"> simple</span><span style=\"background-color: #FFF0F0\"> story</span><span style=\"background-color: #FFFDFD\"> in</span><span style=\"background-color: #FFF1F1\"> a</span><span style=\"background-color: #FFFEFE\"> complex</span><span style=\"background-color: #FFD1D1\"> manner</span><span style=\"background-color: #FFF8F8\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFF2F2\"> plot</span><span style=\"background-color: #FFEFEF\"> of</span><span style=\"background-color: #FFE1E1\"> ashes</span><span style=\"background-color: #FFEFEF\"> of</span><span style=\"background-color: #FFFEFE\"> time</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> fairly</span><span style=\"background-color: #FFFCFC\"> simple</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFDFD\"> comes</span><span style=\"background-color: #FFFEFE\"> down</span><span style=\"background-color: #FFFDFD\"> to</span><span style=\"background-color: #FFF7F7\"> two</span><span style=\"background-color: #FFFEFE\"> words</span><span style=\"background-color: #FFFEFE\"> :</span><span style=\"background-color: #FFFBFB\"> love</span><span style=\"background-color: #FFF6F6\"> triangle</span><span style=\"background-color: #FFF8F8\"> .</span><span style=\"background-color: #FFF3F3\"> because</span><span style=\"background-color: #FFEEEE\"> of</span><span style=\"background-color: #FFF6F6\"> those</span><span style=\"background-color: #FFFBFB\"> love</span><span style=\"background-color: #FFFDFD\"> triangles</span><span style=\"background-color: #FFFEFE\"> crossing</span><span style=\"background-color: #FFF9F9\"> stories</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> jealousy</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFF2F2\"> hate</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFBFB\"> love</span><span style=\"background-color: #FFFDFD\"> are</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFEBEB\"> main</span><span style=\"background-color: #FFFDFD\"> dynamics</span><span style=\"background-color: #FFFEFE\"> displayed</span><span style=\"background-color: #FFFEFE\"> by</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> characters</span><span style=\"background-color: #FFF8F8\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> narrative</span><span style=\"background-color: #FFE4E4\"> part</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFF8F8\"> seen</span><span style=\"background-color: #FFFDFD\"> through</span><span style=\"background-color: #FFEBEB\"> <unk></span><span style=\"background-color: #FFFEFE\"> yang</span><span style=\"background-color: #FFEAEA\"> <unk></span><span style=\"background-color: #FFF7F7\"> s</span><span style=\"background-color: #FFFBFB\"> eyes</span><span style=\"background-color: #FFF6F6\"> leslie</span><span style=\"background-color: #FFFEFE\"> cheung</span><span style=\"background-color: #FFF8F8\"> .</span><span style=\"background-color: #FFE9E9\"> <unk></span><span style=\"background-color: #FFFEFE\"> yang</span><span style=\"background-color: #FFE9E9\"> <unk></span><span style=\"background-color: #FFFDFD\"> lives</span><span style=\"background-color: #FFFDFD\"> in</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> desert</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFF9F9\"> where</span><span style=\"background-color: #FFE9E9\"> he</span><span style=\"background-color: #FFF1F1\"> acts</span><span style=\"background-color: #FFFEFE\"> as</span><span style=\"background-color: #FFEBEB\"> <unk></span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> various</span><span style=\"background-color: #FFFEFE\"> swordsmen</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFDFD\"> becomes</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> tool</span><span style=\"background-color: #FFEFEF\"> of</span><span style=\"background-color: #FFFBFB\"> destiny</span><span style=\"background-color: #FFFDFD\"> through</span><span style=\"background-color: #FFF7F7\"> which</span><span style=\"background-color: #FFFEFE\"> vengeance</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFCFC\"> achieved</span><span style=\"background-color: #FFF8F8\"> .</span><span style=\"background-color: #FFFDFD\"> unfortunately</span><span style=\"background-color: #FFE0E0\"> ashes</span><span style=\"background-color: #FFEFEF\"> of</span><span style=\"background-color: #FFFEFE\"> time</span><span style=\"background-color: #FFE7E7\"> fails</span><span style=\"background-color: #FFFDFD\"> in</span><span style=\"background-color: #FFC9C9\"> telling</span><span style=\"background-color: #FFFDFD\"> these</span><span style=\"background-color: #FFFCFC\"> simple</span><span style=\"background-color: #FFF8F8\"> stories</span><span style=\"background-color: #FFEFEF\"> of</span><span style=\"background-color: #FFFBFB\"> love</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFF2F2\"> hate</span><span style=\"background-color: #FFF8F8\"> .</span><span style=\"background-color: #FFFDFD\"> wong</span><span style=\"background-color: #FFF7F7\"> kar</span><span style=\"background-color: #FFFDFD\"> wai</span><span style=\"background-color: #FFFEFE\"> lost</span><span style=\"background-color: #FFFEFE\"> himself</span><span style=\"background-color: #FFD4D4\"> driven</span><span style=\"background-color: #FFFEFE\"> by</span><span style=\"background-color: #FFF1F1\"> a</span><span style=\"background-color: #FFFCFC\"> desire</span><span style=\"background-color: #FFFDFD\"> to</span><span style=\"background-color: #FF9E9E\"> make</span><span style=\"background-color: #FFFEFE\"> each</span><span style=\"background-color: #FFFCFC\"> frame</span><span style=\"background-color: #FFF0F0\"> of</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> film</span><span style=\"background-color: #FFF0F0\"> a</span><span style=\"background-color: #FFDEDE\"> painting</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FF0000\"> an</span><span style=\"background-color: #FFFBFB\"> aesthetic</span><span style=\"background-color: #FFCDCD\"> experience</span><span style=\"background-color: #FFF8F8\"> .</span><span style=\"background-color: #FFFDFD\"> in</span><span style=\"background-color: #FFF9F9\"> fact</span><span style=\"background-color: #FFCBCB\"> beside</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> casting</span><span style=\"background-color: #FFF0F0\"> of</span><span style=\"background-color: #FFFDFD\"> beautiful</span><span style=\"background-color: #FFFEFE\"> actors</span><span style=\"background-color: #FFFAFA\"> men</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFBFB\"> women</span><span style=\"background-color: #FFFEFE\"> everything</span><span style=\"background-color: #FFF1F1\"> else</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFF0F0\"> a</span><span style=\"background-color: #FFFCFC\"> failure</span><span style=\"background-color: #FFFDFD\"> in</span><span style=\"background-color: #FFFAFA\"> this</span><span style=\"background-color: #FFFEFE\"> movie</span><span style=\"background-color: #FFF8F8\"> .</span><span style=\"background-color: #FFFEFE\"> dialogs</span><span style=\"background-color: #FFFDFD\"> are</span><span style=\"background-color: #FFEAEA\"> <unk></span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFE5E5\"> not</span><span style=\"background-color: #FFFEFE\"> original</span><span style=\"background-color: #FFFBFB\"> at</span><span style=\"background-color: #FFFEFE\"> all</span><span style=\"background-color: #FFF8F8\"> .</span><span style=\"background-color: #FFFEFE\"> picture</span><span style=\"background-color: #FFF7F7\"> s</span><span style=\"background-color: #FFFEFE\"> quality</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFEEEE\"> very</span><span style=\"background-color: #FFFCFC\"> much</span><span style=\"background-color: #FFEBEB\"> <unk></span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFCFC\"> editing</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> one</span><span style=\"background-color: #FFF0F0\"> of</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> worst</span><span style=\"background-color: #FFFEFE\"> ever</span><span style=\"background-color: #FFF8F8\"> seen</span><span style=\"background-color: #FFFBFB\"> at</span><span style=\"background-color: #FFFDFD\"> least</span><span style=\"background-color: #FFFEFE\"> by</span><span style=\"background-color: #FFFEFE\"> me</span><span style=\"background-color: #FFFDFD\"> in</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFBFB\"> swordplay</span><span style=\"background-color: #FFFEFE\"> genre</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> finally</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFCFC\"> filming</span><span style=\"background-color: #FFF0F0\"> of</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> rare</span><span style=\"background-color: #FFFCFC\"> sword</span><span style=\"background-color: #FF6666\"> fight</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFEFEF\"> very</span><span style=\"background-color: #FFFEFE\"> confusing</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFB9B9\"> unappealing</span><span style=\"background-color: #FFF8F8\"> .</span><span style=\"background-color: #FFFEFE\"> even</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFECEC\"> attempt</span><span style=\"background-color: #FFF0F0\"> of</span><span style=\"background-color: #FFFCFC\"> building</span><span style=\"background-color: #FFFEFE\"> artistic</span><span style=\"background-color: #FFFBFB\"> scenes</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFE7E7\"> not</span><span style=\"background-color: #FFFEFE\"> always</span><span style=\"background-color: #FFFCFC\"> achieved</span><span style=\"background-color: #FFFEFE\"> :</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> so</span><span style=\"background-color: #FFFDFD\"> call</span><span style=\"background-color: #FFF3F3\"> erotic</span><span style=\"background-color: #FFFBFB\"> women</span><span style=\"background-color: #FFF7F7\"> on</span><span style=\"background-color: #FFF0F0\"> a</span><span style=\"background-color: #FFFEFE\"> horse</span><span style=\"background-color: #FFFCFC\"> scene</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> ridiculous</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFE7E7\"> not</span><span style=\"background-color: #FFF3F3\"> erotic</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> useless</span><span style=\"background-color: #FFF8F8\"> .</span><span style=\"background-color: #FFFDFD\"> wong</span><span style=\"background-color: #FFF7F7\"> kar</span><span style=\"background-color: #FFFDFD\"> wai</span><span style=\"background-color: #FFFDFD\"> wanted</span><br><br>[TransformerBlock 2のAttention]<br><span style=\"background-color: #FFEFEF\"> ashes</span><span style=\"background-color: #FFEEEE\"> of</span><span style=\"background-color: #FFC6C6\"> time</span><span style=\"background-color: #FFCCCC\"> was</span><span style=\"background-color: #FFE3E3\"> an</span><span style=\"background-color: #FF9E9E\"> audacious</span><span style=\"background-color: #FFAFAF\"> project</span><span style=\"background-color: #FFF5F5\"> but</span><span style=\"background-color: #FFFAFA\"> ended</span><span style=\"background-color: #FFFEFE\"> up</span><span style=\"background-color: #FFFEFE\"> being</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> pretentious</span><span style=\"background-color: #FFFAFA\"> movie</span><span style=\"background-color: #FF8989\"> .</span><span style=\"background-color: #FFD2D2\"> this</span><span style=\"background-color: #FFB8B8\"> film</span><span style=\"background-color: #FF7777\"> is</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> good</span><span style=\"background-color: #FFFDFD\"> example</span><span style=\"background-color: #FFEFEF\"> of</span><span style=\"background-color: #FFFEFE\"> how</span><span style=\"background-color: #FF7575\"> to</span><span style=\"background-color: #FFFDFD\"> tell</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFBFB\"> simple</span><span style=\"background-color: #FFF7F7\"> story</span><span style=\"background-color: #FFFAFA\"> in</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFCFC\"> complex</span><span style=\"background-color: #FFD1D1\"> manner</span><span style=\"background-color: #FF9292\"> .</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFE8E8\"> plot</span><span style=\"background-color: #FFEEEE\"> of</span><span style=\"background-color: #FFEFEF\"> ashes</span><span style=\"background-color: #FFEEEE\"> of</span><span style=\"background-color: #FFC7C7\"> time</span><span style=\"background-color: #FF7777\"> is</span><span style=\"background-color: #FFFBFB\"> fairly</span><span style=\"background-color: #FFFBFB\"> simple</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> comes</span><span style=\"background-color: #FFEFEF\"> down</span><span style=\"background-color: #FF6A6A\"> to</span><span style=\"background-color: #FFFEFE\"> two</span><span style=\"background-color: #FFEEEE\"> words</span><span style=\"background-color: #FFF5F5\"> :</span><span style=\"background-color: #FFF1F1\"> love</span><span style=\"background-color: #FFF8F8\"> triangle</span><span style=\"background-color: #FF8A8A\"> .</span><span style=\"background-color: #FFF8F8\"> because</span><span style=\"background-color: #FFEEEE\"> of</span><span style=\"background-color: #FFFEFE\"> those</span><span style=\"background-color: #FFF2F2\"> love</span><span style=\"background-color: #FFFDFD\"> triangles</span><span style=\"background-color: #FF4242\"> crossing</span><span style=\"background-color: #FFFEFE\"> stories</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFF1F1\"> jealousy</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFF7F7\"> hate</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFF1F1\"> love</span><span style=\"background-color: #FFF3F3\"> are</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFDFD\"> main</span><span style=\"background-color: #FFDBDB\"> dynamics</span><span style=\"background-color: #FFFDFD\"> displayed</span><span style=\"background-color: #FFFDFD\"> by</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFF8F8\"> characters</span><span style=\"background-color: #FF8B8B\"> .</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFCACA\"> narrative</span><span style=\"background-color: #FFFAFA\"> part</span><span style=\"background-color: #FF6F6F\"> is</span><span style=\"background-color: #FFFCFC\"> seen</span><span style=\"background-color: #FFFEFE\"> through</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFDFD\"> yang</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFD7D7\"> s</span><span style=\"background-color: #FFCDCD\"> eyes</span><span style=\"background-color: #FFA7A7\"> leslie</span><span style=\"background-color: #FFF9F9\"> cheung</span><span style=\"background-color: #FF8C8C\"> .</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFDFD\"> yang</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFCFC\"> lives</span><span style=\"background-color: #FFF9F9\"> in</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFAFA\"> desert</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFCFC\"> where</span><span style=\"background-color: #FFFEFE\"> he</span><span style=\"background-color: #FFFBFB\"> acts</span><span style=\"background-color: #FFFCFC\"> as</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FF6565\"> to</span><span style=\"background-color: #FFD1D1\"> various</span><span style=\"background-color: #FFFEFE\"> swordsmen</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFE8E8\"> becomes</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFEEEE\"> tool</span><span style=\"background-color: #FFEEEE\"> of</span><span style=\"background-color: #FFFEFE\"> destiny</span><span style=\"background-color: #FFFEFE\"> through</span><span style=\"background-color: #FFFBFB\"> which</span><span style=\"background-color: #FFEAEA\"> vengeance</span><span style=\"background-color: #FF7878\"> is</span><span style=\"background-color: #FFBABA\"> achieved</span><span style=\"background-color: #FF8B8B\"> .</span><span style=\"background-color: #FFFBFB\"> unfortunately</span><span style=\"background-color: #FFEEEE\"> ashes</span><span style=\"background-color: #FFEEEE\"> of</span><span style=\"background-color: #FFC5C5\"> time</span><span style=\"background-color: #FFF9F9\"> fails</span><span style=\"background-color: #FFF9F9\"> in</span><span style=\"background-color: #FFB9B9\"> telling</span><span style=\"background-color: #FFFEFE\"> these</span><span style=\"background-color: #FFFBFB\"> simple</span><span style=\"background-color: #FFFEFE\"> stories</span><span style=\"background-color: #FFEFEF\"> of</span><span style=\"background-color: #FFF1F1\"> love</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFF7F7\"> hate</span><span style=\"background-color: #FF8D8D\"> .</span><span style=\"background-color: #FFF0F0\"> wong</span><span style=\"background-color: #FFBBBB\"> kar</span><span style=\"background-color: #FFFAFA\"> wai</span><span style=\"background-color: #FFF9F9\"> lost</span><span style=\"background-color: #FFFCFC\"> himself</span><span style=\"background-color: #FFF4F4\"> driven</span><span style=\"background-color: #FFFDFD\"> by</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFD8D8\"> desire</span><span style=\"background-color: #FF7474\"> to</span><span style=\"background-color: #FFFBFB\"> make</span><span style=\"background-color: #FFEFEF\"> each</span><span style=\"background-color: #FF8080\"> frame</span><span style=\"background-color: #FFEFEF\"> of</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFBCBC\"> film</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFCFC\"> painting</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFE4E4\"> an</span><span style=\"background-color: #FFF7F7\"> aesthetic</span><span style=\"background-color: #FFE2E2\"> experience</span><span style=\"background-color: #FF8F8F\"> .</span><span style=\"background-color: #FFFAFA\"> in</span><span style=\"background-color: #FFFAFA\"> fact</span><span style=\"background-color: #FFF9F9\"> beside</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFBFB\"> casting</span><span style=\"background-color: #FFEEEE\"> of</span><span style=\"background-color: #FFFDFD\"> beautiful</span><span style=\"background-color: #FFFDFD\"> actors</span><span style=\"background-color: #FFFBFB\"> men</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFE4E4\"> women</span><span style=\"background-color: #FFFBFB\"> everything</span><span style=\"background-color: #FFFEFE\"> else</span><span style=\"background-color: #FF7272\"> is</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFDFD\"> failure</span><span style=\"background-color: #FFFAFA\"> in</span><span style=\"background-color: #FFD3D3\"> this</span><span style=\"background-color: #FFFAFA\"> movie</span><span style=\"background-color: #FF8A8A\"> .</span><span style=\"background-color: #FFFEFE\"> dialogs</span><span style=\"background-color: #FFF3F3\"> are</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFF2F2\"> not</span><span style=\"background-color: #FFFDFD\"> original</span><span style=\"background-color: #FFE4E4\"> at</span><span style=\"background-color: #FFF7F7\"> all</span><span style=\"background-color: #FF8585\"> .</span><span style=\"background-color: #FFFEFE\"> picture</span><span style=\"background-color: #FFD5D5\"> s</span><span style=\"background-color: #FFFAFA\"> quality</span><span style=\"background-color: #FF6D6D\"> is</span><span style=\"background-color: #FF3A3A\"> very</span><span style=\"background-color: #FFFEFE\"> much</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFEDED\"> editing</span><span style=\"background-color: #FF6E6E\"> is</span><span style=\"background-color: #FF0000\"> one</span><span style=\"background-color: #FFEDED\"> of</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFE1E1\"> worst</span><span style=\"background-color: #FFFAFA\"> ever</span><span style=\"background-color: #FFFCFC\"> seen</span><span style=\"background-color: #FFE6E6\"> at</span><span style=\"background-color: #FFEDED\"> least</span><span style=\"background-color: #FFFDFD\"> by</span><span style=\"background-color: #FFFAFA\"> me</span><span style=\"background-color: #FFF9F9\"> in</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFEFE\"> swordplay</span><span style=\"background-color: #FFD4D4\"> genre</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> finally</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFE2E2\"> filming</span><span style=\"background-color: #FFEDED\"> of</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFF1F1\"> rare</span><span style=\"background-color: #FFFBFB\"> sword</span><span style=\"background-color: #FFF9F9\"> fight</span><span style=\"background-color: #FF7171\"> is</span><span style=\"background-color: #FF3E3E\"> very</span><span style=\"background-color: #FFFAFA\"> confusing</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFCFC\"> unappealing</span><span style=\"background-color: #FF8383\"> .</span><span style=\"background-color: #FFFEFE\"> even</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFEDED\"> attempt</span><span style=\"background-color: #FFEEEE\"> of</span><span style=\"background-color: #FFFCFC\"> building</span><span style=\"background-color: #FFFAFA\"> artistic</span><span style=\"background-color: #FFFBFB\"> scenes</span><span style=\"background-color: #FF7575\"> is</span><span style=\"background-color: #FFF3F3\"> not</span><span style=\"background-color: #FFFDFD\"> always</span><span style=\"background-color: #FFB9B9\"> achieved</span><span style=\"background-color: #FFF5F5\"> :</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFEFE\"> so</span><span style=\"background-color: #FFFEFE\"> call</span><span style=\"background-color: #FFFDFD\"> erotic</span><span style=\"background-color: #FFE6E6\"> women</span><span style=\"background-color: #FFFBFB\"> on</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFCFC\"> horse</span><span style=\"background-color: #FFFEFE\"> scene</span><span style=\"background-color: #FF6E6E\"> is</span><span style=\"background-color: #FFFEFE\"> ridiculous</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFF2F2\"> not</span><span style=\"background-color: #FFFDFD\"> erotic</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFF5F5\"> useless</span><span style=\"background-color: #FF8686\"> .</span><span style=\"background-color: #FFF0F0\"> wong</span><span style=\"background-color: #FFBABA\"> kar</span><span style=\"background-color: #FFFAFA\"> wai</span><span style=\"background-color: #FFFAFA\"> wanted</span>"]},"metadata":{},"execution_count":43}],"source":["from IPython.display import HTML\n","\n","# Transformerで処理\n","\n","# ミニバッチの用意\n","batch = next(iter(test_loader))\n","\n","# GPUが使えるならGPUにデータを送る\n","inputs = batch['input_ids'].to(device)  # 文章\n","labels = batch['label'].to(device)  # ラベル\n","\n","# mask作成\n","input_mask = (inputs != input_pad)\n","\n","# Transformerに入力\n","outputs, normlized_weights_1, normlized_weights_2 = net_trained(\n","    inputs, input_mask)\n","_, preds = torch.max(outputs, 1)  # ラベルを予測\n","\n","\n","#index = 3  # 出力させたいデータ\n","index = random.randint(0, batch_size-1)\n","html_output = mk_html(index, batch, preds, normlized_weights_1,\n","                      normlized_weights_2)  # HTML作成\n","HTML(html_output)  # HTML形式で出力\n"]},{"cell_type":"markdown","source":["# 課題(Transformer)\n","\n","- 説明文中で言及した次の2つの課題について実際に試しなさい\n","  - Embeddingの値を学習させた場合とさせない場合の結果の違い\n","  - ClassificationHeadにおける特徴量の扱い方における結果の違い\n","    - この場合ハイライティングは言及しなくてよい\n","\n","- 日本語で実験してみよう\n","  - https://github.com/amazon-research/amazon-multilingual-counterfactual-dataset\n","  - こちらのデータセット利用してトライする\n","    - ただ、中身を見るとわかるが、ちょっとつまらないかも\n","\n","- Embeddingによる内部の単語表現ベクトルの次元を変えたとき、精度にどのように影響するかを調査しなさい\n","  - できれば減らせるようにしよう\n","\n","- Transformerの段数を増やし、精度が向上するか確認してみよう\n","\n","- LightGBMと精度を比較してみなさい\n","  - 落胆する結果にならないとよいですが…"],"metadata":{"id":"JniR0P2CQuIz"}},{"cell_type":"markdown","metadata":{"id":"2UbJrC7Fq43T"},"source":["# PyTorch Transformerを用いた単語予測\n","\n","Transformerは複雑な構造をもっており、これそのものをPytorchで記述することも可能であるが、CNNやRNNと同様、PyTorchが提供するライブラリを利用することで簡単に利用できる\n","- ここではPytorch Transformerが提供するTransformerを構築するに必要な層の要素を組み合わせて設計する\n","\n","Pytorh TransformerとTorchTextを用い、先に学んだsequence-to-sequenceモデルを使って機械翻訳モデルを実装する\n","- この内容はPyTorchのチュートリアルドキュメントに準拠する\n","\n","WikiText2から取得した文章を用いて単語系列であるsequenceを入力、次に来る単語の予測を行う\n"]},{"cell_type":"markdown","metadata":{"id":"m5z7ICe5cTN8"},"source":["## モデル定義"]},{"cell_type":"markdown","metadata":{"id":"7QGqYTRpDIbs"},"source":["単語、つまりトークンの並びであるシーケンスがモデルに入力されると、位置エンコーディング層で単語の順序情報が加えられる\n","\n","言語モデルタスクでは、入力シーケンスと共に、アテンション・マスクを利用する\n","- nn.TransformerEncoderのSelf-Attention層では、シーケンスにおけるその単語以前の単語のみ知ることができる\n","  - 普通は、未来に登場するはずの単語は考慮できないため\n","- そこで、言語モデルタスクでは、後で登場するトークンは未知のトークンとして扱う必要があるため、これらをマスクする\n"]},{"cell_type":"markdown","metadata":{"id":"XX10cXx_DWd2"},"source":["nn.TransformerEncoderについて\n","- nn.TransformerEncoderモデルの出力は、最終的に全結合層に送られlog-Softmax関数を介することで予測結果を得ることができる\n","- nn.TransformerEncoderは、複数のnn.TransformerEncoderLayer層で構成されており並列的に動作できるためRNNよりも計算効率が良い\n","\n","TransformerModelの引き数\n","- src: [seq_len, batch_size]のTensor型\n","- src_mask: [seq_len, seq_len]のTensor型\n","戻り値: [seq_len, batch_size, ntoken]のTensor型\n"]},{"cell_type":"code","metadata":{"id":"vD0wRqmlPPd6"},"source":["import math\n","from typing import Tuple\n","\n","import torch\n","from torch import nn, Tensor\n","import torch.nn.functional as F\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer\n","from torch.utils.data import dataset\n","\n","# PositionalEncodingをTransformerModelの前に定義（参照順序の修正）\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        position = torch.arange(max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n","        pe = torch.zeros(max_len, 1, d_model)\n","        pe[:, 0, 0::2] = torch.sin(position * div_term)\n","        pe[:, 0, 1::2] = torch.cos(position * div_term)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        # [seq_len, batch_size, embedding_dim]型Tensorを引数とする\n","        x = x + self.pe[:x.size(0)]\n","        return self.dropout(x)\n","\n","class TransformerModel(nn.Module):\n","    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n","                 nlayers: int, dropout: float = 0.5):\n","        super().__init__()\n","        self.model_type = 'Transformer'\n","        self.pos_encoder = PositionalEncoding(d_model, dropout)\n","        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n","        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n","        self.encoder = nn.Embedding(ntoken, d_model)\n","        self.d_model = d_model\n","        self.decoder = nn.Linear(d_model, ntoken)\n","\n","        self.init_weights()\n","\n","    def init_weights(self) -> None:\n","        initrange = 0.1\n","        self.encoder.weight.data.uniform_(-initrange, initrange)\n","        self.decoder.bias.data.zero_()\n","        self.decoder.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n","        src = self.encoder(src) * math.sqrt(self.d_model)\n","        src = self.pos_encoder(src)\n","        output = self.transformer_encoder(src, src_mask)\n","        output = self.decoder(output)\n","        return output\n","\n","def generate_square_subsequent_mask(sz: int) -> Tensor:\n","    # -infの上三角行列を生成し，対角線上に0を置く。\n","    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hX1-8iMzkrcm"},"source":["## PositionalEncoding\n","\n","PosigionalEncodingモジュールは、シーケンス内のトークンの相対的な位置、もしくは絶対的な位置に関する情報を与える\n","\n","オリジナルの実装と同様、入力と出力は同じ次元である\n","- つまり、もともとの入力$x$に対して、PositionalEncodingの値$p(x)$が得られたとすると、出力は$x+p(x)$となる"]},{"cell_type":"code","metadata":{"id":"B94dp7t9PPd9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768456455619,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"66b62c14-4d66-460f-8098-17f328d60b61"},"source":["# PositionalEncodingは上のセルで既に定義済み\n","# (TransformerModelが参照するため、先に定義する必要があります)\n","print(\"PositionalEncoding is already defined above.\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PositionalEncoding is already defined above.\n"]}]},{"cell_type":"markdown","metadata":{"id":"NkurbIT-cbN5"},"source":["## データの読み込みとバッチ処理\n"]},{"cell_type":"markdown","metadata":{"id":"dhPLp8qLmpkS"},"source":["ここでは、torchtextのWikitext-2データセットを利用する\n","\n","vocabはトークン（単語）をテンソル形式の数値に変換する\n","- 訓練データセットを元に構築されており、データセット依存である\n","\n","- batchify()関数は、トークンが左から右に一つずつ並んだシーケンス形式のデータを束ねて、batch処理ができるようにする\n","  - 変換にはデータをbatch_size 変数のサイズで分割し、余ったトークンは廃棄する\n","\n","例えば、アルファベット26文字をシーケンスとしたとき、バッチサイズが4であれば、アルファベットを長さ6の4つのシーケンスに分割することが考えられる\n","\n","この時次のような変換が行なわれる\n","\n","\\begin{align}\\begin{bmatrix}\n","  \\text{A} & \\text{B} & \\text{C} & \\ldots & \\text{X} & \\text{Y} & \\text{Z}\n","  \\end{bmatrix}\n","  \\Rightarrow\n","  \\begin{bmatrix}\n","  \\begin{bmatrix}\\text{A} \\\\ \\text{B} \\\\ \\text{C} \\\\ \\text{D} \\\\ \\text{E} \\\\ \\text{F}\\end{bmatrix} &\n","  \\begin{bmatrix}\\text{G} \\\\ \\text{H} \\\\ \\text{I} \\\\ \\text{J} \\\\ \\text{K} \\\\ \\text{L}\\end{bmatrix} &\n","  \\begin{bmatrix}\\text{M} \\\\ \\text{N} \\\\ \\text{O} \\\\ \\text{P} \\\\ \\text{Q} \\\\ \\text{R}\\end{bmatrix} &\n","  \\begin{bmatrix}\\text{S} \\\\ \\text{T} \\\\ \\text{U} \\\\ \\text{V} \\\\ \\text{W} \\\\ \\text{X}\\end{bmatrix}\n","  \\end{bmatrix}\\end{align}\n","\n","なお、各バッチ、つまり各列はモデル内ではそれぞれ独立しており、その境界を越えて依存関係を学習することはできない\n","- 例えばFとGの依存関係を学習することはできない\n","- それでも大量にデータを入力して学習させるため問題とはならない\n","- バッチ処理を有効に活用した方が計算効率が高く、その方がメリットが大きい\n"]},{"cell_type":"markdown","source":["### WikiText2データの準備\n","\n","torchtextは非推奨（deprecated）のため、WikiText2データを直接ダウンロードして使用する\n","- データはS3からZIPファイルとしてダウンロード\n","- 自作のトークナイザーと語彙構築関数を使用\n"],"metadata":{"id":"g2bddT_ckgOJ"}},{"cell_type":"code","source":["!pip install torchdata"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AO-sHgYUkay5","executionInfo":{"status":"ok","timestamp":1768456460072,"user_tz":-540,"elapsed":4452,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"5d4e2236-84ef-402e-de64-1c43ce4e1442"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchdata in /usr/local/lib/python3.12/dist-packages (0.11.0)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.12/dist-packages (from torchdata) (2.5.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchdata) (2.32.4)\n","Requirement already satisfied: torch>=2 in /usr/local/lib/python3.12/dist-packages (from torchdata) (2.9.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (3.20.2)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (3.5.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchdata) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchdata) (3.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchdata) (2026.1.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2->torchdata) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2->torchdata) (3.0.3)\n"]}]},{"cell_type":"markdown","source":["必要なライブラリの読み込み\n","\n"],"metadata":{"id":"840dAvHobWkf"}},{"cell_type":"code","source":["# torchtextは非推奨のため、自作のデータ読み込みを使用\n","# 必要なライブラリ\n","import urllib.request\n","import zipfile\n","import os\n","print(\"WikiText2データを直接ダウンロードします\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DXflwEXKY5Gk","executionInfo":{"status":"ok","timestamp":1768456460114,"user_tz":-540,"elapsed":41,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"f9a69b65-ed1b-4eff-ccec-87525ec04c30"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WikiText2データを直接ダウンロードします\n"]}]},{"cell_type":"markdown","source":["### ライブラリの準備\n","\n","外部ライブラリへの依存を排除し、自作のデータローダーを使用する\n","- URLから直接WikiText2データをダウンロード\n","- 自作のトークナイザーで処理\n"],"metadata":{"id":"RgUg9xlpgrkA"}},{"cell_type":"code","source":["# 自作の関数を使用（torchtext不要）\n","print(\"自作のトークナイザーと語彙構築を使用\")\n"],"metadata":{"id":"xF_hfy6Jkd82","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768456460128,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"89dc570e-c899-4a18-9f5a-3e604d0d5608"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["自作のトークナイザーと語彙構築を使用\n"]}]},{"cell_type":"markdown","source":["### データ処理関数\n","\n","- `data_process`: テキストをテンソル列に変換する\n","- `batchify`: データをbatch_size個のシーケンスに分割し、きれいに収まらない余分な要素を削除する\n","  - data: Tensor, shape [N]\n","  - bsz: int, batch size\n","  - 戻り値: Tensor of shape [N // bsz, bsz]\n"],"metadata":{"id":"T0MO7YeoZi-P"}},{"cell_type":"code","source":["!pip install portalocker"],"metadata":{"id":"OlYcnBLGwfnB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768456470381,"user_tz":-540,"elapsed":10252,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"6eb1fa52-040f-41c4-f6fc-46cadf6caa46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting portalocker\n","  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n","Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n","Installing collected packages: portalocker\n","Successfully installed portalocker-3.2.0\n"]}]},{"cell_type":"code","source":["# WikiText2データセットの読み込み（外部ライブラリ不要）\n","import re\n","from collections import Counter\n","from datasets import load_dataset\n","\n","# WikiText2をHugging Face datasetsから読み込み\n","print(\"WikiText2データをダウンロード中...\")\n","dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n","train_text = \"\\n\".join(dataset[\"train\"][\"text\"])\n","val_text = \"\\n\".join(dataset[\"validation\"][\"text\"])\n","test_text = \"\\n\".join(dataset[\"test\"][\"text\"])\n","print(\"ダウンロード完了\")\n","\n","# 自作トークナイザー（WikiText2用）\n","def wikitext_tokenizer(text):\n","    \"\"\"WikiText2用のシンプルなトークナイザー\"\"\"\n","    text = text.lower()\n","    text = re.sub(r\"([.!?,;:])\", r\" \\1 \", text)\n","    text = re.sub(r\"[^a-zA-Z0-9\\s.!?,;:]\", \" \", text)\n","    tokens = text.split()\n","    return tokens\n","\n","# WikiText2用の語彙クラス\n","class WikiVocabulary:\n","    def __init__(self, specials=['<unk>']):\n","        self.token2idx = {}\n","        self.idx2token = {}\n","        for token in specials:\n","            self._add_token(token)\n","        self.default_idx = self.token2idx.get('<unk>', 0)\n","\n","    def _add_token(self, token):\n","        if token not in self.token2idx:\n","            idx = len(self.token2idx)\n","            self.token2idx[token] = idx\n","            self.idx2token[idx] = token\n","\n","    def build_from_text(self, text, tokenizer_fn, min_freq=1):\n","        \"\"\"テキストから語彙を構築\"\"\"\n","        tokens = tokenizer_fn(text)\n","        counter = Counter(tokens)\n","        for token, freq in counter.items():\n","            if freq >= min_freq:\n","                self._add_token(token)\n","        return self\n","\n","    def set_default_index(self, idx):\n","        self.default_idx = idx\n","\n","    def __len__(self):\n","        return len(self.token2idx)\n","\n","    def __call__(self, tokens):\n","        \"\"\"トークンリストをIDリストに変換\"\"\"\n","        return [self.token2idx.get(token, self.default_idx) for token in tokens]\n","\n","    def __getitem__(self, token):\n","        return self.token2idx.get(token, self.default_idx)\n","\n","    def lookup_token(self, idx):\n","        return self.idx2token.get(idx, '<unk>')\n","\n","# tokenizer関数を設定（WikiText2用）\n","tokenizer = wikitext_tokenizer\n","\n","# 語彙を構築\n","print(\"語彙を構築中...\")\n","vocab = WikiVocabulary(specials=['<unk>'])\n","vocab.build_from_text(train_text, tokenizer)\n","vocab.set_default_index(vocab['<unk>'])\n","\n","def data_process(text) -> Tensor:\n","    \"\"\"テキストをテンソルに変換\"\"\"\n","    tokens = tokenizer(text)\n","    token_ids = vocab(tokens)\n","    return torch.tensor(token_ids, dtype=torch.long)\n","\n","# batchify関数\n","def batchify(data: Tensor, bsz: int) -> Tensor:\n","    \"\"\"データをバッチ処理用に整形\"\"\"\n","    seq_len = data.size(0) // bsz\n","    data = data[:seq_len * bsz]\n","    data = data.view(bsz, seq_len).t().contiguous()\n","    return data.to(device)\n","\n","# データをテンソルに変換\n","train_data = data_process(train_text)\n","val_data = data_process(val_text)\n","test_data = data_process(test_text)\n","\n","print(f\"語彙サイズ: {len(vocab)}\")\n","print(f\"train_data (before batchify): {train_data.shape}\")\n","\n","# バッチ処理\n","batch_size = 20\n","eval_batch_size = 10\n","train_data = batchify(train_data, batch_size)\n","val_data = batchify(val_data, eval_batch_size)\n","test_data = batchify(test_data, eval_batch_size)\n","\n","print(f\"train_data (after batchify): {train_data.shape}\")\n","print(f\"val_data shape: {val_data.shape}\")\n","print(f\"test_data shape: {test_data.shape}\")"],"metadata":{"id":"ap-_QY18YqBH","colab":{"base_uri":"https://localhost:8080/","height":419,"referenced_widgets":["9b157c29e9c54c6eb4b2ec76ef2811ea","7427e062220e488485cf8e535c6dee30","cf1c70ef81eb4df0a71b3dc22554d826","3f9b1f6bb6b644f495323033d42c8270","1fbfc802c2584584a04dbf4d66c15ac5","b07c5cb9359d4537b606d2a9b26a40a7","3dc14059be8c4663ad978cf6ad85f061","303fb2264cf5431da5e1c21ec8127d76","bef788f78ea94e0eb1d3a7d808919b2d","7dbf9fa85da74af28c65cc01414cab3b","58e4462f33bb4f3786dabf2ebdc8cc59","bd201dc0da9045d3a1225f8a4fbb9c1e","34c2c3feff4f43ed853af0453701e69e","32685b8facfc4024adb7e57fd661919e","52b13e0f9cdf4524a2909f54203f5d98","86a72381e03a48f1b4dce25a625f3dbe","1a9224357d4249fd853c3df5c824bb83","ce268779211148d9935ca503e6c680f5","2ac4de40c2e74f7888c4f8b617b50ff0","156998c81cdc41bd8f73184d67668162","131013a276984418bb54831be29caabd","a56ee9c4d8974d35916b2eb4c52e1388","4bb44d69c33b4a28943d228194da8438","016c3c93653c47849d5a083cb17d08af","c50c36009309467080ef7f005eb15b22","8577602f6e2e4aacaa1449e61b3fe8a1","707d751a31354bf78c2d25a4da6f584a","295eafb9edbb4bef84794eea830c9bbc","a4a693748472485cb6b92a67a8bebfa7","b589e92a3c864c6094c1a8dedbb7df4a","66471754c0794626b66b0169efe5ead5","4f038e3e38934416b5344fcc57ea8243","a14076b80d134010a11fa58586cf9792","ce06ca0296f847baa4a832a42bbaa139","d8f59be8570f4ec18689b4bb3b098fd2","70b29cf9a6c44376b6f6857555a7eda8","e9c07450e8d24535969db6fbc5d4a544","f612573213d54a64ac01a2f8534d4738","f52bba504fc044cea1f8f1b38aa36830","92e9b1b0937246179005d7093c4db6da","3ed46dfde52a40d191f06a9f9f40b65d","3ebabf697fc24de7b53f41068c539434","17aa0a6a6b8b4d85a69e41a4a52650d5","71cf783772474087b880fb75ea2d46c2","4328dc5e42da4309a7a31256feaa2611","7f754f44e48144adbc9552d4e34d9895","b0b9367204214957b3b1ec405eb1a921","9ffed447759d47d9b170ef10ff48e4e0","14026009e195409f8e966fba6ca031fc","f63a5fda80ef40578eaf8a95f8943309","12d7548145f544f6bb3e33c0f5fe56b3","7774020d24ed451d89754d4e7c431668","1c4cf56525814d338c5ef258489eaf11","4765384adc6a426cb9c92b772de0bb5b","7ccdb44370b549c0ae013d37bf40b88c","890af45bd3f147bf90be78a2526a35d7","d70ba381a5a74f9080e802a2f14c5533","c5cc1a5fb060449a902a0d60de59220b","7a560d62bfd44fe7956f77be9a17b512","0f14b7ffb85f49b489b103c0627b8324","86b7058147754a65b70906df2aeefd77","982be505c3d54b1eb96f25929d069da9","e6bd3b5600f44bb785546d9087c4106e","a9277340fb6443cd84e1460a04643615","903b4595aad54ce1902d302e50f8217d","76cb031e72a04fc2b23384f04e17e5b8","709d558ea5bf48be81c69787b5573ee5","6c5cffaa57ef403e890538883426de1f","8ff1ef6b78334caba4e1c9762577bd69","d4ccb2c48e0744609451032f75772ec8","8b06a2cd4f434c939aca862083837f1c","286d630501be4cb5aac220aee192fe0f","4794e3e8926b4e56a38f390092dcaaa2","33dc2e1e90654f018fdc2bd17e9b8f9b","fdd957442abe4efe87f144300600c383","00699c3d4a1540c69ff03a566363eb50","5d97424881174163b573001d21353990"]},"executionInfo":{"status":"ok","timestamp":1768456603924,"user_tz":-540,"elapsed":9769,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"72792eff-7245-491a-fcbf-d18b1470a8c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WikiText2データをダウンロード中...\n"]},{"output_type":"display_data","data":{"text/plain":["README.md: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b157c29e9c54c6eb4b2ec76ef2811ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["wikitext-2-raw-v1/test-00000-of-00001.pa(…):   0%|          | 0.00/733k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd201dc0da9045d3a1225f8a4fbb9c1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["wikitext-2-raw-v1/train-00000-of-00001.p(…):   0%|          | 0.00/6.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bb44d69c33b4a28943d228194da8438"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["wikitext-2-raw-v1/validation-00000-of-00(…):   0%|          | 0.00/657k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce06ca0296f847baa4a832a42bbaa139"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4328dc5e42da4309a7a31256feaa2611"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"890af45bd3f147bf90be78a2526a35d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"709d558ea5bf48be81c69787b5573ee5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ダウンロード完了\n","語彙を構築中...\n","語彙サイズ: 64829\n","train_data (before batchify): torch.Size([1949494])\n","train_data (after batchify): torch.Size([97474, 20])\n","val_data shape: torch.Size([20390, 10])\n","test_data shape: torch.Size([22927, 10])\n"]}]},{"cell_type":"markdown","metadata":{"id":"_lu9vP19sP9W"},"source":["## 入力シーケンスとTargetシーケンスの生成\n","\n","``get_batch()``関数を用いてTransformerモデルの入力シーケンスと、Targetシーケンスを生成する\n","- ソースデータを変数``bptt``の長さのチャンクデータに細分化する\n","- 今回の言語モデルタスクでは、入力シーケンスの続きとなる単語をTargetとして学習させる\n","\n","例えば``bptt``が2の場合は後続する2 つの要素を取得する\n","\n","- ``get_batch()``関数の返り値``data``の0次元目がチャンクの長さでを表し、Transformerモデルの次元Sと一致する\n","- dataの1次元目はバッチサイズを示す次元数Nである\n","\n","- 引数\n","  - source: [full_seq_len, batch_size]のテンソル\n","  - i: 整数\n","- 返り値\n","  - (data, target)\n","  - [seq_len, batch_size]のテンソルであるdataと、[seq_len * batch_size]のテンソルであるtarget"]},{"cell_type":"code","metadata":{"id":"vwlWJxBHPPeE"},"source":["bptt = 35\n","def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n","    seq_len = min(bptt, len(source) - 1 - i)\n","    data = source[i:i+seq_len]\n","    target = source[i+1:i+1+seq_len].reshape(-1)\n","    return data, target"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1crAe63wcYAF"},"source":["インスタンスの初期化\n","--------------------"]},{"cell_type":"markdown","metadata":{"id":"UMeu_Zh7cbH7"},"source":["モデルは、以下のハイパーパラメータを使用して設定されます。vocabのサイズは、vocabオブジェクトの長さと同じです。"]},{"cell_type":"code","metadata":{"id":"n8uZqoGWPPeI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768456623431,"user_tz":-540,"elapsed":516,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"856fe09d-2112-4130-feed-5064aa61720f"},"source":["ntokens = len(vocab)  # 語彙サイズ\n","emsize = 200  # 埋め込み次元数\n","d_hid = 200  # forwardネットワークモデルのnn.TransformerEncoderの次元\n","nlayers = 2  # nn.TransformerEncoderのnn.TransformerEncoderLayerの数\n","nhead = 2  # nn.MultiheadAttentionにおけるheadの数\n","dropout = 0.2  # dropoutの割合\n","model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["語彙数を確認する"],"metadata":{"id":"syHb9YFHmReQ"}},{"cell_type":"code","source":["ntokens"],"metadata":{"id":"aA58Lil2mPNS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768456623450,"user_tz":-540,"elapsed":19,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"f622c5ad-e1e3-4ea5-9201-6334a7a7f38e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["64829"]},"metadata":{},"execution_count":55}]},{"cell_type":"markdown","metadata":{"id":"Xx-EHjPUf7bE"},"source":["モデルの実行\n","-------------\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aoF0qhd7f7nX"},"source":["- CrossEntropyLossとSDGを用いる\n","- 初期の学習率は5.0としている\n","- エポック単位で学習率を調整する\n","  - StepLRを使用して学習率を調整する\n","  - 訓練中は、勾配爆発を防ぐためnn.utils.clip_grad_normを用いて学習率を調整する"]},{"cell_type":"code","metadata":{"id":"RjC4emUHPPeL"},"source":["import copy\n","import time\n","\n","criterion = nn.CrossEntropyLoss()\n","lr = 5.0  # learning rate\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n","\n","def train(model: nn.Module) -> None:\n","    model.train()  # turn on train mode\n","    total_loss = 0.\n","    log_interval = 200\n","    start_time = time.time()\n","    src_mask = generate_square_subsequent_mask(bptt).to(device)\n","\n","    num_batches = len(train_data) // bptt\n","    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n","        data, targets = get_batch(train_data, i)\n","        seq_len = data.size(0)\n","        if seq_len != bptt:  # only on last batch\n","            src_mask = src_mask[:seq_len, :seq_len]\n","        output = model(data, src_mask)\n","        loss = criterion(output.view(-1, ntokens), targets)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        if batch % log_interval == 0 and batch > 0:\n","            lr = scheduler.get_last_lr()[0]\n","            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n","            cur_loss = total_loss / log_interval\n","            ppl = math.exp(cur_loss)\n","            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n","                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n","                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n","            total_loss = 0\n","            start_time = time.time()\n","\n","def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n","    model.eval()  # turn on evaluation mode\n","    total_loss = 0.\n","    src_mask = generate_square_subsequent_mask(bptt).to(device)\n","    with torch.no_grad():\n","        for i in range(0, eval_data.size(0) - 1, bptt):\n","            data, targets = get_batch(eval_data, i)\n","            seq_len = data.size(0)\n","            if seq_len != bptt:\n","                src_mask = src_mask[:seq_len, :seq_len]\n","            output = model(data, src_mask)\n","            output_flat = output.view(-1, ntokens)\n","            total_loss += seq_len * criterion(output_flat, targets).item()\n","    return total_loss / (len(eval_data) - 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rgE9j1KumZTK"},"source":["エポックを繰り返す\n","\n","- 検証データの損失がそれまでの実行のなかで最も良い(低い)場合は当該モデルを保存する\n","- 各エポックの後に学習率を調整する(小さくする)"]},{"cell_type":"code","metadata":{"id":"4Ws6fSWbPPeO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768457442002,"user_tz":-540,"elapsed":818543,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"55d5dc67-0d9c-4d1f-faca-3b68db5e031a"},"source":["best_val_loss = float('inf')\n","epochs = 10\n","best_model = None\n","\n","for epoch in range(1, epochs + 1):\n","    epoch_start_time = time.time()\n","    train(model)\n","    val_loss = evaluate(model, val_data)\n","    val_ppl = math.exp(val_loss)\n","    elapsed = time.time() - epoch_start_time\n","    print('-' * 89)\n","    print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n","          f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n","    print('-' * 89)\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        best_model = copy.deepcopy(model)\n","\n","    scheduler.step()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["| epoch   1 |   200/ 2784 batches | lr 5.00 | ms/batch 29.62 | loss  9.33 | ppl 11219.85\n","| epoch   1 |   400/ 2784 batches | lr 5.00 | ms/batch 28.87 | loss  7.80 | ppl  2449.05\n","| epoch   1 |   600/ 2784 batches | lr 5.00 | ms/batch 31.37 | loss  7.27 | ppl  1437.00\n","| epoch   1 |   800/ 2784 batches | lr 5.00 | ms/batch 29.62 | loss  7.02 | ppl  1117.28\n","| epoch   1 |  1000/ 2784 batches | lr 5.00 | ms/batch 28.51 | loss  6.85 | ppl   943.87\n","| epoch   1 |  1200/ 2784 batches | lr 5.00 | ms/batch 28.36 | loss  6.82 | ppl   914.47\n","| epoch   1 |  1400/ 2784 batches | lr 5.00 | ms/batch 28.13 | loss  6.79 | ppl   885.08\n","| epoch   1 |  1600/ 2784 batches | lr 5.00 | ms/batch 28.01 | loss  6.64 | ppl   766.27\n","| epoch   1 |  1800/ 2784 batches | lr 5.00 | ms/batch 28.03 | loss  6.56 | ppl   705.98\n","| epoch   1 |  2000/ 2784 batches | lr 5.00 | ms/batch 27.89 | loss  6.55 | ppl   698.17\n","| epoch   1 |  2200/ 2784 batches | lr 5.00 | ms/batch 27.98 | loss  6.53 | ppl   684.37\n","| epoch   1 |  2400/ 2784 batches | lr 5.00 | ms/batch 27.85 | loss  6.54 | ppl   690.13\n","| epoch   1 |  2600/ 2784 batches | lr 5.00 | ms/batch 28.06 | loss  6.48 | ppl   649.49\n","-----------------------------------------------------------------------------------------\n","| end of epoch   1 | time: 82.69s | valid loss  6.78 | valid ppl   882.04\n","-----------------------------------------------------------------------------------------\n","| epoch   2 |   200/ 2784 batches | lr 4.75 | ms/batch 28.42 | loss  6.47 | ppl   642.49\n","| epoch   2 |   400/ 2784 batches | lr 4.75 | ms/batch 28.21 | loss  6.42 | ppl   614.57\n","| epoch   2 |   600/ 2784 batches | lr 4.75 | ms/batch 28.44 | loss  6.22 | ppl   502.62\n","| epoch   2 |   800/ 2784 batches | lr 4.75 | ms/batch 28.37 | loss  6.22 | ppl   503.40\n","| epoch   2 |  1000/ 2784 batches | lr 4.75 | ms/batch 28.49 | loss  6.14 | ppl   462.84\n","| epoch   2 |  1200/ 2784 batches | lr 4.75 | ms/batch 28.43 | loss  6.24 | ppl   511.40\n","| epoch   2 |  1400/ 2784 batches | lr 4.75 | ms/batch 28.47 | loss  6.26 | ppl   522.58\n","| epoch   2 |  1600/ 2784 batches | lr 4.75 | ms/batch 28.23 | loss  6.15 | ppl   468.56\n","| epoch   2 |  1800/ 2784 batches | lr 4.75 | ms/batch 28.31 | loss  6.12 | ppl   455.42\n","| epoch   2 |  2000/ 2784 batches | lr 4.75 | ms/batch 28.14 | loss  6.11 | ppl   448.12\n","| epoch   2 |  2200/ 2784 batches | lr 4.75 | ms/batch 28.24 | loss  6.12 | ppl   454.83\n","| epoch   2 |  2400/ 2784 batches | lr 4.75 | ms/batch 28.08 | loss  6.15 | ppl   467.12\n","| epoch   2 |  2600/ 2784 batches | lr 4.75 | ms/batch 28.20 | loss  6.11 | ppl   448.77\n","-----------------------------------------------------------------------------------------\n","| end of epoch   2 | time: 81.76s | valid loss  6.40 | valid ppl   604.28\n","-----------------------------------------------------------------------------------------\n","| epoch   3 |   200/ 2784 batches | lr 4.51 | ms/batch 28.39 | loss  6.14 | ppl   463.14\n","| epoch   3 |   400/ 2784 batches | lr 4.51 | ms/batch 28.09 | loss  6.13 | ppl   458.71\n","| epoch   3 |   600/ 2784 batches | lr 4.51 | ms/batch 28.28 | loss  5.92 | ppl   370.87\n","| epoch   3 |   800/ 2784 batches | lr 4.51 | ms/batch 28.13 | loss  5.95 | ppl   382.41\n","| epoch   3 |  1000/ 2784 batches | lr 4.51 | ms/batch 28.27 | loss  5.86 | ppl   350.50\n","| epoch   3 |  1200/ 2784 batches | lr 4.51 | ms/batch 28.12 | loss  5.98 | ppl   393.97\n","| epoch   3 |  1400/ 2784 batches | lr 4.51 | ms/batch 28.29 | loss  6.00 | ppl   405.41\n","| epoch   3 |  1600/ 2784 batches | lr 4.51 | ms/batch 28.17 | loss  5.92 | ppl   371.57\n","| epoch   3 |  1800/ 2784 batches | lr 4.51 | ms/batch 28.22 | loss  5.88 | ppl   358.95\n","| epoch   3 |  2000/ 2784 batches | lr 4.51 | ms/batch 28.22 | loss  5.86 | ppl   351.74\n","| epoch   3 |  2200/ 2784 batches | lr 4.51 | ms/batch 28.17 | loss  5.90 | ppl   363.73\n","| epoch   3 |  2400/ 2784 batches | lr 4.51 | ms/batch 28.24 | loss  5.92 | ppl   373.21\n","| epoch   3 |  2600/ 2784 batches | lr 4.51 | ms/batch 28.17 | loss  5.88 | ppl   357.92\n","-----------------------------------------------------------------------------------------\n","| end of epoch   3 | time: 81.56s | valid loss  6.31 | valid ppl   550.32\n","-----------------------------------------------------------------------------------------\n","| epoch   4 |   200/ 2784 batches | lr 4.29 | ms/batch 28.40 | loss  5.93 | ppl   377.11\n","| epoch   4 |   400/ 2784 batches | lr 4.29 | ms/batch 28.18 | loss  5.92 | ppl   373.14\n","| epoch   4 |   600/ 2784 batches | lr 4.29 | ms/batch 28.22 | loss  5.70 | ppl   300.34\n","| epoch   4 |   800/ 2784 batches | lr 4.29 | ms/batch 28.28 | loss  5.76 | ppl   316.55\n","| epoch   4 |  1000/ 2784 batches | lr 4.29 | ms/batch 28.22 | loss  5.68 | ppl   293.26\n","| epoch   4 |  1200/ 2784 batches | lr 4.29 | ms/batch 28.31 | loss  5.81 | ppl   332.52\n","| epoch   4 |  1400/ 2784 batches | lr 4.29 | ms/batch 28.15 | loss  5.84 | ppl   343.03\n","| epoch   4 |  1600/ 2784 batches | lr 4.29 | ms/batch 28.35 | loss  5.76 | ppl   316.83\n","| epoch   4 |  1800/ 2784 batches | lr 4.29 | ms/batch 28.18 | loss  5.72 | ppl   305.02\n","| epoch   4 |  2000/ 2784 batches | lr 4.29 | ms/batch 28.35 | loss  5.69 | ppl   297.11\n","| epoch   4 |  2200/ 2784 batches | lr 4.29 | ms/batch 28.20 | loss  5.73 | ppl   306.52\n","| epoch   4 |  2400/ 2784 batches | lr 4.29 | ms/batch 28.33 | loss  5.75 | ppl   312.94\n","| epoch   4 |  2600/ 2784 batches | lr 4.29 | ms/batch 28.24 | loss  5.72 | ppl   305.11\n","-----------------------------------------------------------------------------------------\n","| end of epoch   4 | time: 81.70s | valid loss  6.26 | valid ppl   524.15\n","-----------------------------------------------------------------------------------------\n","| epoch   5 |   200/ 2784 batches | lr 4.07 | ms/batch 28.37 | loss  5.78 | ppl   322.85\n","| epoch   5 |   400/ 2784 batches | lr 4.07 | ms/batch 28.36 | loss  5.77 | ppl   319.15\n","| epoch   5 |   600/ 2784 batches | lr 4.07 | ms/batch 28.20 | loss  5.56 | ppl   258.59\n","| epoch   5 |   800/ 2784 batches | lr 4.07 | ms/batch 28.33 | loss  5.61 | ppl   272.49\n","| epoch   5 |  1000/ 2784 batches | lr 4.07 | ms/batch 28.19 | loss  5.53 | ppl   253.10\n","| epoch   5 |  1200/ 2784 batches | lr 4.07 | ms/batch 28.35 | loss  5.65 | ppl   285.59\n","| epoch   5 |  1400/ 2784 batches | lr 4.07 | ms/batch 28.19 | loss  5.68 | ppl   291.54\n","| epoch   5 |  1600/ 2784 batches | lr 4.07 | ms/batch 28.32 | loss  5.61 | ppl   273.47\n","| epoch   5 |  1800/ 2784 batches | lr 4.07 | ms/batch 28.22 | loss  5.58 | ppl   265.75\n","| epoch   5 |  2000/ 2784 batches | lr 4.07 | ms/batch 28.33 | loss  5.55 | ppl   256.85\n","| epoch   5 |  2200/ 2784 batches | lr 4.07 | ms/batch 28.21 | loss  5.59 | ppl   268.08\n","| epoch   5 |  2400/ 2784 batches | lr 4.07 | ms/batch 28.30 | loss  5.60 | ppl   271.11\n","| epoch   5 |  2600/ 2784 batches | lr 4.07 | ms/batch 28.24 | loss  5.57 | ppl   263.69\n","-----------------------------------------------------------------------------------------\n","| end of epoch   5 | time: 81.82s | valid loss  6.28 | valid ppl   533.88\n","-----------------------------------------------------------------------------------------\n","| epoch   6 |   200/ 2784 batches | lr 3.87 | ms/batch 28.35 | loss  5.63 | ppl   279.14\n","| epoch   6 |   400/ 2784 batches | lr 3.87 | ms/batch 28.39 | loss  5.63 | ppl   277.76\n","| epoch   6 |   600/ 2784 batches | lr 3.87 | ms/batch 28.17 | loss  5.43 | ppl   227.54\n","| epoch   6 |   800/ 2784 batches | lr 3.87 | ms/batch 28.32 | loss  5.48 | ppl   239.72\n","| epoch   6 |  1000/ 2784 batches | lr 3.87 | ms/batch 28.19 | loss  5.41 | ppl   222.57\n","| epoch   6 |  1200/ 2784 batches | lr 3.87 | ms/batch 28.30 | loss  5.54 | ppl   253.57\n","| epoch   6 |  1400/ 2784 batches | lr 3.87 | ms/batch 28.26 | loss  5.55 | ppl   258.21\n","| epoch   6 |  1600/ 2784 batches | lr 3.87 | ms/batch 28.28 | loss  5.50 | ppl   243.48\n","| epoch   6 |  1800/ 2784 batches | lr 3.87 | ms/batch 28.28 | loss  5.47 | ppl   236.48\n","| epoch   6 |  2000/ 2784 batches | lr 3.87 | ms/batch 28.26 | loss  5.42 | ppl   224.78\n","| epoch   6 |  2200/ 2784 batches | lr 3.87 | ms/batch 28.30 | loss  5.46 | ppl   234.91\n","| epoch   6 |  2400/ 2784 batches | lr 3.87 | ms/batch 28.22 | loss  5.48 | ppl   240.46\n","| epoch   6 |  2600/ 2784 batches | lr 3.87 | ms/batch 28.36 | loss  5.46 | ppl   234.30\n","-----------------------------------------------------------------------------------------\n","| end of epoch   6 | time: 81.84s | valid loss  6.34 | valid ppl   565.73\n","-----------------------------------------------------------------------------------------\n","| epoch   7 |   200/ 2784 batches | lr 3.68 | ms/batch 28.38 | loss  5.52 | ppl   249.02\n","| epoch   7 |   400/ 2784 batches | lr 3.68 | ms/batch 28.25 | loss  5.50 | ppl   245.14\n","| epoch   7 |   600/ 2784 batches | lr 3.68 | ms/batch 28.32 | loss  5.30 | ppl   200.75\n","| epoch   7 |   800/ 2784 batches | lr 3.68 | ms/batch 28.23 | loss  5.36 | ppl   213.13\n","| epoch   7 |  1000/ 2784 batches | lr 3.68 | ms/batch 28.33 | loss  5.29 | ppl   198.26\n","| epoch   7 |  1200/ 2784 batches | lr 3.68 | ms/batch 28.19 | loss  5.42 | ppl   224.91\n","| epoch   7 |  1400/ 2784 batches | lr 3.68 | ms/batch 28.32 | loss  5.44 | ppl   229.42\n","| epoch   7 |  1600/ 2784 batches | lr 3.68 | ms/batch 28.21 | loss  5.37 | ppl   214.73\n","| epoch   7 |  1800/ 2784 batches | lr 3.68 | ms/batch 28.41 | loss  5.35 | ppl   211.24\n","| epoch   7 |  2000/ 2784 batches | lr 3.68 | ms/batch 28.25 | loss  5.30 | ppl   200.23\n","| epoch   7 |  2200/ 2784 batches | lr 3.68 | ms/batch 28.39 | loss  5.34 | ppl   208.63\n","| epoch   7 |  2400/ 2784 batches | lr 3.68 | ms/batch 28.21 | loss  5.37 | ppl   214.69\n","| epoch   7 |  2600/ 2784 batches | lr 3.68 | ms/batch 28.36 | loss  5.33 | ppl   206.53\n","-----------------------------------------------------------------------------------------\n","| end of epoch   7 | time: 81.78s | valid loss  6.25 | valid ppl   520.60\n","-----------------------------------------------------------------------------------------\n","| epoch   8 |   200/ 2784 batches | lr 3.49 | ms/batch 28.54 | loss  5.39 | ppl   220.03\n","| epoch   8 |   400/ 2784 batches | lr 3.49 | ms/batch 28.24 | loss  5.39 | ppl   219.22\n","| epoch   8 |   600/ 2784 batches | lr 3.49 | ms/batch 28.35 | loss  5.19 | ppl   179.95\n","| epoch   8 |   800/ 2784 batches | lr 3.49 | ms/batch 28.23 | loss  5.26 | ppl   192.28\n","| epoch   8 |  1000/ 2784 batches | lr 3.49 | ms/batch 28.41 | loss  5.19 | ppl   179.15\n","| epoch   8 |  1200/ 2784 batches | lr 3.49 | ms/batch 28.26 | loss  5.31 | ppl   202.22\n","| epoch   8 |  1400/ 2784 batches | lr 3.49 | ms/batch 28.39 | loss  5.32 | ppl   204.83\n","| epoch   8 |  1600/ 2784 batches | lr 3.49 | ms/batch 28.24 | loss  5.27 | ppl   193.97\n","| epoch   8 |  1800/ 2784 batches | lr 3.49 | ms/batch 28.36 | loss  5.25 | ppl   189.69\n","| epoch   8 |  2000/ 2784 batches | lr 3.49 | ms/batch 28.22 | loss  5.19 | ppl   180.04\n","| epoch   8 |  2200/ 2784 batches | lr 3.49 | ms/batch 28.35 | loss  5.23 | ppl   187.21\n","| epoch   8 |  2400/ 2784 batches | lr 3.49 | ms/batch 28.29 | loss  5.26 | ppl   192.15\n","| epoch   8 |  2600/ 2784 batches | lr 3.49 | ms/batch 28.28 | loss  5.23 | ppl   186.02\n","-----------------------------------------------------------------------------------------\n","| end of epoch   8 | time: 81.86s | valid loss  6.32 | valid ppl   557.72\n","-----------------------------------------------------------------------------------------\n","| epoch   9 |   200/ 2784 batches | lr 3.32 | ms/batch 28.56 | loss  5.30 | ppl   199.64\n","| epoch   9 |   400/ 2784 batches | lr 3.32 | ms/batch 28.25 | loss  5.28 | ppl   197.08\n","| epoch   9 |   600/ 2784 batches | lr 3.32 | ms/batch 28.37 | loss  5.10 | ppl   163.86\n","| epoch   9 |   800/ 2784 batches | lr 3.32 | ms/batch 28.26 | loss  5.16 | ppl   173.63\n","| epoch   9 |  1000/ 2784 batches | lr 3.32 | ms/batch 28.33 | loss  5.10 | ppl   164.14\n","| epoch   9 |  1200/ 2784 batches | lr 3.32 | ms/batch 28.26 | loss  5.21 | ppl   183.64\n","| epoch   9 |  1400/ 2784 batches | lr 3.32 | ms/batch 28.26 | loss  5.22 | ppl   184.53\n","| epoch   9 |  1600/ 2784 batches | lr 3.32 | ms/batch 28.33 | loss  5.18 | ppl   176.90\n","| epoch   9 |  1800/ 2784 batches | lr 3.32 | ms/batch 28.20 | loss  5.15 | ppl   173.12\n","| epoch   9 |  2000/ 2784 batches | lr 3.32 | ms/batch 28.34 | loss  5.10 | ppl   163.95\n","| epoch   9 |  2200/ 2784 batches | lr 3.32 | ms/batch 28.17 | loss  5.13 | ppl   169.54\n","| epoch   9 |  2400/ 2784 batches | lr 3.32 | ms/batch 28.35 | loss  5.16 | ppl   173.71\n","| epoch   9 |  2600/ 2784 batches | lr 3.32 | ms/batch 28.24 | loss  5.13 | ppl   169.60\n","-----------------------------------------------------------------------------------------\n","| end of epoch   9 | time: 81.80s | valid loss  6.34 | valid ppl   566.72\n","-----------------------------------------------------------------------------------------\n","| epoch  10 |   200/ 2784 batches | lr 3.15 | ms/batch 28.35 | loss  5.20 | ppl   180.44\n","| epoch  10 |   400/ 2784 batches | lr 3.15 | ms/batch 28.19 | loss  5.18 | ppl   178.17\n","| epoch  10 |   600/ 2784 batches | lr 3.15 | ms/batch 28.18 | loss  5.00 | ppl   148.80\n","| epoch  10 |   800/ 2784 batches | lr 3.15 | ms/batch 28.31 | loss  5.07 | ppl   158.39\n","| epoch  10 |  1000/ 2784 batches | lr 3.15 | ms/batch 28.24 | loss  5.01 | ppl   150.16\n","| epoch  10 |  1200/ 2784 batches | lr 3.15 | ms/batch 28.33 | loss  5.11 | ppl   166.07\n","| epoch  10 |  1400/ 2784 batches | lr 3.15 | ms/batch 28.21 | loss  5.12 | ppl   167.43\n","| epoch  10 |  1600/ 2784 batches | lr 3.15 | ms/batch 28.36 | loss  5.08 | ppl   160.82\n","| epoch  10 |  1800/ 2784 batches | lr 3.15 | ms/batch 28.20 | loss  5.07 | ppl   159.53\n","| epoch  10 |  2000/ 2784 batches | lr 3.15 | ms/batch 28.37 | loss  5.01 | ppl   150.22\n","| epoch  10 |  2200/ 2784 batches | lr 3.15 | ms/batch 28.26 | loss  5.04 | ppl   154.54\n","| epoch  10 |  2400/ 2784 batches | lr 3.15 | ms/batch 28.37 | loss  5.06 | ppl   157.49\n","| epoch  10 |  2600/ 2784 batches | lr 3.15 | ms/batch 28.24 | loss  5.04 | ppl   155.00\n","-----------------------------------------------------------------------------------------\n","| end of epoch  10 | time: 81.72s | valid loss  6.46 | valid ppl   639.05\n","-----------------------------------------------------------------------------------------\n"]}]},{"cell_type":"markdown","metadata":{"id":"kVn3Ydd3nLWm"},"source":["テストデータセットでモデルを評価する\n","-------------------------------------\n","\n","結果を確認するために、ベストモデルでテスト用データセットを評価する\n"]},{"cell_type":"code","metadata":{"id":"2sL5nPiHPPeU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768457445383,"user_tz":-540,"elapsed":3379,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"6fe44883-fc6e-405d-bcc2-d18b893bd5a9"},"source":["test_loss = evaluate(best_model, test_data)\n","test_ppl = math.exp(test_loss)\n","print('=' * 89)\n","print(f'| End of training | test loss {test_loss:5.2f} | '\n","      f'test ppl {test_ppl:8.2f}')\n","print('=' * 89)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=========================================================================================\n","| End of training | test loss  6.30 | test ppl   543.61\n","=========================================================================================\n"]}]},{"cell_type":"code","source":["evaltext = \"I have enjoyed learning about machine learning so much that I want to continue learning even after the class is over.\"\n","evaltext = tokenizer(evaltext)\n","evaltext"],"metadata":{"id":"vzutwiIEqrN3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768457445397,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"bfb30603-9062-49db-8164-8d65011533fb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i',\n"," 'have',\n"," 'enjoyed',\n"," 'learning',\n"," 'about',\n"," 'machine',\n"," 'learning',\n"," 'so',\n"," 'much',\n"," 'that',\n"," 'i',\n"," 'want',\n"," 'to',\n"," 'continue',\n"," 'learning',\n"," 'even',\n"," 'after',\n"," 'the',\n"," 'class',\n"," 'is',\n"," 'over',\n"," '.']"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["evalvcab = vocab(evaltext)\n","evallen = len(evalvcab)\n","evalvcab"],"metadata":{"id":"zMS0q6rqqt8F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768457445402,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"0b509ded-050f-4d5c-9c1d-1cab561ca10e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[719,\n"," 337,\n"," 877,\n"," 5650,\n"," 724,\n"," 10433,\n"," 5650,\n"," 493,\n"," 731,\n"," 147,\n"," 719,\n"," 10591,\n"," 18,\n"," 1733,\n"," 5650,\n"," 1854,\n"," 138,\n"," 14,\n"," 373,\n"," 22,\n"," 84,\n"," 12]"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["evalmask = torch.zeros(evallen)\n","evalmask = generate_square_subsequent_mask(len(evalvcab)).to(device)"],"metadata":{"id":"oxSTq8By34vC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","evalout = model(torch.tensor(evalvcab).to(device), evalmask.to(device))"],"metadata":{"id":"eF3DlgIKq-UN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evalcode = list()\n","for i in range(evallen):\n","  evalcode.append(torch.argmax(evalout[i], dim=1)[i])"],"metadata":{"id":"TMTdtTYgwt8M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","evalcode = list()\n","#np.argsort(evalout[0][0])\n","for i in range(evallen):\n","  evalline = evalout[i][i].to('cpu').detach().numpy().copy()\n","  evalsort = np.argsort(-evalline)\n","  evalcode.append(evalsort)\n","evalcode"],"metadata":{"id":"h1tW6Q5K0rsh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768457445511,"user_tz":-540,"elapsed":59,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"09414ac8-2051-41ec-9f95-ac5035c41171"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([ 1199,   249, 11402, ...,  6541, 16137, 10892]),\n"," array([  528,    23,     5, ..., 13315, 25255, 16879]),\n"," array([  353,   349,    23, ..., 13353, 13380, 28725]),\n"," array([  724,    18,   147, ...,  1108, 19283, 11685]),\n"," array([   23,    18,   353, ..., 56139,  8638, 63459]),\n"," array([ 1602,  1720,     7, ..., 13888, 16112,  4327]),\n"," array([  724,    18,   147, ..., 19283,  1108, 11685]),\n"," array([  147,    39,   719, ...,  3388, 21954, 53627]),\n"," array([   13,    18,   101, ..., 19466, 35716,  1487]),\n"," array([ 495, 1954,  207, ..., 5796, 9021, 1763]),\n"," array([ 1199,   249, 11402, ...,  6541, 16137, 10892]),\n"," array([   18,    23,   705, ..., 12818,  7733, 59207]),\n"," array([  203,    14,    23, ...,  7455,  5704, 28588]),\n"," array([   18,    39,   523, ..., 28330, 42600, 15462]),\n"," array([  724,    18,    10, ..., 12021,  1108, 11685]),\n"," array([   39,   216,    23, ..., 56153, 56335, 53627]),\n"," array([  495,   349,    23, ...,  6567, 61555, 18147]),\n"," array([   56,    66, 54909, ..., 25255, 30171, 15558]),\n"," array([  128,  5122,    10, ..., 48286, 30185, 60534]),\n"," array([   23,   632,   143, ..., 13854, 35868, 15271]),\n"," array([   23,    14,  2996, ..., 18448, 13845,  6247]),\n"," array([  495,    39,    89, ..., 18557, 29874, 39968])]"]},"metadata":{},"execution_count":64}]},{"cell_type":"markdown","source":["実はあまりうまくいっていない\n","- 気持ちはわからなくもない\n","- 一般にTransformerは大量のデータを用いて時間をかけて学習することで精度が良くなることが知られている"],"metadata":{"id":"ogkE2yYJypcm"}},{"cell_type":"code","source":["import pandas as pd\n","tbl = list()\n","for i, id in enumerate(evalcode):\n","  tbl.append([evalvcab[i], vocab.lookup_token(evalvcab[i]),\n","    id[0].tolist(), vocab.lookup_token(id[0]),\n","    id[1].tolist(), vocab.lookup_token(id[1]),\n","    id[2].tolist(), vocab.lookup_token(id[2]),\n","    id[3].tolist(), vocab.lookup_token(id[3]),\n","    id[4].tolist(), vocab.lookup_token(id[4])])\n","df = pd.DataFrame(tbl)\n","df"],"metadata":{"id":"t4L_LDsgxjt3","colab":{"base_uri":"https://localhost:8080/","height":739},"executionInfo":{"status":"ok","timestamp":1768457445560,"user_tz":-540,"elapsed":44,"user":{"displayName":"Hiroaki Nishi","userId":"14553810797225214496"}},"outputId":"6b7412b4-df16-47d5-f62f-f356d9dac941"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       0         1     2      3     4            5      6       7     8   \\\n","0     719         i  1199      m   249         love  11402      ve  6290   \n","1     337      have   528   been    23            a      5      no  1374   \n","2     877   enjoyed   353    her   349          his     23       a   147   \n","3    5650  learning   724  about    18           to    147    that    10   \n","4     724     about    23      a    18           to    353     her  1191   \n","5   10433   machine  1602   guns  1720          gun      7       :    10   \n","6    5650  learning   724  about    18           to    147    that    10   \n","7     493        so   147   that    39           in    719       i   207   \n","8     731      much    13     of    18           to    101    more   724   \n","9     147      that   495     he  1954          she    207    they   689   \n","10    719         i  1199      m   249         love  11402      ve  6290   \n","11  10591      want    18     to    23            a    705     him   285   \n","12     18        to   203     be    14          the     23       a   349   \n","13   1733  continue    18     to    39           in    523   until   285   \n","14   5650  learning   724  about    18           to     10       ,   147   \n","15   1854      even    39     in   216         when     23       a   101   \n","16    138     after   495     he   349          his     23       a    14   \n","17     14       the    56  first    66       second  54909  kakapo  4008   \n","18    373     class   128    was  5122  battleships     10       ,    12   \n","19     22        is    23      a   632   considered    143      an    95   \n","20     84      over    23      a    14          the   2996      50   349   \n","21     12         .   495     he    39           in     89      on  1954   \n","\n","        9     10       11  \n","0    think  4618      don  \n","1     long    95     also  \n","2     that    39       in  \n","3        ,    32      and  \n","4       30   437        1  \n","5        ,   666     were  \n","6        ,    32      and  \n","7     they    42       it  \n","8    about    19       as  \n","9    could    42       it  \n","10   think  4618      don  \n","11   their   773      you  \n","12     his   337     have  \n","13   their    19       as  \n","14    that    32      and  \n","15    more   278       at  \n","16     the   304    being  \n","17  island  1512    river  \n","18       .    13       of  \n","19    also    39       in  \n","20     his  3111      100  \n","21     she   562  however  "],"text/html":["\n","  <div id=\"df-6e8e99bb-3e95-4e1b-b119-60ee795da51d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>719</td>\n","      <td>i</td>\n","      <td>1199</td>\n","      <td>m</td>\n","      <td>249</td>\n","      <td>love</td>\n","      <td>11402</td>\n","      <td>ve</td>\n","      <td>6290</td>\n","      <td>think</td>\n","      <td>4618</td>\n","      <td>don</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>337</td>\n","      <td>have</td>\n","      <td>528</td>\n","      <td>been</td>\n","      <td>23</td>\n","      <td>a</td>\n","      <td>5</td>\n","      <td>no</td>\n","      <td>1374</td>\n","      <td>long</td>\n","      <td>95</td>\n","      <td>also</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>877</td>\n","      <td>enjoyed</td>\n","      <td>353</td>\n","      <td>her</td>\n","      <td>349</td>\n","      <td>his</td>\n","      <td>23</td>\n","      <td>a</td>\n","      <td>147</td>\n","      <td>that</td>\n","      <td>39</td>\n","      <td>in</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5650</td>\n","      <td>learning</td>\n","      <td>724</td>\n","      <td>about</td>\n","      <td>18</td>\n","      <td>to</td>\n","      <td>147</td>\n","      <td>that</td>\n","      <td>10</td>\n","      <td>,</td>\n","      <td>32</td>\n","      <td>and</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>724</td>\n","      <td>about</td>\n","      <td>23</td>\n","      <td>a</td>\n","      <td>18</td>\n","      <td>to</td>\n","      <td>353</td>\n","      <td>her</td>\n","      <td>1191</td>\n","      <td>30</td>\n","      <td>437</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>10433</td>\n","      <td>machine</td>\n","      <td>1602</td>\n","      <td>guns</td>\n","      <td>1720</td>\n","      <td>gun</td>\n","      <td>7</td>\n","      <td>:</td>\n","      <td>10</td>\n","      <td>,</td>\n","      <td>666</td>\n","      <td>were</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>5650</td>\n","      <td>learning</td>\n","      <td>724</td>\n","      <td>about</td>\n","      <td>18</td>\n","      <td>to</td>\n","      <td>147</td>\n","      <td>that</td>\n","      <td>10</td>\n","      <td>,</td>\n","      <td>32</td>\n","      <td>and</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>493</td>\n","      <td>so</td>\n","      <td>147</td>\n","      <td>that</td>\n","      <td>39</td>\n","      <td>in</td>\n","      <td>719</td>\n","      <td>i</td>\n","      <td>207</td>\n","      <td>they</td>\n","      <td>42</td>\n","      <td>it</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>731</td>\n","      <td>much</td>\n","      <td>13</td>\n","      <td>of</td>\n","      <td>18</td>\n","      <td>to</td>\n","      <td>101</td>\n","      <td>more</td>\n","      <td>724</td>\n","      <td>about</td>\n","      <td>19</td>\n","      <td>as</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>147</td>\n","      <td>that</td>\n","      <td>495</td>\n","      <td>he</td>\n","      <td>1954</td>\n","      <td>she</td>\n","      <td>207</td>\n","      <td>they</td>\n","      <td>689</td>\n","      <td>could</td>\n","      <td>42</td>\n","      <td>it</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>719</td>\n","      <td>i</td>\n","      <td>1199</td>\n","      <td>m</td>\n","      <td>249</td>\n","      <td>love</td>\n","      <td>11402</td>\n","      <td>ve</td>\n","      <td>6290</td>\n","      <td>think</td>\n","      <td>4618</td>\n","      <td>don</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>10591</td>\n","      <td>want</td>\n","      <td>18</td>\n","      <td>to</td>\n","      <td>23</td>\n","      <td>a</td>\n","      <td>705</td>\n","      <td>him</td>\n","      <td>285</td>\n","      <td>their</td>\n","      <td>773</td>\n","      <td>you</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>18</td>\n","      <td>to</td>\n","      <td>203</td>\n","      <td>be</td>\n","      <td>14</td>\n","      <td>the</td>\n","      <td>23</td>\n","      <td>a</td>\n","      <td>349</td>\n","      <td>his</td>\n","      <td>337</td>\n","      <td>have</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1733</td>\n","      <td>continue</td>\n","      <td>18</td>\n","      <td>to</td>\n","      <td>39</td>\n","      <td>in</td>\n","      <td>523</td>\n","      <td>until</td>\n","      <td>285</td>\n","      <td>their</td>\n","      <td>19</td>\n","      <td>as</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>5650</td>\n","      <td>learning</td>\n","      <td>724</td>\n","      <td>about</td>\n","      <td>18</td>\n","      <td>to</td>\n","      <td>10</td>\n","      <td>,</td>\n","      <td>147</td>\n","      <td>that</td>\n","      <td>32</td>\n","      <td>and</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>1854</td>\n","      <td>even</td>\n","      <td>39</td>\n","      <td>in</td>\n","      <td>216</td>\n","      <td>when</td>\n","      <td>23</td>\n","      <td>a</td>\n","      <td>101</td>\n","      <td>more</td>\n","      <td>278</td>\n","      <td>at</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>138</td>\n","      <td>after</td>\n","      <td>495</td>\n","      <td>he</td>\n","      <td>349</td>\n","      <td>his</td>\n","      <td>23</td>\n","      <td>a</td>\n","      <td>14</td>\n","      <td>the</td>\n","      <td>304</td>\n","      <td>being</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>14</td>\n","      <td>the</td>\n","      <td>56</td>\n","      <td>first</td>\n","      <td>66</td>\n","      <td>second</td>\n","      <td>54909</td>\n","      <td>kakapo</td>\n","      <td>4008</td>\n","      <td>island</td>\n","      <td>1512</td>\n","      <td>river</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>373</td>\n","      <td>class</td>\n","      <td>128</td>\n","      <td>was</td>\n","      <td>5122</td>\n","      <td>battleships</td>\n","      <td>10</td>\n","      <td>,</td>\n","      <td>12</td>\n","      <td>.</td>\n","      <td>13</td>\n","      <td>of</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>22</td>\n","      <td>is</td>\n","      <td>23</td>\n","      <td>a</td>\n","      <td>632</td>\n","      <td>considered</td>\n","      <td>143</td>\n","      <td>an</td>\n","      <td>95</td>\n","      <td>also</td>\n","      <td>39</td>\n","      <td>in</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>84</td>\n","      <td>over</td>\n","      <td>23</td>\n","      <td>a</td>\n","      <td>14</td>\n","      <td>the</td>\n","      <td>2996</td>\n","      <td>50</td>\n","      <td>349</td>\n","      <td>his</td>\n","      <td>3111</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>12</td>\n","      <td>.</td>\n","      <td>495</td>\n","      <td>he</td>\n","      <td>39</td>\n","      <td>in</td>\n","      <td>89</td>\n","      <td>on</td>\n","      <td>1954</td>\n","      <td>she</td>\n","      <td>562</td>\n","      <td>however</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e8e99bb-3e95-4e1b-b119-60ee795da51d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6e8e99bb-3e95-4e1b-b119-60ee795da51d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6e8e99bb-3e95-4e1b-b119-60ee795da51d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_3c93f587-49a9-4314-bf30-67e7d2acca65\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_3c93f587-49a9-4314-bf30-67e7d2acca65 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3283,\n        \"min\": 12,\n        \"max\": 10591,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          719,\n          10433,\n          1733\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"i\",\n          \"machine\",\n          \"continue\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 456,\n        \"min\": 13,\n        \"max\": 1602,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          18,\n          39,\n          1199\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"to\",\n          \"in\",\n          \"m\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1157,\n        \"min\": 14,\n        \"max\": 5122,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          5122,\n          66,\n          249\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"battleships\",\n          \"second\",\n          \"love\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11882,\n        \"min\": 5,\n        \"max\": 54909,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          11402,\n          5,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"ve\",\n          \"no\",\n          \":\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1908,\n        \"min\": 10,\n        \"max\": 6290,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          6290,\n          1374,\n          207\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 9,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"think\",\n          \"long\",\n          \"they\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 10,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1420,\n        \"min\": 13,\n        \"max\": 4618,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          4618,\n          95,\n          666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 11,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"don\",\n          \"also\",\n          \"were\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":65}]},{"cell_type":"markdown","source":["---\n","> The language of poetry is so dense, so multivalent, that it demands a concentrated act of attention\n","> — and offers its greatest rewards only to those who reread.\n",">\n","> (Ezra Pound)\n",">\n","> 詩の言葉はあまりに密集し、様々な意味を持つため、集中的な意識を払うことが求められる。そして、\n","> 再読をする者にだけ最大の報酬を提供するのである。\n",">\n","> (エズラ・パウンド)\n","---"],"metadata":{"id":"wA0Xs4PhR43f"}},{"cell_type":"markdown","source":["# 課題(Multi-Head Attention)\n","次のMulti-Head Attentionのコードを参考に、Single-Head AttentionをMulti-Head Attentionに入れ替えて実行させて精度などの変化を確認しなさい"],"metadata":{"id":"S-8tc9Wzy5Xv"}},{"cell_type":"code","source":["def scaled_dot_product(q, k, v, mask=None):\n","    d_k = q.size()[-1]\n","    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n","    attn_logits = attn_logits / math.sqrt(d_k)\n","    if mask is not None:\n","        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n","    attention = F.softmax(attn_logits, dim=-1)\n","    values = torch.matmul(attention, v)\n","    return values, attention\n","\n","class MultiheadAttention(nn.Module):\n","    def __init__(self, input_dim, embed_dim, num_heads):\n","        super().__init__()\n","        assert embed_dim % num_heads == 0, \"Embedding dimension cannot be equal to the number of heads as modulo.\"\n","        self.embed_dim = embed_dim\n","        self.num_heads = num_heads\n","        self.head_dim = embed_dim // num_heads\n","        self.qkv_proj = nn.Linear(input_dim, 3*embed_dim)\n","        self.o_proj = nn.Linear(embed_dim, embed_dim)\n","        self._reset_parameters()\n","    def forward(self, x, mask=None, return_attention=False):\n","        batch_size, seq_length, _ = x.size()\n","        qkv = self.qkv_proj(x)\n","        # Separate Q, K, V from linear output\n","        qkv = qkv.reshape(batch_size, seq_length, self.num_heads, 3*self.head_dim)\n","        qkv = qkv.permute(0, 2, 1, 3) # [Batch, Head, SeqLen, Dims]\n","        q, k, v = qkv.chunk(3, dim=-1)\n","        # Determine value outputs\n","        values, attention = scaled_dot_product(q, k, v, mask=mask)\n","        values = values.permute(0, 2, 1, 3) # [Batch, SeqLen, Head, Dims]\n","        values = values.reshape(batch_size, seq_length, self.embed_dim)\n","        o = self.o_proj(values)\n","        if return_attention:\n","            return o, attention\n","        else:\n","            return o"],"metadata":{"id":"XYkoQ03Qy7F4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 課題(PyTorch Transformerを用いた単語予測)\n","\n","- 日本語による単語補完にトライしてみよう\n"],"metadata":{"id":"U1Px28MVROMY"}}]}