{"cells":[{"cell_type":"markdown","metadata":{"id":"bHZ54p4iIfem"},"source":["---\n",">「団結は強さだ… チームワークとコラボレーションがあれば、すごいことが成し遂げられる。」\n",">\n","> Mattie Stepanek\n","---"]},{"cell_type":"markdown","metadata":{"id":"L9HXMz2Zvn8D"},"source":["# 連合学習が生まれた背景\n","\n","AIには大量のデータが必要であるが、データを集めるには様々な障害がある\n","- 契約上の問題\n","  - 契約で情報の二次配布ができないなど\n","- プライバシの問題\n","  - 学習に用いるデータに個人を特定可能な情報が含まれている場合、オプトインを取得するなど容易に利用することができない\n","- 通信・ストレージの問題\n","  - データを大量にかつ一か所に集めるには、それに見合ったストレージ量や通信容量が必要\n","- 規制\n","  - General Data Protection Regulation （GDPR）  \n","  一般データ保護規則\n","  - California Consumer Privacy Act of 2018（CCPA）  \n","  カリフォルニア州消費者プライバシ法\n","  - 様々な規制が提示されている\n","\n","これらを解決するためには、プライバシを確保しながら分断されたデータでも利用可能な機械学習方法が必要である"]},{"cell_type":"markdown","source":["# 連合学習(Federated Learning)とは\n","\n","複数のデータ所有者が協力して1つの機械学習モデルを構築することを一般に連合学習と呼ぶ\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/flfig.png\" width=500>\n","\n","以下のような特徴・必要事項がある\n","- 参加者の生データそのものは交換しない\n","  - 連合学習に参加し、他の参加者が所有するデータを復元することが困難\n","  - 生データそのものが交換されれば、それぞれ独立したモデルの融合となる\n","- 参加者自身が所有するデータのみで学習させるモデルよりも連合学習の方が高くなる\n","  - ローカルのみの方が高性能であれば連合学習は不要である\n","- モデルの性能はすべてのデータを集約した際の性能に近くなる\n","  - 連合学習の方が高性能ならデータを集約する必要はない\n","\n","なお、連合学習の他、モデルを分割する分散学習も存在し、それらの特徴は、情報通信ネットワークを用いて、学習の計算過程やパラメータ更新などを交換することである\n","- 従って、クライアント・サーバモデルを前提とする場合が多い\n","  - 様々なリモートで情報を交換するため、セキュリティ上の問題が発生する\n","    - サーバが公開してはならないクライアントの情報を公開する\n","    - クライアントが粗悪な学習を行った結果、全体の性能も低下する\n","\n"],"metadata":{"id":"aSrLcM-UZyyl"}},{"cell_type":"markdown","metadata":{"id":"gd-vX3cavOCt"},"source":["# セキュリティ\n","\n","機械学習のセキュリティは大きく２つの考え方がある\n","\n","- セキュア機械学習  \n","攻撃者は機械学習システムを破壊する\n","  - 整合性：モデルの出力を改変し誤った出力とする\n","  - 可用性：モデルパラメータを使用できないレベルに改変する\n","- プライバシ保護機械学習(連合学習のターゲット)  \n","  攻撃者は機械学習システムのプライバシを侵害する\n","  - プライバシ：データ提供者の個人情報を特定する\n","  - 機密性：モデル情報を流出させる"]},{"cell_type":"markdown","source":["\n","## MLに関連するセキュリティ\n","\n","MLに関連するセキュリティについて、連合学習とは少し観点が異なるが、ここでまとめておく\n","\n","|  | プライバシ保護ML | セキュアML |\n","| :---: | :--- | :--- |\n","| セキュリティ違反 | - プライバシ | - 整合性 |\n","|  | - 機密性 | - 可用性 |\n","| 攻撃 | - 再構築攻撃 | - モデルポイズニング攻撃 |\n","|  | - モデル反転攻撃 | - 敵対的攻撃 |\n","|  | - メンバーシップ推論攻撃 | - 中間者攻撃 |\n","| 防御手法 | - MPC | - 防御的蒸留 |\n","|  | - 準同型暗号 | - 敵対的学習 |\n","|  | - 差分プライバシ | - 正則化 |\n","\n","\n","- 再構築攻撃: ランダムに初期化した乱数データを入力して勾配情報を獲得、勾配を基に窃取したいデータが属するクラスに対する入力データの誤差が小さくなる方向に入力データを変更することで特定に近づける\n","- モデル反転攻撃: モデルの入力と出力を反転させる手法で、モデルが入手できている場合は直接勾配降下法で入力データ特定に向けた最適化が可能\n","- メンバーシップ推論攻撃: 学習データ分布を予測し、「学習データに含まれていると思われるデータ」と「含まれていないと思われるデータ」を用意、その分類スコアを獲得、さらにそのスコアを入力としてメンバーかどうかを独自に構築した攻撃用ネットワークで学習させることで、どのような分類の入力が利用されたかを特定する\n","- モデルポイズニング攻撃: モデルが誤った推論を行うように、誤った入力を投入させる\n","- 敵対的攻撃: 本来のデータと区別がつきにくい敵対例に対して、正しいデータが獲得できないようなデータを提示することで、その解決法としてReLUのような微分不可能な点を含まない活性化関数を利用することが挙げられている\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/adversarial_example.png\" width=500>\n","\n","- MPC(Multi-party Computation): 複数人感での通信\n","- 準同型暗号: 暗号化したまま計算や検索ができる暗号化方式\n","- 差分プライバシ: ある個人のデータを含むデータセットについて、それと隣接(ある特定の部分しか違わない)データセットと区別できないようにデータを加工する匿名化手法で、一般にデータにラプラスノイズを加えて(ラプラスメカニズム)匿名化する\n","- 防御的蒸留: 学習済みモデルの入力と出力をよりシンプルなアーキテクチャを持ったモデルで学習させて比較する\n","- 敵対的学習: 正しいラベルと紐づけた敵対的サンプルを学習データに加えて学習を行う防御手法\n","- 正則化: 情報を追加する、ペナルティを与えるなどした情報の加工により過学習を防ぐ\n","\n","その他、勾配マスキングと呼ばれる、学習時に入力データに対する微分値を最小化（難読化）することで、敵対的サンプルの効果を低減させる防御手法がある"],"metadata":{"id":"pIiBZgFMjDSr"}},{"cell_type":"markdown","source":["## 攻撃について"],"metadata":{"id":"mRojpN-mjX-K"}},{"cell_type":"markdown","source":["### 想定される攻撃者像\n","\n","- 正直者  \n","基本的に無害\n","- “semi-honest”, “honest-but-curious”, “半正直”な攻撃者  \n","  - プロトコルやルールは守る\n","  - 自身が取得できない情報を不正に知ろうとする\n","- 悪意のある攻撃者\n","  - プロトコルやルールから逸脱する\n","  - システム破壊を試みる"],"metadata":{"id":"zWk-tjzDjbQp"}},{"cell_type":"markdown","source":["### 機械学習システムへのプライバシ脅威モデル\n","- 再構築攻撃\n","  - 学習や推論時に生データや特徴ベクトルを再構築  \n","ex. 勾配情報から学習データを復元\n","- モデル反転攻撃  \n","  - 様々なデータをモデルに入力して学習データやモデル構造を再構築する\n","- メンバーシップ推論攻撃\n","  - 特定の標本が学習データに含まれているかを調べる\n","- 属性推論攻撃\n","  - 公開データの中から個人(標本)を識別することで、個人の属性を入手する\n","    - 強力な背景知識があれば匿名化されていても個人を特定可能となる場合がある\n","- モデルポイズニング攻撃\n","  - 学習処理を解析、攻撃してモデルの更新をコントロールする\n","    - ex. 自分の更新だけ強く反映させる\n","  - 連合学習は特にこの点での脆弱性に対する対応が必要となる"],"metadata":{"id":"vCC1IxwlGvTQ"}},{"cell_type":"markdown","source":["# 分散深層学習"],"metadata":{"id":"7QR6_px4HOjv"}},{"cell_type":"markdown","source":["連合学習は、通信ネットワークなどを介して、異なる場所で学習モデルを統一する仕組みであるが、これは、より広い、「分散深層学習」の一部とみなすことができる\n","\n","例えば、大きなニューラルネットワークを通信ネットワークをつなげて複数のホストで扱うなども可能であり、これらをまとめて分散深層学習と呼ぶ\n","\n","なお、推論時の分散は容易であるが、学習時の分散は、誤差逆伝播の仕組みもネットワークを介して行われるため、より複雑になる\n","- 通信コストも大きくなり、導入メリットが得にくい形態である"],"metadata":{"id":"ispcRTJV7g6k"}},{"cell_type":"markdown","source":["## 分散機械学習の目的\n","\n","スケーラビリティの獲得\n","\n","- 機械学習をスケールさせる\n","  - 大規模化しても性能が追従して向上してほしい\n","- 分散処理\n","  - メモリ不足に対応する\n","- データを水平分割し複数ノードで同時に並列して学習を行う\n","  - 学習時間を短縮する\n","- プライバシ保護\n","  - データ所有者がデータ公開を望まない\n","- データ公開ではない方法で協調し学習を達成したい\n","  - 分散処理\n"],"metadata":{"id":"PAEgfJhpqM8_"}},{"cell_type":"markdown","source":["## 対応手法\n","- データ並列\n","  - 巨大な学習データを水平分割し並列学習を行う\n","- ノード間の学習を集約する\n","  - モデル並列\n","    - 巨大なモデルを分割し複数GPUを利用して学習する\n","    - パイプライン化してスループットを向上させる\n","- グラフ並列\n","  - Graph Neural Network(GNN)について並列化する\n","    - データの関連をネットワークで表現したグラフデータに深層学習を取り入れたモデル\n","    - RNNはunfoldして直列につながったGNNとみなすことができ、これをより複雑なネットワークにする\n","    - グラフとしての入力データからデータグループ間の結合を獲得して学習を進める\n","- タスク並列\n","  - タスクを分割して並列実行する\n","  - 複数GPUやGPU・CPU協調など\n","\n"],"metadata":{"id":"qBtDKZFNsIey"}},{"cell_type":"markdown","source":["プライバシ保護が目的の分散機械学習\n","\n","何を秘匿したいのか（どれか，もしくは全部）\n","入力の学習データ\n","出力の予測ラベル\n","モデル情報\n","メタデータ（データと所有者の関係性とか）\n","データの分割\n","水平分割\n","標本は異なるが，属性は同じ\n","ex. 全ての参加者が同じビジネスをしている\n","垂直分割\n","標本は同じだが，属性が異なる\n","ex. 参加者は異なるビジネスをしている\n","\n"],"metadata":{"id":"8bVbaV3vqRSa"}},{"cell_type":"markdown","source":["## プライバシ保護分散機械学習技術\n","\n","- 匿名化\n","  - 差分プライバシなどで匿名化されたデータを使用する\n","    - 比較的実装が容易\n","    - データのみ匿名化される\n","    - 匿名化によりモデル性能が低下する\n","- 秘密計算による暗号化\n","  - 秘密計算などを用いて分散機械学習を行う\n","  - 計算効率が低下する\n","- プライバシ保護勾配降下法\n","  - 代数的アプローチ\n","    - 行列計算の代数的性質を利用する\n","    - その内容は秘密計算に近しい\n","  - 疎な勾配更新\n","    - 勾配の一部のみを共有する\n","  - 勾配を通信する際に差分プライバシを施す\n","  - 勾配を量子化する\n","- Naïveな連合学習\n","  - FedAvg\n","\n","すべての問題を解決する手法はなく次の点でトレードオフとなる\n","- モデル性能\n","- 計算コスト\n","- 通信コスト\n","\n"],"metadata":{"id":"aUHFETI5qWJs"}},{"cell_type":"markdown","source":["# Naïveな連合学習\n","\n","FedAvgがもっともよく知られている\n","\n","- 想定環境\n","  - データが水平に分割されている\n","  - 全ての参加者で同じタスクを行う\n","- FedAvgの方法\n","  - 参加者がそれぞれのモデルとデータでモデルの更新を行う\n","  - 参加者は勾配(モデルの更新情報)をコーディネータ(サーバ)に送る\n","  - コーディネータは集約した勾配もしくはモデルの加重平均を用いてグローバルモデルを更新する\n","  - コーディネータはグローバルモデルを参加者に配布する\n","  - 上記を繰り返す\n","\n","- FedAvgにおけるプライバシの定義\n","  - 参加者が保持する生データが開示されなければ良い\n","    - ただし、勾配から生データ情報をおおよそ復元可能であることが実証されている\n","  - コーディネータは不正をしない\n","    - 実際にはコーディネータが攻撃者になり勾配を公開する可能性が否定できない\n","\n"],"metadata":{"id":"CrOmJXR6qaaA"}},{"cell_type":"markdown","source":["# 水平連合学習\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/DataDistribution_Horizontal.png\" width=300>\n","\n","- 特徴\n","  - データが水平に分割される\n","    - 赤い部分が水平に区切られる\n","  - 標本は異なるが、属性は同じ\n","\n","- 具体例(次ような場合)\n","  - 参加者は地方銀行で似たカラムのDBを保持\n","  - 参加者はそれぞれの地域でサービスを提供\n","  - サービスの利用者(標本)は異なる\n","\n","- 水平連合学習のアルゴリズム\n","  - 先述のFedAvg\n","  - サーバクライアント型の連合学習\n","  - FedAvgでは何を平均化するのか？\n","    - モデル平均も勾配平均も両方ともFedAvgと呼ばれる\n","    - 参加者間でモデル初期値が同じであり、ローカルモデルの更新が行われると必ずモデル集約が行われる場合は、モデル平均と勾配平均が等価となる\n","\n","- 水平連合学習の課題\n","  - 設計者がデータを見ることができない（これはメリットでもある）\n","  - クライアントのデータが秘匿されているのでテスト環境を用意するのが難しい\n","  - ハイパーパラメータのチューニングのためなどに何回も実験することが困難\n","  - 参加者集める方法の検討が必要\n","  - 参加者が同じビジネスをしている場合は競合と協力することになるため契約上の問題が発生する可能性がある\n","  - インセンティブ設計が必要\n","  - 参加者の不正行為を防ぐ手法が必要\n"],"metadata":{"id":"gpAGtR1wqhMY"}},{"cell_type":"markdown","source":["-- 垂直連合学習\n","\n","<img src=\"http://class.west.sd.keio.ac.jp/dataai/text/DataDistribution_Vertical.png\" width=300>\n","\n","- 特徴\n","  - データが垂直に分割される\n","  - 標本は同じであるが、属性は異なる\n","\n","- 具体例(次のような場合)\n","  - 参加者は銀行と小売店で保持しているDBのカラムは異なる\n","  - 同じ個人がそれぞれのサービスを利用\n","  - 標本は同じ\n","\n","- 垂直連合学習のアルゴリズム\n","  - 連合線形回帰\n","    - 連合学習で線形回帰を実現\n","  - 準同型暗号を使用して参加者が保有するデータのプライバシを守る\n","    - SecureBoost\n","  - 連合学習でGBDTを実現\n","      - GBDTとはGradient(勾配)、Boosting(ブースティング) 、Decision(決定)、Tree(決定木であるDicision Tree)を組み合わせた手法のこと\n","\n","- 垂直連合学習の課題\n","  - 参加者の相互依存が大きい\n","  - 学習の途中で中間結果をやり取りすることが多い\n","  - 参加者ごとに持っているデータの属性が異なる\n","    - 参加者の離脱により連合学習が破綻しうる\n","    - 耐障害性が大事\n","\n","連合学習のプライバシ保護や攻撃に関する研究のほとんどが水平連合学習である"],"metadata":{"id":"oIRR6nNQqt7N"}},{"cell_type":"markdown","source":["# Federated Optimization（連合最適化）\n","\n","次のような分散最適化がある\n","- Non-IID: ユーザごとに持つデータの分布が異なる\n","- Unbalanced: ユーザによってデータ量が異なる\n","- Massively distributed:ユーザ数に比べて、ユーザごとのサンプルサイズが極めて少ない場合\n","- Limited communication: 通信量を削減する"],"metadata":{"id":"1MOQIbfgqy7i"}},{"cell_type":"markdown","source":["## Personalized Federated Learning\n","\n","- モデルをクライアントごとにPersonalizeする\n","- クライアント間のデータ分布の差異に対応\n","- さまざまな手法が提案されている\n","  - MAML問題の分散型手法\n","  - ヘッセ行列を近似する\n","  - モデルを組み合わせる手法\n","  - 共有部分とPersonalize部分に分けてそれぞれ学習させる手法\n","  - グローバルな部分をFedAvg，ローカルな部分をローカルで学習させる手法\n","  - 各クライアントがローカルな特徴抽出器とグローバルな出力を持つ手法\n","  - グローバルモデルとローカルモデルを異なる正則化で学習させる手法\n","  - データ分布が似ているクライクライアントをグループ化する手法\n","  - データ分布が近いクライアント同士で連携する手法"],"metadata":{"id":"UNvQ_n-d9itM"}},{"cell_type":"markdown","source":["Federated Learning(FL)を実際に実装する\n","\n","FLはネットワークでモデルを結合するため、普通に実装するとネットワークプログラミングが必要となる\n","\n","PyTorchには分散学習に関するコマンドが備わっているが、ネットワークプログラミングの知識は別途必要となる\n","\n","そこで、ここではFLライブラリを用いず、PyTorchの基本機能を用いて概念を理解する\n","- 通信部分は含んでおらず、仮想環境（リモート環境）を利用するような実装にはなっていない"],"metadata":{"id":"TuBgAgQbSw_V"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QwGLl2JnOq3w"},"outputs":[],"source":["import copy\n","from logging import Formatter, StreamHandler, getLogger\n","import os\n","import random\n","from typing import Dict, List\n","\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch import optim\n","from torch.utils.data import DataLoader\n","from torch.utils.data.dataset import Subset\n","import torchvision\n","import torchvision.transforms as transforms"]},{"cell_type":"markdown","source":["パラメータを設定する"],"metadata":{"id":"RVZ_pceMnNl-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KhtPaTqPOq3y"},"outputs":[],"source":["config = {\n","    \"batch_size\": 128,\n","    \"device\": \"cuda:0\",\n","    \"epochs\": 5,\n","    \"learning_rate\": 0.0001,\n","    \"num_clients\": 5,\n","    \"rounds\": 5,\n","    \"seed\": 42,\n","}"]},{"cell_type":"markdown","source":["ログの取得および乱数のシードに関する設定を行う"],"metadata":{"id":"1WbFOBajneyA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WBp1xNHLOq3y"},"outputs":[],"source":["def get_logger(name=\"EXP\"):\n","    log_fmt = Formatter(f\"%(asctime)s [{name}][%(levelname)s] %(message)s \")\n","    logger = getLogger(__name__)\n","    handler = StreamHandler()\n","    handler.setLevel(\"INFO\")\n","    handler.setFormatter(log_fmt)\n","    logger.setLevel(\"INFO\")\n","    logger.addHandler(handler)\n","    logger.propagate = False\n","    return logger\n","\n","def seed_everything(seed=1234):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True"]},{"cell_type":"markdown","source":["専用のデータローダを設定する"],"metadata":{"id":"tB16C2nonlWw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jo1CG5W_Oq3z"},"outputs":[],"source":["class FedAvgRetriever():\n","    def __init__(self, config: Dict) -> None:\n","        self.config = config\n","\n","        # init CIFAR-10\n","        transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","        ])\n","        self.train_set = torchvision.datasets.CIFAR10(\n","            root='./data', train=True, download=True, transform=transform)\n","        self.test_set = torchvision.datasets.CIFAR10(\n","            root='./data', train=False, download=True, transform=transform)\n","\n","    def get(self, num_clients: int) -> List[Dict[str, DataLoader]]:\n","        train_size = len(self.train_set) // num_clients\n","        test_size = len(self.test_set) // num_clients\n","\n","        dataloaders = []\n","        for i in range(num_clients):\n","            train_idx = range(i * train_size, (i + 1) * train_size)\n","            test_idx = range(i * test_size, (i + 1) * test_size)\n","\n","            train_set = Subset(self.train_set, train_idx)\n","            test_set = Subset(self.test_set, test_idx)\n","\n","            train_loader = DataLoader(\n","                train_set, batch_size=self.config[\"batch_size\"], shuffle=True, num_workers=4)\n","            test_loader = DataLoader(\n","                test_set, batch_size=self.config[\"batch_size\"], shuffle=False, num_workers=4)\n","            dataloaders.append({\n","                \"train\": train_loader,\n","                \"test\": test_loader\n","            })\n","\n","        return dataloaders"]},{"cell_type":"markdown","source":["シンプルなMNISTの分類モデルを記述する\n","- ここでは精度は問わずシンプルな設計とする"],"metadata":{"id":"vKIK2jJcn4yA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dspaQqXpOq3z"},"outputs":[],"source":["class CNNModel(nn.Module):\n","    def __init__(self):\n","        super(CNNModel, self).__init__()\n","        self.relu = nn.ReLU()\n","        self.pool = nn.MaxPool2d(2)\n","\n","        self.conv1 = nn.Conv2d(3, 16, 3)\n","        self.conv2 = nn.Conv2d(16, 128, 3)\n","\n","        self.fc1 = nn.Linear(128, 64)\n","        self.fc2 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = self.pool(x)\n","        x = self.conv2(x)\n","        x = self.relu(x)\n","\n","        x_size = x.size()\n","        x = x.reshape(x_size[0], -1, x_size[2] ** 2).mean(2)\n","\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"markdown","source":["クライアントモデルを記述する"],"metadata":{"id":"3mp8bXfQsyAU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IQeORnO9Oq3z"},"outputs":[],"source":["class FedAvgClient():\n","    def __init__(self, config: Dict, logger, dataloaders: Dict[str, DataLoader]) -> None:\n","        self.config = config\n","        self.train_loader = dataloaders[\"train\"]\n","        self.test_loader = dataloaders[\"test\"]\n","\n","        self.model: CNNModel = None  # type: ignore\n","\n","    def set_global_model(self, global_model: CNNModel):\n","        del self.model\n","        self.model = copy.deepcopy(global_model)\n","\n","    def train_local_model(self) -> CNNModel:\n","        criterion = nn.CrossEntropyLoss()\n","        optimizer = optim.Adam(self.model.parameters(),\n","                               lr=self.config[\"learning_rate\"])\n","\n","        def _train_loop():\n","            running_loss = 0\n","            for i, (X, y) in enumerate(self.train_loader):\n","                X = X.to(self.config[\"device\"])\n","                y = y.to(self.config[\"device\"])\n","                optimizer.zero_grad()\n","                outputs = self.model(X)\n","                loss = criterion(outputs, y)\n","                running_loss += loss.item()\n","                loss.backward()\n","                optimizer.step()\n","            return running_loss / len(self.train_loader)\n","\n","        def _test_loop():\n","            labels = []\n","            preds = []\n","            running_loss = 0\n","            with torch.no_grad():\n","                for i, (X, y) in enumerate(self.test_loader):\n","                    X = X.to(self.config[\"device\"])\n","                    y = y.to(self.config[\"device\"])\n","                    output = self.model(X)\n","                    loss = criterion(output, y)\n","                    running_loss += loss.item()\n","                    labels.append(y.detach().cpu())\n","                    preds.append(output.detach().cpu())\n","            labels = torch.cat(labels, dim=0)\n","            preds = torch.cat(preds, dim=0).argmax(1)\n","            acc = torch.sum(preds == labels) / len(labels)\n","            return running_loss / len(self.test_loader), acc.item()\n","\n","        self.model.to(self.config[\"device\"])\n","        for epoch in range(self.config[\"epochs\"]):\n","            self.model.train()\n","            train_loss = _train_loop()\n","            self.model.eval()\n","            test_loss, acc = _test_loop()\n","\n","            logger.info(f\"train_loss: {train_loss}, test_loss: {test_loss}, acc: {acc}\")\n","\n","        return self.model"]},{"cell_type":"markdown","source":["サーバ側を記述する\n","- モデルのパラメータを取得し、その平均をとって配布する\n","- モデルパラメータの取得と設定はすでに学んだ方法である"],"metadata":{"id":"zMMMKFqQtF-g"}},{"cell_type":"code","source":["class FedAvgServer():\n","    def __init__(self, config: Dict) -> None:\n","        self.config = config\n","\n","    def init_global_model(self) -> CNNModel:\n","        global_model = CNNModel()\n","        return global_model\n","\n","    def aggregate(self, local_models: List[CNNModel]) -> CNNModel:\n","        global_model = CNNModel().to(self.config[\"device\"])\n","\n","        # conv 1\n","        global_model.conv1.weight.data = torch.zeros_like(\n","            global_model.conv1.weight.data)\n","        for local_model in local_models:\n","            global_model.conv1.weight.data += local_model.conv1.weight.data\n","        global_model.conv1.weight.data /= len(local_models)\n","\n","        # conv 2\n","        global_model.conv2.weight.data = torch.zeros_like(\n","            global_model.conv2.weight.data)\n","        for local_model in local_models:\n","            global_model.conv2.weight.data += local_model.conv2.weight.data\n","        global_model.conv2.weight.data /= len(local_models)\n","\n","        # fc1\n","        global_model.fc1.weight.data = torch.zeros_like(\n","            global_model.fc1.weight.data)\n","        for local_model in local_models:\n","            global_model.fc1.weight.data += local_model.fc1.weight.data\n","        global_model.fc1.weight.data /= len(local_models)\n","\n","        # fc2\n","        global_model.fc2.weight.data = torch.zeros_like(\n","            global_model.fc2.weight.data)\n","        for local_model in local_models:\n","            global_model.fc2.weight.data += local_model.fc2.weight.data\n","        global_model.fc2.weight.data /= len(local_models)\n","\n","        return global_model"],"metadata":{"id":"5X1lhlRQtJqg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["実際に学習を行う\n","- ここでは、クライアント数は5としている"],"metadata":{"id":"anFMxHe4tUow"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RaLzThPEOq30","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724049285230,"user_tz":-540,"elapsed":466172,"user":{"displayName":"西宏章","userId":"00237858890977261979"}},"outputId":"e4609176-ef88-4baa-cc20-c075ea4d6e0e"},"outputs":[{"output_type":"stream","name":"stderr","text":["2024-08-19 06:26:58,351 [EXP][INFO] FedAvg start \n"]},{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:18<00:00, 9120738.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","2024-08-19 06:27:22,168 [EXP][INFO] Round: 0 start \n","2024-08-19 06:27:22,169 [EXP][INFO] train client: 0 \n","2024-08-19 06:27:27,402 [EXP][INFO] train_loss: 2.296985019611407, test_loss: 2.2834156453609467, acc: 0.12849999964237213 \n","2024-08-19 06:27:30,492 [EXP][INFO] train_loss: 2.26235358322723, test_loss: 2.231324687600136, acc: 0.19300000369548798 \n","2024-08-19 06:27:34,665 [EXP][INFO] train_loss: 2.1914345855954327, test_loss: 2.146526873111725, acc: 0.21050000190734863 \n","2024-08-19 06:27:38,114 [EXP][INFO] train_loss: 2.112354719186131, test_loss: 2.0833983719348907, acc: 0.22750000655651093 \n","2024-08-19 06:27:41,313 [EXP][INFO] train_loss: 2.0665830826457543, test_loss: 2.047814227640629, acc: 0.24650000035762787 \n","2024-08-19 06:27:41,317 [EXP][INFO] train client: 1 \n","2024-08-19 06:27:44,462 [EXP][INFO] train_loss: 2.2969547645955144, test_loss: 2.2827677875757217, acc: 0.1185000017285347 \n","2024-08-19 06:27:48,753 [EXP][INFO] train_loss: 2.2655427999134305, test_loss: 2.2365401834249496, acc: 0.15600000321865082 \n","2024-08-19 06:27:52,065 [EXP][INFO] train_loss: 2.2002553034432326, test_loss: 2.158226042985916, acc: 0.18700000643730164 \n","2024-08-19 06:27:55,396 [EXP][INFO] train_loss: 2.1227403200125394, test_loss: 2.0904861092567444, acc: 0.2070000022649765 \n","2024-08-19 06:27:58,694 [EXP][INFO] train_loss: 2.0719817212865324, test_loss: 2.0527559593319893, acc: 0.22200000286102295 \n","2024-08-19 06:27:58,702 [EXP][INFO] train client: 2 \n","2024-08-19 06:28:03,088 [EXP][INFO] train_loss: 2.2953819685344454, test_loss: 2.2839014530181885, acc: 0.10750000178813934 \n","2024-08-19 06:28:06,223 [EXP][INFO] train_loss: 2.26196255261385, test_loss: 2.235776662826538, acc: 0.15449999272823334 \n","2024-08-19 06:28:09,465 [EXP][INFO] train_loss: 2.1931735020649583, test_loss: 2.15504390001297, acc: 0.20250000059604645 \n","2024-08-19 06:28:13,116 [EXP][INFO] train_loss: 2.1135035979596872, test_loss: 2.091612607240677, acc: 0.2150000035762787 \n","2024-08-19 06:28:17,336 [EXP][INFO] train_loss: 2.0568716480762146, test_loss: 2.048932008445263, acc: 0.2460000067949295 \n","2024-08-19 06:28:17,339 [EXP][INFO] train client: 3 \n","2024-08-19 06:28:20,546 [EXP][INFO] train_loss: 2.298823416987552, test_loss: 2.2846675515174866, acc: 0.12250000238418579 \n","2024-08-19 06:28:23,689 [EXP][INFO] train_loss: 2.2691619003875347, test_loss: 2.2356181144714355, acc: 0.18700000643730164 \n","2024-08-19 06:28:27,809 [EXP][INFO] train_loss: 2.2034864244581778, test_loss: 2.1446020305156708, acc: 0.22550000250339508 \n","2024-08-19 06:28:31,266 [EXP][INFO] train_loss: 2.1218600590017775, test_loss: 2.073639914393425, acc: 0.23100000619888306 \n","2024-08-19 06:28:34,452 [EXP][INFO] train_loss: 2.0707570042791246, test_loss: 2.0351796224713326, acc: 0.2475000023841858 \n","2024-08-19 06:28:34,457 [EXP][INFO] train client: 4 \n","2024-08-19 06:28:38,148 [EXP][INFO] train_loss: 2.296190753767762, test_loss: 2.282834693789482, acc: 0.13249999284744263 \n","2024-08-19 06:28:42,662 [EXP][INFO] train_loss: 2.261479646344728, test_loss: 2.2308395504951477, acc: 0.17749999463558197 \n","2024-08-19 06:28:45,789 [EXP][INFO] train_loss: 2.196012379247931, test_loss: 2.1434871554374695, acc: 0.2084999978542328 \n","2024-08-19 06:28:48,924 [EXP][INFO] train_loss: 2.122439046449299, test_loss: 2.073512353003025, acc: 0.2434999942779541 \n","2024-08-19 06:28:52,021 [EXP][INFO] train_loss: 2.067560644089421, test_loss: 2.0276260748505592, acc: 0.25600001215934753 \n","2024-08-19 06:28:52,023 [EXP][INFO] Aggregate global model \n","2024-08-19 06:28:52,029 [EXP][INFO] Distribute global model \n","2024-08-19 06:28:52,036 [EXP][INFO] Round: 1 start \n","2024-08-19 06:28:52,037 [EXP][INFO] train client: 0 \n","2024-08-19 06:28:56,592 [EXP][INFO] train_loss: 2.056003221982642, test_loss: 2.0417877435684204, acc: 0.25049999356269836 \n","2024-08-19 06:28:59,664 [EXP][INFO] train_loss: 2.0331640560415725, test_loss: 2.0251969173550606, acc: 0.2644999921321869 \n","2024-08-19 06:29:02,783 [EXP][INFO] train_loss: 2.0158704413643367, test_loss: 2.0130598098039627, acc: 0.26249998807907104 \n","2024-08-19 06:29:05,923 [EXP][INFO] train_loss: 1.9997248891033703, test_loss: 1.9954282715916634, acc: 0.27300000190734863 \n","2024-08-19 06:29:10,465 [EXP][INFO] train_loss: 1.9841265421879442, test_loss: 1.9818347468972206, acc: 0.27900001406669617 \n","2024-08-19 06:29:10,467 [EXP][INFO] train client: 1 \n","2024-08-19 06:29:13,504 [EXP][INFO] train_loss: 2.0619295744956294, test_loss: 2.051557496190071, acc: 0.23250000178813934 \n","2024-08-19 06:29:16,628 [EXP][INFO] train_loss: 2.0401644133314303, test_loss: 2.034352108836174, acc: 0.24199999868869781 \n","2024-08-19 06:29:20,001 [EXP][INFO] train_loss: 2.0249395732638202, test_loss: 2.018697537481785, acc: 0.2409999966621399 \n","2024-08-19 06:29:24,159 [EXP][INFO] train_loss: 2.011623714543596, test_loss: 2.00440314412117, acc: 0.24899999797344208 \n","2024-08-19 06:29:27,253 [EXP][INFO] train_loss: 1.9971963121921201, test_loss: 1.9899903982877731, acc: 0.26750001311302185 \n","2024-08-19 06:29:27,255 [EXP][INFO] train client: 2 \n","2024-08-19 06:29:30,383 [EXP][INFO] train_loss: 2.0473569043074984, test_loss: 2.046506717801094, acc: 0.2529999911785126 \n","2024-08-19 06:29:33,829 [EXP][INFO] train_loss: 2.02181304557414, test_loss: 2.0263191610574722, acc: 0.25450000166893005 \n","2024-08-19 06:29:37,923 [EXP][INFO] train_loss: 2.0057598639138137, test_loss: 2.007996328175068, acc: 0.28700000047683716 \n","2024-08-19 06:29:41,140 [EXP][INFO] train_loss: 1.9880067577844933, test_loss: 1.9946035966277122, acc: 0.27799999713897705 \n","2024-08-19 06:29:44,344 [EXP][INFO] train_loss: 1.973743023751657, test_loss: 1.977127693593502, acc: 0.2709999978542328 \n","2024-08-19 06:29:44,346 [EXP][INFO] train client: 3 \n","2024-08-19 06:29:48,089 [EXP][INFO] train_loss: 2.0637879492361333, test_loss: 2.02613128721714, acc: 0.24449999630451202 \n","2024-08-19 06:29:51,846 [EXP][INFO] train_loss: 2.0385042715676223, test_loss: 2.00882101804018, acc: 0.25949999690055847 \n","2024-08-19 06:29:54,958 [EXP][INFO] train_loss: 2.0253568344478365, test_loss: 1.9933259710669518, acc: 0.2605000138282776 \n","2024-08-19 06:29:58,175 [EXP][INFO] train_loss: 2.0151187241831914, test_loss: 1.9784327819943428, acc: 0.26499998569488525 \n","2024-08-19 06:30:02,311 [EXP][INFO] train_loss: 1.9983201419250876, test_loss: 1.9631868675351143, acc: 0.2694999873638153 \n","2024-08-19 06:30:02,316 [EXP][INFO] train client: 4 \n","2024-08-19 06:30:05,569 [EXP][INFO] train_loss: 2.06080439422704, test_loss: 2.0184979289770126, acc: 0.2554999887943268 \n","2024-08-19 06:30:08,703 [EXP][INFO] train_loss: 2.0371093644371516, test_loss: 2.002017706632614, acc: 0.24400000274181366 \n","2024-08-19 06:30:11,932 [EXP][INFO] train_loss: 2.0216498465477666, test_loss: 1.987595684826374, acc: 0.2615000009536743 \n","2024-08-19 06:30:16,191 [EXP][INFO] train_loss: 2.00735376303709, test_loss: 1.9739463701844215, acc: 0.26100000739097595 \n","2024-08-19 06:30:19,296 [EXP][INFO] train_loss: 1.9883107309099994, test_loss: 1.9576852023601532, acc: 0.265500009059906 \n","2024-08-19 06:30:19,298 [EXP][INFO] Aggregate global model \n","2024-08-19 06:30:19,306 [EXP][INFO] Distribute global model \n","2024-08-19 06:30:19,313 [EXP][INFO] Round: 2 start \n","2024-08-19 06:30:19,314 [EXP][INFO] train client: 0 \n","2024-08-19 06:30:22,463 [EXP][INFO] train_loss: 2.01394163958634, test_loss: 2.0050339847803116, acc: 0.26249998807907104 \n","2024-08-19 06:30:25,589 [EXP][INFO] train_loss: 1.9898379075376293, test_loss: 1.98942182213068, acc: 0.27149999141693115 \n","2024-08-19 06:30:29,984 [EXP][INFO] train_loss: 1.9736324352554129, test_loss: 1.9761890545487404, acc: 0.2840000092983246 \n","2024-08-19 06:30:33,094 [EXP][INFO] train_loss: 1.959995232050932, test_loss: 1.9631073996424675, acc: 0.2815000116825104 \n","2024-08-19 06:30:36,213 [EXP][INFO] train_loss: 1.9472818178466604, test_loss: 1.9519305974245071, acc: 0.28200000524520874 \n","2024-08-19 06:30:36,216 [EXP][INFO] train client: 1 \n","2024-08-19 06:30:39,334 [EXP][INFO] train_loss: 2.023800504358509, test_loss: 2.0070099979639053, acc: 0.25999999046325684 \n","2024-08-19 06:30:43,706 [EXP][INFO] train_loss: 1.9989557220966, test_loss: 1.9903447702527046, acc: 0.2605000138282776 \n","2024-08-19 06:30:46,779 [EXP][INFO] train_loss: 1.9871941880334782, test_loss: 1.976463571190834, acc: 0.26350000500679016 \n","2024-08-19 06:30:49,862 [EXP][INFO] train_loss: 1.9707095668285708, test_loss: 1.9676628783345222, acc: 0.26249998807907104 \n","2024-08-19 06:30:52,980 [EXP][INFO] train_loss: 1.9614064512373526, test_loss: 1.9518087953329086, acc: 0.2784999907016754 \n","2024-08-19 06:30:52,984 [EXP][INFO] train client: 2 \n","2024-08-19 06:30:57,366 [EXP][INFO] train_loss: 2.003793751137166, test_loss: 2.000321440398693, acc: 0.26499998569488525 \n","2024-08-19 06:31:00,460 [EXP][INFO] train_loss: 1.9779033917414992, test_loss: 1.9862594306468964, acc: 0.27799999713897705 \n","2024-08-19 06:31:03,665 [EXP][INFO] train_loss: 1.9647883810574496, test_loss: 1.9703437685966492, acc: 0.2865000069141388 \n","2024-08-19 06:31:07,205 [EXP][INFO] train_loss: 1.9494525737400297, test_loss: 1.9564480781555176, acc: 0.28450000286102295 \n","2024-08-19 06:31:11,320 [EXP][INFO] train_loss: 1.9399860795540145, test_loss: 1.9439630508422852, acc: 0.29649999737739563 \n","2024-08-19 06:31:11,323 [EXP][INFO] train client: 3 \n","2024-08-19 06:31:14,573 [EXP][INFO] train_loss: 2.0233282801471177, test_loss: 1.9810265228152275, acc: 0.26499998569488525 \n","2024-08-19 06:31:17,617 [EXP][INFO] train_loss: 1.9998528670661058, test_loss: 1.9671534895896912, acc: 0.27799999713897705 \n","2024-08-19 06:31:21,133 [EXP][INFO] train_loss: 1.9878070626077773, test_loss: 1.9548167362809181, acc: 0.27000001072883606 \n","2024-08-19 06:31:25,217 [EXP][INFO] train_loss: 1.976153630244581, test_loss: 1.9397532120347023, acc: 0.2944999933242798 \n","2024-08-19 06:31:28,356 [EXP][INFO] train_loss: 1.963935855068738, test_loss: 1.9291574731469154, acc: 0.273499995470047 \n","2024-08-19 06:31:28,358 [EXP][INFO] train client: 4 \n","2024-08-19 06:31:31,588 [EXP][INFO] train_loss: 2.0185760727411584, test_loss: 1.974288746714592, acc: 0.2669999897480011 \n","2024-08-19 06:31:35,621 [EXP][INFO] train_loss: 1.990888557856596, test_loss: 1.961586132645607, acc: 0.26649999618530273 \n","2024-08-19 06:31:39,305 [EXP][INFO] train_loss: 1.9837851282916492, test_loss: 1.9499498084187508, acc: 0.25949999690055847 \n","2024-08-19 06:31:42,626 [EXP][INFO] train_loss: 1.9719772535034372, test_loss: 1.9395547062158585, acc: 0.2770000100135803 \n","2024-08-19 06:31:45,857 [EXP][INFO] train_loss: 1.9593156500707698, test_loss: 1.9318998083472252, acc: 0.28200000524520874 \n","2024-08-19 06:31:45,860 [EXP][INFO] Aggregate global model \n","2024-08-19 06:31:45,865 [EXP][INFO] Distribute global model \n","2024-08-19 06:31:45,871 [EXP][INFO] Round: 3 start \n","2024-08-19 06:31:45,872 [EXP][INFO] train client: 0 \n","2024-08-19 06:31:50,397 [EXP][INFO] train_loss: 1.953229117997085, test_loss: 1.9534730911254883, acc: 0.28700000047683716 \n","2024-08-19 06:31:53,594 [EXP][INFO] train_loss: 1.9363117942327186, test_loss: 1.9411690458655357, acc: 0.27950000762939453 \n","2024-08-19 06:31:56,823 [EXP][INFO] train_loss: 1.926172552229483, test_loss: 1.931404247879982, acc: 0.29499998688697815 \n","2024-08-19 06:32:00,142 [EXP][INFO] train_loss: 1.9183596508412422, test_loss: 1.92286516726017, acc: 0.29249998927116394 \n","2024-08-19 06:32:04,903 [EXP][INFO] train_loss: 1.9098614077024822, test_loss: 1.9113299250602722, acc: 0.30149999260902405 \n","2024-08-19 06:32:04,905 [EXP][INFO] train client: 1 \n","2024-08-19 06:32:08,164 [EXP][INFO] train_loss: 1.970761984209471, test_loss: 1.9523880779743195, acc: 0.26649999618530273 \n","2024-08-19 06:32:11,413 [EXP][INFO] train_loss: 1.9530367504192303, test_loss: 1.944095604121685, acc: 0.28349998593330383 \n","2024-08-19 06:32:15,231 [EXP][INFO] train_loss: 1.9447549777694895, test_loss: 1.9332288950681686, acc: 0.28299999237060547 \n","2024-08-19 06:32:19,438 [EXP][INFO] train_loss: 1.9357774423647531, test_loss: 1.924192987382412, acc: 0.28450000286102295 \n","2024-08-19 06:32:22,611 [EXP][INFO] train_loss: 1.9236130322082132, test_loss: 1.917035162448883, acc: 0.2874999940395355 \n","2024-08-19 06:32:22,615 [EXP][INFO] train client: 2 \n","2024-08-19 06:32:25,756 [EXP][INFO] train_loss: 1.9458610498452489, test_loss: 1.944061279296875, acc: 0.2904999852180481 \n","2024-08-19 06:32:29,464 [EXP][INFO] train_loss: 1.925665185421328, test_loss: 1.9321714714169502, acc: 0.2985000014305115 \n","2024-08-19 06:32:33,351 [EXP][INFO] train_loss: 1.9162488179870798, test_loss: 1.9217383563518524, acc: 0.296999990940094 \n","2024-08-19 06:32:36,506 [EXP][INFO] train_loss: 1.908148181589344, test_loss: 1.9119644686579704, acc: 0.2939999997615814 \n","2024-08-19 06:32:39,737 [EXP][INFO] train_loss: 1.8989292881156825, test_loss: 1.9048021659255028, acc: 0.3050000071525574 \n","2024-08-19 06:32:39,741 [EXP][INFO] train client: 3 \n","2024-08-19 06:32:43,927 [EXP][INFO] train_loss: 1.9667583839802802, test_loss: 1.9253465235233307, acc: 0.2865000069141388 \n","2024-08-19 06:32:47,351 [EXP][INFO] train_loss: 1.9618942465963243, test_loss: 1.9148289486765862, acc: 0.3050000071525574 \n","2024-08-19 06:32:50,598 [EXP][INFO] train_loss: 1.94242377975319, test_loss: 1.908662535250187, acc: 0.28949999809265137 \n","2024-08-19 06:32:53,849 [EXP][INFO] train_loss: 1.9390436939046354, test_loss: 1.8957932963967323, acc: 0.3125 \n","2024-08-19 06:32:58,376 [EXP][INFO] train_loss: 1.9270599884322928, test_loss: 1.8870929926633835, acc: 0.3154999911785126 \n","2024-08-19 06:32:58,378 [EXP][INFO] train client: 4 \n","2024-08-19 06:33:01,543 [EXP][INFO] train_loss: 1.9578376842450491, test_loss: 1.9255083054304123, acc: 0.2865000069141388 \n","2024-08-19 06:33:04,765 [EXP][INFO] train_loss: 1.9460058996949015, test_loss: 1.9132059961557388, acc: 0.28949999809265137 \n","2024-08-19 06:33:07,957 [EXP][INFO] train_loss: 1.9349378498294685, test_loss: 1.9047869890928268, acc: 0.2879999876022339 \n","2024-08-19 06:33:12,273 [EXP][INFO] train_loss: 1.923952449726153, test_loss: 1.8958721905946732, acc: 0.2879999876022339 \n","2024-08-19 06:33:15,529 [EXP][INFO] train_loss: 1.9159193416185016, test_loss: 1.8855200856924057, acc: 0.30550000071525574 \n","2024-08-19 06:33:15,532 [EXP][INFO] Aggregate global model \n","2024-08-19 06:33:15,538 [EXP][INFO] Distribute global model \n","2024-08-19 06:33:15,544 [EXP][INFO] Round: 4 start \n","2024-08-19 06:33:15,544 [EXP][INFO] train client: 0 \n","2024-08-19 06:33:18,674 [EXP][INFO] train_loss: 1.9347865928577472, test_loss: 1.9210157245397568, acc: 0.28700000047683716 \n","2024-08-19 06:33:22,015 [EXP][INFO] train_loss: 1.9098362258717985, test_loss: 1.9142348542809486, acc: 0.2944999933242798 \n","2024-08-19 06:33:26,141 [EXP][INFO] train_loss: 1.9033945557437366, test_loss: 1.9048256278038025, acc: 0.2955000102519989 \n","2024-08-19 06:33:29,246 [EXP][INFO] train_loss: 1.8935139209409304, test_loss: 1.8978559374809265, acc: 0.29499998688697815 \n","2024-08-19 06:33:32,405 [EXP][INFO] train_loss: 1.8888213679760317, test_loss: 1.8888756111264229, acc: 0.2955000102519989 \n","2024-08-19 06:33:32,408 [EXP][INFO] train client: 1 \n","2024-08-19 06:33:35,992 [EXP][INFO] train_loss: 1.9495617121080808, test_loss: 1.9324494153261185, acc: 0.2745000123977661 \n","2024-08-19 06:33:39,899 [EXP][INFO] train_loss: 1.925078055526637, test_loss: 1.9235989153385162, acc: 0.2775000035762787 \n","2024-08-19 06:33:43,062 [EXP][INFO] train_loss: 1.9176443558705003, test_loss: 1.9159340113401413, acc: 0.2750000059604645 \n","2024-08-19 06:33:46,368 [EXP][INFO] train_loss: 1.9100431596176535, test_loss: 1.9071345403790474, acc: 0.29100000858306885 \n","2024-08-19 06:33:50,607 [EXP][INFO] train_loss: 1.903447999229914, test_loss: 1.898075558245182, acc: 0.2815000116825104 \n","2024-08-19 06:33:50,612 [EXP][INFO] train client: 2 \n","2024-08-19 06:33:53,873 [EXP][INFO] train_loss: 1.9206097533431234, test_loss: 1.916880115866661, acc: 0.28949999809265137 \n","2024-08-19 06:33:57,064 [EXP][INFO] train_loss: 1.9014431871945345, test_loss: 1.9056874960660934, acc: 0.30399999022483826 \n","2024-08-19 06:34:00,340 [EXP][INFO] train_loss: 1.8956386137612258, test_loss: 1.9082791805267334, acc: 0.2985000014305115 \n","2024-08-19 06:34:04,975 [EXP][INFO] train_loss: 1.881669382505779, test_loss: 1.889834277331829, acc: 0.31049999594688416 \n","2024-08-19 06:34:08,251 [EXP][INFO] train_loss: 1.8756158563155163, test_loss: 1.8831254616379738, acc: 0.3100000023841858 \n","2024-08-19 06:34:08,254 [EXP][INFO] train client: 3 \n","2024-08-19 06:34:11,536 [EXP][INFO] train_loss: 1.959420919418335, test_loss: 1.9037190675735474, acc: 0.28600001335144043 \n","2024-08-19 06:34:14,865 [EXP][INFO] train_loss: 1.9343443052678169, test_loss: 1.8940553814172745, acc: 0.30149999260902405 \n","2024-08-19 06:34:19,244 [EXP][INFO] train_loss: 1.925885251805752, test_loss: 1.8875522837042809, acc: 0.3100000023841858 \n","2024-08-19 06:34:22,403 [EXP][INFO] train_loss: 1.9137543288967278, test_loss: 1.881313294172287, acc: 0.30300000309944153 \n","2024-08-19 06:34:25,919 [EXP][INFO] train_loss: 1.914688151093978, test_loss: 1.8774113655090332, acc: 0.30399999022483826 \n","2024-08-19 06:34:25,921 [EXP][INFO] train client: 4 \n","2024-08-19 06:34:29,857 [EXP][INFO] train_loss: 1.95344192770463, test_loss: 1.8944811299443245, acc: 0.28949999809265137 \n","2024-08-19 06:34:33,752 [EXP][INFO] train_loss: 1.9219538380828085, test_loss: 1.8873840421438217, acc: 0.28999999165534973 \n","2024-08-19 06:34:37,009 [EXP][INFO] train_loss: 1.9184712337542185, test_loss: 1.882637619972229, acc: 0.30649998784065247 \n","2024-08-19 06:34:40,258 [EXP][INFO] train_loss: 1.9060063452660283, test_loss: 1.8741862773895264, acc: 0.30799999833106995 \n","2024-08-19 06:34:44,637 [EXP][INFO] train_loss: 1.900280098371868, test_loss: 1.868317998945713, acc: 0.3009999990463257 \n","2024-08-19 06:34:44,641 [EXP][INFO] Aggregate global model \n","2024-08-19 06:34:44,649 [EXP][INFO] Distribute global model \n","2024-08-19 06:34:44,658 [EXP][INFO] FedAvg finished \n"]}],"source":["seed_everything(config[\"seed\"])\n","logger = get_logger()\n","\n","logger.info(\"FedAvg start\")\n","\n","# init dataset\n","retriever = FedAvgRetriever(config)\n","dataloaders = retriever.get(config[\"num_clients\"])\n","\n","# init server and clients\n","server = FedAvgServer(config)\n","clients = [FedAvgClient(config, logger, dataloaders[i])\n","            for i in range(config[\"num_clients\"])]\n","\n","# init FedAvg\n","global_model = server.init_global_model()\n","for client in clients:\n","    client.set_global_model(global_model)\n","\n","# round loop\n","for round in range(config[\"rounds\"]):\n","\n","    logger.info(f\"Round: {round} start\")\n","\n","    local_models = []\n","    for i, client in enumerate(clients):\n","        logger.info(f\"train client: {i}\")\n","        local_model = client.train_local_model()\n","        local_models.append(local_model)\n","\n","    logger.info(f\"Aggregate global model\")\n","    global_model = server.aggregate(local_models)\n","    logger.info(f\"Distribute global model\")\n","    for client in clients:\n","        client.set_global_model(global_model)\n","\n","logger.info(\"FedAvg finished\")"]},{"cell_type":"markdown","source":["# 課題1\n","\n","精度を改善してみよう"],"metadata":{"id":"pvZYMdV7zbi7"}},{"cell_type":"markdown","source":["# 課題2\n","\n","3つ以上のFLに改造してみよう"],"metadata":{"id":"SVEz51A4zwwd"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/keioNishi/lec-dataai/blob/main/dataai-text-J-Diffusion.ipynb","timestamp":1661617425151},{"file_id":"https://github.com/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb","timestamp":1661425026567}],"gpuType":"T4","toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}